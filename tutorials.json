[
    {
        "name": "Classification of chest vs. adominal X-rays",
        "description": "The goal of this tutorial is to build a deep learning classifier to accurately differentiate between chest and abdominal X-rays",
        "author": [
            [
                "tmoneyx01",
                "https://github.com/tmoneyx01"
            ]
        ],
        "links": [
            [
                "annotator",
                "https://public.md.ai/annotator/project/PVq9raBJ"
            ],
            [
                "git",
                "https://github.com/mdai/mdai-client-py",
                26
            ],
            [
                "docs",
                "https://docs.md.ai/"
            ],
            [
                "pypi",
                "https://pypi.org/project/mdai/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/mdai/ml-lessons/blob/master/lesson1-xray-images-classification.ipynb",
        "update": 1583563620.0
    },
    {
        "name": "SkinDeep",
        "description": "Remove Body Tattoo Using Deep Learning",
        "author": [
            [
                "Vijish Madhavan",
                "https://github.com/vijishmadhavan"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1805.08318"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1710.10196"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1707.02921"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1603.08155"
            ],
            [
                "git",
                "https://github.com/vijishmadhavan/SkinDeep",
                947
            ],
            [
                "git",
                "https://github.com/jantic/DeOldify"
            ]
        ],
        "colab": "https://colab.research.google.com/github/vijishmadhavan/SkinDeep/blob/master/SkinDeep_good.ipynb",
        "update": 1619279123.0
    },
    {
        "name": "ArtLine",
        "description": "A Deep Learning based project for creating line art portraits",
        "author": [
            [
                "Vijish Madhavan",
                "https://github.com/vijishmadhavan"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1805.08318"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1710.10196"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1707.02921"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1603.08155"
            ],
            [
                "git",
                "https://github.com/vijishmadhavan/ArtLine",
                3601
            ],
            [
                "git",
                "https://github.com/yiranran/APDrawingGAN"
            ],
            [
                "git",
                "https://github.com/jantic/DeOldify"
            ],
            [
                "data",
                "https://cg.cs.tsinghua.edu.cn/people/~Yongjin/APDrawingDB.zip"
            ]
        ],
        "colab": "https://colab.research.google.com/github/vijishmadhavan/ArtLine/blob/main/ControlNet_%2BArtLine_.ipynb",
        "update": 1677846317.0
    },
    {
        "name": "Big Sleep",
        "description": "Text to image generation, using OpenAI's CLIP and a BigGAN",
        "author": [
            [
                "Phil Wang",
                "https://lucidrains.github.io/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2103.00020"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1809.11096"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/bigsleep/comments/lxawb4/how_to_use_some_of_the_newer_features_of/"
            ],
            [
                "git",
                "https://github.com/lucidrains/big-sleep",
                2569
            ],
            [
                "reddit",
                "https://www.reddit.com/r/bigsleep/"
            ],
            [
                "pypi",
                "https://pypi.org/project/big-sleep/"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1MEWKbm-driRNF8PrU7ogS5o3se-ePyPb",
        "update": 1615949421.123
    },
    {
        "name": "Deep Daze",
        "description": "Text to image generation using OpenAI's CLIP and Siren",
        "author": [
            [
                "Phil Wang",
                "https://lucidrains.github.io/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2103.00020"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2006.09661"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/deepdaze/"
            ],
            [
                "git",
                "https://github.com/lucidrains/deep-daze",
                4375
            ],
            [
                "pypi",
                "https://pypi.org/project/deep-daze/"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1_YOHdORb0Fg1Q7vWZ_KlrtFe9Ur3pmVj",
        "update": 1615949380.476
    },
    {
        "name": "Reformer",
        "description": "Performs on par with Transformer models while being much more memory-efficient and much faster on long sequences",
        "author": [
            [
                "Phil Wang",
                "https://lucidrains.github.io/"
            ],
            [
                "Nikita Kitaev",
                "https://kitaev.com/"
            ],
            [
                "Łukasz Kaiser",
                "https://scholar.google.com/citations?user=JWmiQR0AAAAJ"
            ],
            [
                "Anselm Levskaya",
                "https://anselmlevskaya.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/lucidrains/reformer-pytorch",
                2129
            ],
            [
                "git",
                "https://github.com/lucidrains/routing-transformer"
            ],
            [
                "git",
                "https://github.com/lucidrains/sinkhorn-transformer"
            ],
            [
                "git",
                "https://github.com/lucidrains/performer-pytorch"
            ],
            [
                "git",
                "https://github.com/lucidrains/linear-attention-transformer/"
            ],
            [
                "git",
                "https://github.com/lucidrains/compressive-transformer-pytorch"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2001.04451"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1907.01470"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1910.05895"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1909.11556"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1911.02150"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2002.05202"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2003.05997"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2003.04887"
            ],
            [
                "neurips",
                "https://proceedings.neurips.cc/paper/2019/hash/9d8df73a3cfbf3c5b47bc9b50f214aff-Abstract.html"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2002.07028"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2103.03404"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2104.09864"
            ],
            [
                "neurips",
                "https://proceedings.neurips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html"
            ],
            [
                "yt",
                "https://youtu.be/i4H0kjxrias"
            ],
            [
                "yt",
                "https://youtu.be/Kf3x3lqf9cQ"
            ],
            [
                "yt",
                "https://youtu.be/0eTULzrOztQ"
            ],
            [
                "blog post",
                "https://ai.googleblog.com/2020/01/reformer-efficient-transformer.html"
            ],
            [
                "pypi",
                "https://pypi.org/project/reformer-pytorch/"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1awNgXYtjvUeXl1gS-v1iyDXTJJ-fyJIK",
        "update": 1636240654.93
    },
    {
        "name": "AudioLM",
        "description": "Framework for high-quality audio generation with long-term consistency",
        "author": [
            [
                "Phil Wang",
                "https://lucidrains.github.io/"
            ],
            [
                "Zalán Borsos",
                "https://zalanborsos.com/"
            ],
            [
                "Raphaël Marinier",
                "https://github.com/RaphaelMarinier"
            ],
            [
                "Damien Vincent",
                "https://www.linkedin.com/in/damien-vincent-1958381"
            ],
            [
                "Eugene Kharitonov",
                "https://eugene-kharitonov.github.io/"
            ],
            [
                "Olivier Pietquin",
                "https://research.google/people/105812"
            ],
            [
                "Matt Sharifi",
                "https://scholar.google.com/citations?user=GeQNBz0AAAAJ"
            ],
            [
                "Olivier Teboul",
                "https://scholar.google.com/citations?user=ep0OfyAAAAAJ"
            ],
            [
                "David Grangier",
                "http://david.grangier.info/"
            ],
            [
                "Marco Tagliasacchi",
                "https://scholar.google.com/citations?user=zwH1rZQAAAAJ"
            ],
            [
                "Neil Zeghidour",
                "https://github.com/lienz"
            ]
        ],
        "links": [
            [
                "project",
                "https://google-research.github.io/seanet/audiolm/examples/"
            ],
            [
                "blog post",
                "https://blog.research.google/2022/10/audiolm-language-modeling-approach-to.html"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2209.03143"
            ],
            [
                "doi",
                "https://doi.org/10.1109/TASLP.2023.3288409",
                103
            ],
            [
                "discord",
                "https://discord.gg/xBPBXfcFHd"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2107.03312"
            ],
            [
                "git",
                "https://github.com/lucidrains/audiolm-pytorch",
                2453
            ],
            [
                "git",
                "https://github.com/facebookresearch/encodec"
            ],
            [
                "git",
                "https://github.com/lucidrains/musiclm-pytorch"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2305.02765"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2305.19466"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2002.05202"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1911.02150"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2207.12598"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2105.13290"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2210.13432"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2111.09883"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2104.05707"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2210.13438"
            ],
            [
                "yt",
                "https://youtu.be/Vucewi_kPEU"
            ],
            [
                "yt",
                "https://youtu.be/behUbh0koZk"
            ],
            [
                "yt",
                "https://youtu.be/olNvmUCmY8o"
            ]
        ],
        "colab": "https://colab.research.google.com/github/lucidrains/audiolm-pytorch/blob/main/audiolm_pytorch_demo.ipynb",
        "update": 1679606718.0
    },
    {
        "name": "Transfer learning and fine-tuning",
        "description": "You will learn how to classify images of cats and dogs by using transfer learning from a pre-trained network",
        "author": [
            [
                "François Chollet",
                "https://fchollet.com/"
            ]
        ],
        "links": [
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Transfer_learning"
            ],
            [
                "pwc",
                "https://paperswithcode.com/task/transfer-learning"
            ],
            [
                "tf",
                "https://www.tensorflow.org/tutorials/images/transfer_learning"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb",
        "update": 1719370506.0
    },
    {
        "name": "DeepDream",
        "description": "This tutorial contains a minimal implementation of DeepDream: an experiment that visualizes the patterns learned by a neural network",
        "author": [
            [
                "Alexander Mordvintsev",
                "https://znah.net/"
            ],
            [
                "Billy Lamberta",
                "https://github.com/lamberta"
            ]
        ],
        "links": [
            [
                "blog post",
                "https://research.google/blog/inceptionism-going-deeper-into-neural-networks/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1409.4842"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Inception"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/DeepDream"
            ],
            [
                "medium",
                "https://medium.com/@nik.nagarajan2/deepdream-a-psychedelic-ai-experience-ab482dd5228b"
            ],
            [
                "tf",
                "https://www.tensorflow.org/tutorials/generative/deepdream"
            ],
            [
                "medium",
                "https://towardsdatascience.com/dreaming-over-text-f6745c829cee"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/deepdream.ipynb",
        "update": 1642034218.0
    },
    {
        "name": "Neural style transfer",
        "description": "This tutorial uses deep learning to compose one image in the style of another image",
        "author": [
            [
                "Leon Gatys",
                "https://scholar.google.com/citations?user=ADMVEmsAAAAJ"
            ],
            [
                "Alexander Ecker",
                "https://eckerlab.org/"
            ],
            [
                "Matthias Bethge",
                "https://bethgelab.org/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1508.06576"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/style_transfer.ipynb",
        "update": 1715030334.0
    },
    {
        "name": "Adversarial FGSM",
        "description": "This tutorial creates an adversarial example using the Fast Gradient Signed Method attack. This was one of the first and most popular attacks to fool a neural network.",
        "author": [
            [
                "Ian Goodfellow",
                "https://www.iangoodfellow.com/"
            ],
            [
                "Jonathon Shlens",
                "https://shlens.github.io/"
            ],
            [
                "Christian Szegedy",
                "https://scholar.google.com/citations?user=bnQMuzgAAAAJ"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1412.6572"
            ],
            [
                "tf",
                "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/applications/MobileNetV2"
            ],
            [
                "imagenet",
                "http://www.image-net.org/"
            ],
            [
                "tf",
                "https://www.tensorflow.org/tutorials/generative/adversarial_fgsm"
            ],
            [
                "medium",
                "https://medium.com/@zachariaharungeorge/a-deep-dive-into-the-fast-gradient-sign-method-611826e34865"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/adversarial_fgsm.ipynb",
        "update": 1615576517.0
    },
    {
        "name": "Autoencoders",
        "description": "This tutorial introduces autoencoders with three examples: the basics, image denoising, and anomaly detection",
        "author": [
            [
                "Billy Lamberta",
                "https://github.com/lamberta"
            ]
        ],
        "links": [
            [
                "book",
                "https://www.deeplearningbook.org/contents/autoencoders.html"
            ],
            [
                "data",
                "http://www.timeseriesclassification.com/description.php?Dataset=ECG5000"
            ],
            [
                "blog post",
                "https://blog.keras.io/building-autoencoders-in-keras.html"
            ],
            [
                "examples",
                "https://anomagram.fastforwardlabs.com/#/"
            ],
            [
                "pwc",
                "https://paperswithcode.com/method/autoencoder"
            ],
            [
                "tf",
                "https://www.tensorflow.org/tutorials/generative/autoencoder"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/autoencoder.ipynb",
        "update": 1713214469.0
    },
    {
        "name": "CVAE",
        "description": "This notebook demonstrates how train a Variational Autoencoder on the MNIST dataset",
        "author": [
            [
                "Diederik Kingma",
                "http://www.dpkingma.com/"
            ],
            [
                "Max Welling",
                "https://staff.fnwi.uva.nl/m.welling/"
            ],
            [
                "Danilo Rezende",
                "https://danilorezende.com/about/"
            ],
            [
                "Shakir Mohamed",
                "https://shakirm.com/"
            ],
            [
                "Daan Wierstra",
                "https://scholar.google.com/citations?user=aDbsf28AAAAJ"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1312.6114"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1401.4082"
            ],
            [
                "tf",
                "https://www.tensorflow.org/tutorials/generative/cvae"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/cvae.ipynb",
        "update": 1616435123.0
    },
    {
        "name": "CycleGAN",
        "description": "This notebook demonstrates unpaired image to image translation using conditional GAN's",
        "author": [
            [
                "Jun-Yan Zhu",
                "https://www.cs.cmu.edu/~junyanz/"
            ],
            [
                "Taesung Park",
                "https://taesung.me/"
            ],
            [
                "Phillip Isola",
                "https://web.mit.edu/phillipi/"
            ],
            [
                "Alexei Efros",
                "https://people.eecs.berkeley.edu/~efros/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1703.10593"
            ],
            [
                "tf",
                "https://www.tensorflow.org/datasets/catalog/cycle_gan"
            ],
            [
                "tf",
                "https://www.tensorflow.org/tutorials/generative/cyclegan"
            ],
            [
                "doi",
                "https://doi.org/10.1109/ICCV.2017.244",
                12599
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/cyclegan.ipynb",
        "update": 1705454428.0
    },
    {
        "name": "DCGAN",
        "description": "This tutorial demonstrates how to generate images of handwritten digits using a Deep Convolutional Generative Adversarial Network",
        "author": [
            [
                "Alec Radford",
                "https://scholar.google.com/citations?user=dOad5HoAAAAJ"
            ],
            [
                "Luke Metz",
                "https://lukemetz.com/"
            ],
            [
                "Soumith Chintala",
                "https://soumith.ch/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1511.06434"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/jessicali9530/celeba-dataset"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1701.00160"
            ],
            [
                "medium",
                "https://medium.com/@vedantjagtap2002/artificial-intelligence-approach-to-reduce-energy-used-for-cooling-data-centres-d2d78d92c107"
            ],
            [
                "tf",
                "https://www.tensorflow.org/tutorials/generative/dcgan"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/dcgan.ipynb",
        "update": 1615576999.0
    },
    {
        "name": "Pix2Pix",
        "description": "This notebook demonstrates image to image translation using conditional GAN's",
        "author": [
            [
                "Phillip Isola",
                "https://web.mit.edu/phillipi/"
            ],
            [
                "Jun-Yan Zhu",
                "https://www.cs.cmu.edu/~junyanz/"
            ],
            [
                "Tinghui Zhou",
                "https://tinghuiz.github.io/"
            ],
            [
                "Alexei Efros",
                "https://people.eecs.berkeley.edu/~efros/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1611.07004"
            ],
            [
                "data",
                "https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets/"
            ],
            [
                "doi",
                "https://doi.org/10.1109/CVPR.2017.632",
                11868
            ],
            [
                "tf",
                "https://www.tensorflow.org/tutorials/generative/pix2pix"
            ],
            [
                "medium",
                "https://medium.com/the-ai-team/image-to-image-translation-using-conditional-dcgans-7edc9e78c476"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/pix2pix.ipynb",
        "update": 1721850081.0
    },
    {
        "name": "Simple audio recognition",
        "description": "This tutorial will show you how to build a basic speech recognition network that recognizes ten different words",
        "author": [
            [
                "Google",
                "https://www.tensorflow.org/"
            ]
        ],
        "links": [
            [
                "tf",
                "https://www.tensorflow.org/datasets/catalog/speech_commands"
            ],
            [
                "coursera",
                "https://www.coursera.org/lecture/audio-signal-processing/stft-2-tjEQe"
            ],
            [
                "tf.js",
                "https://codelabs.developers.google.com/codelabs/tensorflowjs-audio-codelab/index.html"
            ],
            [
                "pwc",
                "https://paperswithcode.com/task/speech-recognition"
            ],
            [
                "tf",
                "https://www.tensorflow.org/tutorials/audio/simple_audio"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/audio/simple_audio.ipynb",
        "update": 1731650218.0
    },
    {
        "name": "Image classification",
        "description": "This tutorial shows how to classify images of flowers",
        "author": [
            [
                "Billy Lamberta",
                "https://github.com/lamberta"
            ]
        ],
        "links": [
            [
                "pwc",
                "https://paperswithcode.com/task/image-classification"
            ],
            [
                "tf",
                "https://www.tensorflow.org/tutorials/images/classification"
            ],
            [
                "tf",
                "https://www.tensorflow.org/api_docs/python/tf/keras/Sequential"
            ],
            [
                "tf",
                "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/classification.ipynb",
        "update": 1721850081.0
    },
    {
        "name": "CNN",
        "description": "This tutorial demonstrates training a simple Convolutional Neural Network to classify CIFAR images",
        "author": [
            [
                "Billy Lamberta",
                "https://github.com/lamberta"
            ]
        ],
        "links": [
            [
                "link",
                "https://developers.google.com/machine-learning/glossary/#convolutional_neural_network"
            ],
            [
                "cifar",
                "https://www.cs.toronto.edu/~kriz/cifar.html"
            ],
            [
                "tf",
                "https://www.tensorflow.org/tutorials/images/cnn"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/cnn.ipynb",
        "update": 1621635708.0
    },
    {
        "name": "Data augmentation",
        "description": "This tutorial demonstrates data augmentation: a technique to increase the diversity of your training set by applying random transformations such as image rotation",
        "author": [
            [
                "Billy Lamberta",
                "https://github.com/lamberta"
            ]
        ],
        "links": [
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Data_augmentation"
            ],
            [
                "tf",
                "https://www.tensorflow.org/datasets/catalog/tf_flowers"
            ],
            [
                "pwc",
                "https://paperswithcode.com/task/data-augmentation"
            ],
            [
                "tf",
                "https://www.tensorflow.org/tutorials/images/data_augmentation"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/data_augmentation.ipynb",
        "update": 1707893833.0
    },
    {
        "name": "Image segmentation",
        "description": "This tutorial focuses on the task of image segmentation, using a modified U-Net",
        "author": [
            [
                "Olaf Ronneberger",
                "https://lmb.informatik.uni-freiburg.de/people/ronneber/"
            ],
            [
                "Philipp Fischer",
                "https://scholar.google.com/citations?user=M2j8KYMAAAAJ"
            ],
            [
                "Thomas Brox",
                "https://lmb.informatik.uni-freiburg.de/people/brox/index.en.html"
            ]
        ],
        "links": [
            [
                "doi",
                "http://doi.org/10.1007/978-3-319-24574-4_28",
                36494
            ],
            [
                "data",
                "https://www.robots.ox.ac.uk/~vgg/data/pets/"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/c/carvana-image-masking-challenge/overview"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1505.04597"
            ],
            [
                "tf",
                "https://www.tensorflow.org/tutorials/images/segmentation"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/segmentation.ipynb",
        "update": 1712679964.0
    },
    {
        "name": "Integrated gradients",
        "description": "This tutorial demonstrates how to implement Integrated Gradients, an Explainable AI technique",
        "author": [
            [
                "Mukund Sundararajan",
                "https://scholar.google.com/citations?user=q39nzokAAAAJ"
            ],
            [
                "Ankur Taly",
                "https://theory.stanford.edu/~ataly/"
            ],
            [
                "Qiqi Yan",
                "https://scholar.google.com/citations?user=Wn8xr_gAAAAJ"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/ankurtaly/Integrated-Gradients",
                600
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1703.01365"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Explainable_artificial_intelligence"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Linear_interpolation"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Riemann_sum"
            ],
            [
                "git",
                "https://github.com/GoogleCloudPlatform/training-data-analyst/tree/master/blogs/integrated_gradients"
            ],
            [
                "visualizing",
                "https://distill.pub/2020/attribution-baselines/"
            ],
            [
                "tf",
                "https://www.tensorflow.org/tutorials/interpretability/integrated_gradients"
            ],
            [
                "medium",
                "https://medium.com/codex/explainable-ai-integrated-gradients-for-deep-neural-network-predictions-eb4f96248afb"
            ],
            [
                "medium",
                "https://towardsdatascience.com/understanding-deep-learning-models-with-integrated-gradients-24ddce643dbf"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/interpretability/integrated_gradients.ipynb",
        "update": 1705454428.0
    },
    {
        "name": "Actor-Critic",
        "description": "This tutorial demonstrates how to implement the Actor-Critic method using TensorFlow to train an agent on the Open AI Gym CartPole-V0 environment",
        "author": [
            [
                "Vijay Konda",
                "https://scholar.google.com/citations?user=bi-WXQIAAAAJ"
            ],
            [
                "John Tsitsiklis",
                "https://web.mit.edu/jnt/www/home.html"
            ]
        ],
        "links": [
            [
                "neurips",
                "https://papers.nips.cc/paper/1786-actor-critic-algorithms"
            ],
            [
                "gym",
                "https://gym.openai.com/"
            ],
            [
                "neurips",
                "https://papers.nips.cc/paper/1713-policy-gradient-methods-for-reinforcement-learning-with-function-approximation.pdf"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Temporal_difference_learning"
            ],
            [
                "tf",
                "https://www.tensorflow.org/tutorials/reinforcement_learning/actor_critic"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/reinforcement_learning/actor_critic.ipynb",
        "update": 1695852632.0
    },
    {
        "name": "Classify text with BERT",
        "description": "This tutorial contains complete code to fine-tune BERT to perform sentiment analysis on a dataset of plain-text IMDB movie reviews",
        "author": [
            [
                "Anirudh Dubey",
                "https://github.com/anirudh161"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1810.04805"
            ],
            [
                "doi",
                "https://doi.org/10.18653/v1/N19-1423",
                2559
            ],
            [
                "data",
                "https://ai.stanford.edu/~amaas/data/sentiment/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1711.05101"
            ],
            [
                "tf",
                "https://tfhub.dev/google/collections/bert/1"
            ],
            [
                "pwc",
                "https://paperswithcode.com/task/text-classification"
            ],
            [
                "tf",
                "https://www.tensorflow.org/text/tutorials/classify_text_with_bert"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/classify_text_with_bert.ipynb",
        "update": 1691475595.0
    },
    {
        "name": "Image captioning",
        "description": "Given an image our goal is to generate a caption",
        "author": [
            [
                "Kelvin Xu",
                "https://kelvinxu.github.io/"
            ],
            [
                "Jimmy Ba",
                "https://jimmylba.github.io/"
            ],
            [
                "Ryan Kiros",
                "https://github.com/ryankiros"
            ],
            [
                "Kyunghyun Cho",
                "https://kyunghyuncho.me/"
            ],
            [
                "Aaron Courville",
                "https://mila.quebec/en/directory/aaron-courville"
            ],
            [
                "Ruslan Salakhutdinov",
                "https://www.cs.cmu.edu/~rsalakhu/"
            ],
            [
                "Richard Zemel",
                "https://www.cs.columbia.edu/~zemel/"
            ],
            [
                "Yoshua Bengio",
                "https://yoshuabengio.org/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1502.03044"
            ],
            [
                "data",
                "https://cocodataset.org/#home"
            ],
            [
                "tf",
                "https://www.tensorflow.org/text/tutorials/image_captioning"
            ],
            [
                "medium",
                "https://medium.com/@labbikarmacharya/paper-review-show-attend-and-tell-neural-image-caption-generation-with-visual-attention-03928d8fe17b"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/image_captioning.ipynb",
        "update": 1690321814.0
    },
    {
        "name": "NMT with attention",
        "description": "This notebook trains a seq2seq model for Spanish to English translation",
        "author": [
            [
                "Minh-Thang Luong",
                "https://nlp.stanford.edu/~lmthang/"
            ],
            [
                "Hieu Pham",
                "https://huyhieupham.github.io/"
            ],
            [
                "Christopher Manning",
                "https://nlp.stanford.edu/~manning/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1508.04025"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1409.0473"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Neural_machine_translation"
            ],
            [
                "data",
                "http://www.manythings.org/anki/"
            ],
            [
                "tf",
                "https://www.tensorflow.org/text/tutorials/nmt_with_attention"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/nmt_with_attention.ipynb",
        "update": 1676500156.0
    },
    {
        "name": "GLUE using BERT on TPU",
        "description": "This tutorial contains complete end-to-end code to train models on a TPU",
        "author": [
            [
                "Anirudh Dubey",
                "https://github.com/anirudh161"
            ]
        ],
        "links": [
            [
                "GLUE",
                "https://gluebenchmark.com/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1810.04805"
            ],
            [
                "tf",
                "https://www.tensorflow.org/guide/tpu"
            ],
            [
                "tf",
                "https://www.tensorflow.org/text/tutorials/bert_glue"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/bert_glue.ipynb",
        "update": 1676500156.0
    },
    {
        "name": "Text classification with RNN",
        "description": "This text classification tutorial trains a recurrent neural network on the IMDB large movie review dataset for sentiment analysis",
        "author": [
            [
                "Anirudh Dubey",
                "https://github.com/anirudh161"
            ]
        ],
        "links": [
            [
                "link",
                "https://developers.google.com/machine-learning/glossary/#recurrent_neural_network"
            ],
            [
                "data",
                "http://ai.stanford.edu/~amaas/data/sentiment/"
            ],
            [
                "pwc",
                "https://paperswithcode.com/task/text-classification"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/text_classification_rnn.ipynb",
        "update": 1647515329.0
    },
    {
        "name": "Text generation with RNN",
        "description": "This tutorial demonstrates how to generate text using a character-based RNN",
        "author": [
            [
                "Anirudh Dubey",
                "https://github.com/anirudh161"
            ]
        ],
        "links": [
            [
                "link",
                "http://karpathy.github.io/2015/05/21/rnn-effectiveness/"
            ],
            [
                "pwc",
                "https://paperswithcode.com/task/text-generation"
            ],
            [
                "tf",
                "https://www.tensorflow.org/text/tutorials/text_generation"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/text_generation.ipynb",
        "update": 1651535163.0
    },
    {
        "name": "Transformer",
        "description": "This tutorial trains a Transformer model to translate Portuguese to English",
        "author": [
            [
                "Ashish Vaswani",
                "https://en.wikipedia.org/wiki/Ashish_Vaswani"
            ],
            [
                "Noam Shazeer",
                "https://en.wikipedia.org/wiki/Noam_Shazeer"
            ],
            [
                "Niki Parmar",
                "https://scholar.google.com/citations?user=q2YXPSgAAAAJ"
            ],
            [
                "Jakob Uszkoreit",
                "http://jakob.uszkoreit.net/"
            ],
            [
                "Llion Jones",
                "https://scholar.google.com/citations?user=_3_P5VwAAAAJ"
            ],
            [
                "Aidan Gomez",
                "https://aidangomez.ca/"
            ],
            [
                "Łukasz Kaiser",
                "https://scholar.google.com/citations?user=JWmiQR0AAAAJ"
            ],
            [
                "Illia Polosukhin",
                "https://scholar.google.com/citations?user=3SyxFIAAAAAJ"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1706.03762"
            ],
            [
                "link",
                "https://deepmind.com/blog/article/alphastar-mastering-real-time-strategy-game-starcraft-ii"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1903.03878"
            ],
            [
                "git",
                "https://github.com/neulab/word-embeddings-for-nmt",
                121
            ],
            [
                "tf",
                "https://www.tensorflow.org/text/tutorials/transformer"
            ],
            [
                "neurips",
                "https://papers.nips.cc/paper/7181-attention-is-all-you-need"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/transformer.ipynb",
        "update": 1717112439.0
    },
    {
        "name": "Word2Vec",
        "description": "Word2Vec is not a singular algorithm, rather, it is a family of model architectures and optimizations that can be used to learn word embeddings from large datasets",
        "author": [
            [
                "Google",
                "https://www.tensorflow.org/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1301.3781"
            ],
            [
                "neurips",
                "https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf"
            ],
            [
                "projector",
                "http://projector.tensorflow.org/"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Zipf%27s_law"
            ],
            [
                "link",
                "https://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes01-wordvecs1.pdf"
            ],
            [
                "pwc",
                "https://paperswithcode.com/method/cbow-word2vec"
            ],
            [
                "pwc",
                "https://paperswithcode.com/method/skip-gram-word2vec"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/word2vec.ipynb",
        "update": 1690321814.0
    },
    {
        "name": "Word embeddings",
        "description": "This tutorial contains an introduction to word embeddings",
        "author": [
            [
                "Billy Lamberta",
                "https://github.com/lamberta"
            ]
        ],
        "links": [
            [
                "projector",
                "http://projector.tensorflow.org/"
            ],
            [
                "data",
                "http://ai.stanford.edu/~amaas/data/sentiment/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/text/blob/master/docs/guide/word_embeddings.ipynb",
        "update": 1690321813.0
    },
    {
        "name": "Building Your Own Federated Learning Algorithm",
        "description": "We discuss how to implement federated learning algorithms without deferring to the tff.learning API",
        "author": [
            [
                "Zachary Charles",
                "https://zachcharles.com/"
            ]
        ],
        "links": [
            [
                "tf",
                "https://www.tensorflow.org/federated/api_docs/python/tff/learning/Model"
            ],
            [
                "blog post",
                "https://ai.googleblog.com/2020/05/federated-analytics-collaborative-data.html"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1907.08610"
            ],
            [
                "pwc",
                "https://paperswithcode.com/task/federated-learning"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/federated/blob/master/docs/tutorials/building_your_own_federated_learning_algorithm.ipynb",
        "update": 1730482459.0
    },
    {
        "name": "Federated Learning for Image Classification",
        "description": "We use the classic MNIST training example to introduce the Federated Learning API layer of TFF, tff.learning - a set of higher-level interfaces that can be used to perform common types of federated learning tasks, such as federated training, against user-supplied models implemented in TensorFlow",
        "author": [
            [
                "Krzysztof Ostrowski",
                "https://github.com/krzys-ostrowski"
            ]
        ],
        "links": [
            [
                "data",
                "https://www.nist.gov/srd/nist-special-database-19"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1602.05629"
            ],
            [
                "medium",
                "https://medium.com/tensorflow/standardizing-on-keras-guidance-on-high-level-apis-in-tensorflow-2-0-bad2b04c819a"
            ],
            [
                "pwc",
                "https://paperswithcode.com/task/federated-learning"
            ],
            [
                "pwc",
                "https://paperswithcode.com/task/image-classification"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/federated/blob/master/docs/tutorials/federated_learning_for_image_classification.ipynb",
        "update": 1730482459.0
    },
    {
        "name": "Federated Learning for Text Generation",
        "description": "We start with a RNN that generates ASCII characters, and refine it via federated learning",
        "author": [
            [
                "Krzysztof Ostrowski",
                "https://github.com/krzys-ostrowski"
            ]
        ],
        "links": [
            [
                "tf",
                "https://www.tensorflow.org/hub"
            ],
            [
                "data",
                "http://www.ibiblio.org/pub/docs/books/gutenberg/9/98/98.txt"
            ],
            [
                "data",
                "http://www.ibiblio.org/pub/docs/books/gutenberg/4/46/46.txt"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1812.01097"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1602.05629"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/federated/blob/master/docs/tutorials/federated_learning_for_text_generation.ipynb",
        "update": 1730482459.0
    },
    {
        "name": "Custom Federated Algorithms, Part 1: Introduction to the Federated Core",
        "description": "This tutorial is the first part of a two-part series that demonstrates how to implement custom types of federated algorithms in TensorFlow Federated using the Federated Core - a set of lower-level interfaces that serve as a foundation upon which we have implemented the Federated Learning layer",
        "author": [
            [
                "Krzysztof Ostrowski",
                "https://github.com/krzys-ostrowski"
            ]
        ],
        "links": [
            [
                "tf",
                "https://www.tensorflow.org/federated/federated_core"
            ],
            [
                "tf",
                "https://www.tensorflow.org/federated/federated_learning"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1602.05629"
            ],
            [
                "pwc",
                "https://paperswithcode.com/task/federated-learning"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/federated/blob/master/docs/tutorials/custom_federated_algorithms_1.ipynb",
        "update": 1730482459.0
    },
    {
        "name": "Custom Federated Algorithms, Part 2: Implementing Federated Averaging",
        "description": "This tutorial is the second part of a two-part series that demonstrates how to implement custom types of federated algorithms in TFF using the Federated Core, which serves as a foundation for the Federated Learning layer",
        "author": [
            [
                "Krzysztof Ostrowski",
                "https://github.com/krzys-ostrowski"
            ]
        ],
        "links": [
            [
                "tf",
                "https://www.tensorflow.org/federated/federated_core"
            ],
            [
                "tf",
                "https://www.tensorflow.org/federated/federated_learning"
            ],
            [
                "git",
                "https://github.com/tensorflow/federated/blob/master/tensorflow_federated/python/learning/federated_averaging.py",
                2321
            ],
            [
                "pwc",
                "https://paperswithcode.com/task/federated-learning"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/federated/blob/master/docs/tutorials/custom_federated_algorithms_2.ipynb",
        "update": 1730482459.0
    },
    {
        "name": "TFF for Federated Learning Research: Model and Update Compression",
        "description": "We use the EMNIST dataset to demonstrate how to enable lossy compression algorithms to reduce communication cost in the Federated Averaging algorithm",
        "author": [
            [
                "Weikang Song",
                "https://github.com/swkpku"
            ]
        ],
        "links": [
            [
                "tf",
                "https://www.tensorflow.org/federated/api_docs/python/tff/simulation/datasets/emnist"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1602.05629"
            ],
            [
                "tf",
                "https://www.tensorflow.org/federated/api_docs/python/tff/learning/build_federated_averaging_process"
            ],
            [
                "tensor encoding",
                "http://jakubkonecny.com/files/tensor_encoding.pdf"
            ],
            [
                "pwc",
                "https://paperswithcode.com/task/federated-learning"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/federated/blob/master/docs/tutorials/tff_for_federated_learning_research_compression.ipynb",
        "update": 1725572271.0
    },
    {
        "name": "High-performance simulations with TFF",
        "description": "This tutorial will describe how to setup high-performance simulations with TFF in a variety of common scenarios",
        "author": [
            [
                "Krzysztof Ostrowski",
                "https://github.com/krzys-ostrowski"
            ]
        ],
        "links": [
            [
                "pwc",
                "https://paperswithcode.com/task/federated-learning"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/federated/blob/master/docs/tutorials/simulations.ipynb",
        "update": 1730482459.0
    },
    {
        "name": "High-performance Simulation with Kubernetes",
        "description": "This tutorial will describe how to set up high-performance simulation using a TFF runtime running on Kubernetes",
        "author": [
            [
                "Jason Roselander",
                "https://github.com/roselander"
            ]
        ],
        "links": [
            [
                "GKE",
                "https://cloud.google.com/kubernetes-engine/"
            ],
            [
                "shell",
                "https://cloud.google.com/shell/"
            ],
            [
                "pwc",
                "https://paperswithcode.com/task/federated-learning"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/federated/blob/master/docs/tutorials/high_performance_simulation_with_kubernetes.ipynb",
        "update": 1675189866.0
    },
    {
        "name": "Introduction to the TensorFlow Models NLP library",
        "description": "You will learn how to build transformer-based models for common NLP tasks including pretraining, span labelling and classification using the building blocks from NLP modeling library",
        "author": [
            [
                "Chen Chen",
                "https://github.com/chenGitHuber"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/tensorflow/models/tree/master/official/nlp/modeling",
                77243
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1810.04805"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/models/blob/master/official/colab/nlp/nlp_modeling_library_intro.ipynb",
        "update": 1655923595.0
    },
    {
        "name": "TF-Agents",
        "description": "A reliable, scalable and easy to use TensorFlow library for Contextual Bandits and Reinforcement Learning",
        "author": [
            [
                "Sergio Guadarrama",
                "https://github.com/sguada"
            ],
            [
                "Anoop Korattikara",
                "https://github.com/kbanoop"
            ],
            [
                "Oscar Ramirez",
                "https://github.com/oars"
            ],
            [
                "Pablo Castro",
                "https://psc-g.github.io/"
            ],
            [
                "Ethan Holly",
                "https://github.com/eholly-g"
            ],
            [
                "Sam Fishman",
                "http://sam.fish/"
            ],
            [
                "Ke Wang",
                "https://scholar.google.com/citations?user=QRYX59sAAAAJ"
            ],
            [
                "Ekaterina Gonina",
                "https://github.com/egonina"
            ],
            [
                "Neal Wu",
                "https://twitter.com/WuNeal"
            ],
            [
                "Efi Kokiopoulou",
                "https://github.com/efiko"
            ],
            [
                "Luciano Sbaiz",
                "https://scholar.google.com/citations?user=fKBmhcUAAAAJ"
            ],
            [
                "Jamie Smith",
                "https://scholar.google.com/citations?user=jk17mo8AAAAJ"
            ],
            [
                "Gábor Bartók",
                "https://github.com/bartokg"
            ],
            [
                "Jesse Berent",
                "https://www.linkedin.com/in/jesse-berent-a1b6875"
            ],
            [
                "Chris Harris",
                "https://www.linkedin.com/in/charris"
            ],
            [
                "Vincent Vanhoucke",
                "https://vincent.vanhoucke.com/"
            ],
            [
                "Eugene Brevdo",
                "https://ebrevdo.github.io/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/tensorflow/agents",
                2810
            ],
            [
                "docs",
                "https://www.tensorflow.org/agents/api_docs/python/tf_agents"
            ],
            [
                "tf",
                "https://www.tensorflow.org/agents"
            ],
            [
                "yt",
                "https://youtu.be/2nKD6zFQ8xI"
            ],
            [
                "yt",
                "https://youtu.be/-TTziY7EmUA"
            ],
            [
                "yt",
                "https://youtu.be/52DTXidSVWc"
            ],
            [
                "yt",
                "https://youtu.be/U7g7-Jzj9qo"
            ],
            [
                "yt",
                "https://youtu.be/tAOApRQAgpc"
            ],
            [
                "yt",
                "https://youtu.be/X4eruXqNbDc"
            ],
            [
                "yt",
                "https://youtu.be/g0yDlAbi6Pc"
            ],
            [
                "yt",
                "https://youtu.be/VmZI_YkfPBM"
            ],
            [
                "yt",
                "https://youtu.be/7QFSziiAnxI"
            ],
            [
                "medium",
                "https://towardsdatascience.com/introduction-to-tf-agents-a-library-for-reinforcement-learning-in-tensorflow-68ab9add6ad6"
            ],
            [
                "medium",
                "https://medium.com/analytics-vidhya/tf-agents-a-flexible-reinforcement-learning-library-for-tensorflow-5f125420f64b"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/agents/blob/master/docs/tutorials/0_intro_rl.ipynb",
        "update": 1671073571.0
    },
    {
        "name": "Deep-MAC",
        "description": "Welcome to the Novel class segmentation demo",
        "author": [
            [
                "Vighnesh Birodkar",
                "http://vighneshbirodkar.github.io/"
            ]
        ],
        "links": [
            [
                "pwc",
                "https://paperswithcode.com/method/deep-mac"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2104.00613"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/models/blob/master/research/object_detection/colab_tutorials/deepmac_colab.ipynb",
        "update": 1660084213.0
    },
    {
        "name": "TF-Ranking",
        "description": "End-to-end walkthrough of training a TensorFlow Ranking neural network model which incorporates sparse textual features",
        "author": [
            [
                "Rama Kumar",
                "https://github.com/ramakumar1729"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1910.09676"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1812.00073"
            ],
            [
                "data",
                "http://hamedz.ir/resources/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1905.08957"
            ],
            [
                "git",
                "https://github.com/tensorflow/ranking",
                2747
            ],
            [
                "git",
                "https://github.com/tensorflow/serving/blob/master/tensorflow_serving/apis/input.proto#L72"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Mean_reciprocal_rank"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Discounted_cumulative_gain"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1811.04415"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/ranking/blob/master/tensorflow_ranking/examples/handling_sparse_features.ipynb",
        "update": 1612416508.0
    },
    {
        "name": "Tensor2Tensor",
        "description": "Library for deep learning models that is well-suited for neural machine translation and includes the reference implementation of the state-of-the-art Transformer model",
        "author": [
            [
                "Ashish Vaswani",
                "https://scholar.google.com/citations?user=oR9sCGYAAAAJ"
            ],
            [
                "Samy Bengio",
                "https://scholar.google.com/citations?user=Vs-MdPcAAAAJ"
            ],
            [
                "Eugene Brevdo",
                "https://ebrevdo.github.io/"
            ],
            [
                "François Chollet",
                "https://fchollet.com/"
            ],
            [
                "Aidan Gomez",
                "https://gom.ai/"
            ],
            [
                "Stephan Gouws",
                "https://scholar.google.com/citations?user=lLTdYUYAAAAJ"
            ],
            [
                "Llion Jones",
                "https://www.linkedin.com/in/llion-jones-9ab3064b"
            ],
            [
                "Łukasz Kaiser",
                "https://scholar.google.com/citations?user=JWmiQR0AAAAJ"
            ],
            [
                "Nal Kalchbrenner",
                "https://www.nal.ai/"
            ],
            [
                "Niki Parmar",
                "https://github.com/nikiparmar"
            ],
            [
                "Ryan Sepassi",
                "https://ryansepassi.com/"
            ],
            [
                "Noam Shazeer",
                "https://github.com/nshazeer"
            ],
            [
                "Jakob Uszkoreit",
                "https://scholar.google.com/citations?user=mOG0bwsAAAAJ"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/tensorflow/tensor2tensor",
                15623
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1803.07416"
            ],
            [
                "blog post",
                "https://ai.googleblog.com/2017/06/accelerating-deep-learning-research.html"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1812.02825"
            ],
            [
                "data",
                "https://research.fb.com/downloads/babi/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1706.03762"
            ],
            [
                "tf",
                "https://tensorflow.github.io/tensor2tensor/cloud_mlengine.html"
            ],
            [
                "tf",
                "https://tensorflow.github.io/tensor2tensor/cloud_tpu.html"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1706.03059"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1706.05137"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1801.09797"
            ],
            [
                "yt",
                "https://youtu.be/O2UvKxaOH7c"
            ],
            [
                "yt",
                "https://youtu.be/VYQ8n3Besrw"
            ],
            [
                "yt",
                "https://youtu.be/cS2UZKHq4i4"
            ],
            [
                "medium",
                "https://towardsdatascience.com/tensor2tensor-and-one-model-to-learn-them-all-7ef3f9b61ba4"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/Transformer_translate.ipynb",
        "update": 1579031124.0
    },
    {
        "name": "Lingvo",
        "description": "Framework for building neural networks in Tensorflow, particularly sequence models",
        "author": [
            [
                "Jonathan Shen",
                "https://github.com/jonathanasdf"
            ],
            [
                "Patrick Nguyen",
                "https://scholar.google.com/citations?user=38fqeIYAAAAJ"
            ],
            [
                "Yonghui Wu",
                "https://scholar.google.com/citations?user=55FnA9wAAAAJ"
            ],
            [
                "Zhifeng Chen",
                "https://github.com/zffchen78"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/tensorflow/lingvo",
                2818
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1902.08295"
            ],
            [
                "docker",
                "https://github.com/tensorflow/lingvo/blob/master/docker/dev.Dockerfile"
            ],
            [
                "docker",
                "https://github.com/tensorflow/lingvo/blob/master/docker/lib.dockerfile"
            ],
            [
                "docs",
                "https://tensorflow.github.io/lingvo/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1508.01211"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1412.1602"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1602.02410"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2006.16668"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2106.04060"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/lingvo/blob/master/codelabs/introduction.ipynb",
        "update": 1643404828.0
    },
    {
        "name": "TensorFlow Graphics",
        "description": "Differentiable computer graphics in tensorflow",
        "author": [
            [
                "Julien Valentin",
                "https://github.com/julienvalentin"
            ],
            [
                "Cem Keskin",
                "https://github.com/cem-keskin"
            ],
            [
                "Pavel Pidlypenskyi",
                "https://github.com/podlipensky"
            ],
            [
                "Ameesh Makadia",
                "https://github.com/amakadia"
            ],
            [
                "Avneesh Sud",
                "https://github.com/avneesh-g"
            ],
            [
                "Sofien Bouaziz",
                "http://sofienbouaziz.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/tensorflow/graphics",
                2756
            ],
            [
                "twitter",
                "https://twitter.com/_TFGraphics_"
            ],
            [
                "tf",
                "https://www.tensorflow.org/graphic"
            ],
            [
                "doi",
                "https://doi.org/10.1145/3450508.3464595",
                0
            ],
            [
                "medium",
                "https://medium.com/syncedreview/computer-graphics-computer-vision-tensorflow-graphics-110e955e26bb"
            ],
            [
                "yt",
                "https://youtu.be/Un0JDL3i5Hg"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/graphics/blob/master/tensorflow_graphics/notebooks/6dof_alignment.ipynb",
        "update": 1590008479.0
    },
    {
        "name": "TensorBoard",
        "description": "Suite of web applications for inspecting and understanding your TensorFlow runs and graphs",
        "author": [
            [
                "Yuan Tang",
                "https://terrytangyuan.github.io/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/tensorflow/tensorboard",
                6733
            ],
            [
                "tf",
                "https://www.tensorflow.org/tensorboard/get_started"
            ],
            [
                "website",
                "https://tensorboard.dev/"
            ],
            [
                "tf",
                "https://www.tensorflow.org/api_docs/python/tf/summary"
            ],
            [
                "tf",
                "https://www.tensorflow.org/api_docs/python/tf/linalg/matmul"
            ],
            [
                "tf",
                "https://www.tensorflow.org/api_docs/python/tf/nn/relu"
            ],
            [
                "git",
                "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/supervisor.py"
            ],
            [
                "tf",
                "https://www.tensorflow.org/api_docs/python/tf/compat/v1/train/summary_iterator"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Reservoir_sampling"
            ],
            [
                "yt",
                "https://youtu.be/eBbEDRsCmv4"
            ],
            [
                "yt",
                "https://youtu.be/BqgTU7_cBnk"
            ],
            [
                "yt",
                "https://youtu.be/qEQ-_EId-D0"
            ],
            [
                "yt",
                "https://youtu.be/3bownM3L5zM"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/tensorboard/blob/master/docs/scalars_and_keras.ipynb",
        "update": 1676042855.0
    },
    {
        "name": "Hello, many worlds",
        "description": "This tutorial shows how a classical neural network can learn to correct qubit calibration errors",
        "author": [
            [
                "Michael Broughton",
                "https://github.com/MichaelBroughton"
            ]
        ],
        "links": [
            [
                "tf",
                "https://www.tensorflow.org/quantum/api_docs/python/tfq/layers"
            ],
            [
                "tf",
                "https://www.tensorflow.org/quantum/api_docs/python/tfq/get_expectation_op"
            ],
            [
                "tf",
                "https://www.tensorflow.org/guide/keras/functional"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Pauli_matrices"
            ],
            [
                "yt",
                "https://youtu.be/-o9AhIz1uvo"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/quantum/blob/master/docs/tutorials/hello_many_worlds.ipynb",
        "update": 1715967948.0
    },
    {
        "name": "TFDS",
        "description": "Collection of ready-to-use datasets for use with TensorFlow, Jax, and other Machine Learning frameworks",
        "author": [
            [
                "Google",
                "https://www.tensorflow.org/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/tensorflow/datasets",
                4325
            ],
            [
                "tf",
                "https://www.tensorflow.org/datasets"
            ],
            [
                "yt",
                "https://youtu.be/YrMy-BAqk8k"
            ],
            [
                "yt",
                "https://youtu.be/6th3rahsw9Y"
            ],
            [
                "yt",
                "https://youtu.be/3HYy0SPd7TE"
            ],
            [
                "yt",
                "https://youtu.be/MvcK-MaXbHk"
            ],
            [
                "medium",
                "https://towardsdatascience.com/youre-importing-data-wrong-c171f52eea00"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/datasets/blob/master/docs/overview.ipynb",
        "update": 1681214657.0
    },
    {
        "name": "TPU",
        "description": "Reference models and tools for Cloud TPUs",
        "author": [
            [
                "Google",
                "https://cloud.google.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/tensorflow/tpu",
                5216
            ],
            [
                "website",
                "https://cloud.google.com/tpu/"
            ],
            [
                "yt",
                "https://youtu.be/W7A-9MYvPwI"
            ],
            [
                "yt",
                "https://youtu.be/MXxN4fv01c8"
            ],
            [
                "yt",
                "https://youtu.be/FsxthdQ_sL4"
            ],
            [
                "yt",
                "https://youtu.be/zEOtG-ChmZE"
            ],
            [
                "yt",
                "https://youtu.be/kBjYK3K3P6M"
            ],
            [
                "yt",
                "https://youtu.be/8j1MWZGNoXM"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Tensor_Processing_Unit"
            ],
            [
                "yt",
                "https://youtu.be/hszd5UqnfLk"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/keras_mnist_tpu.ipynb",
        "update": 1671555380.0
    },
    {
        "name": "GNN",
        "description": "Production-tested library for building GNNs at large scale",
        "author": [
            [
                "Oleksandr Ferludin",
                "https://github.com/aferludin"
            ],
            [
                "Arno Eigenwillig",
                "https://github.com/arnoegw"
            ],
            [
                "Martin Blais",
                "https://github.com/blais"
            ],
            [
                "Dustin Zelle",
                "https://github.com/dzelle"
            ],
            [
                "Jan Pfeifer",
                "https://github.com/janpfeifer"
            ],
            [
                "Alvaro Sanchez-Gonzalez",
                "https://github.com/alvarosg"
            ],
            [
                "Wai Lok Sibon Li",
                "https://scholar.google.com/citations?user=qX9aUx8AAAAJ"
            ],
            [
                "Sami Abu-El-Haija",
                "https://samihaija.github.io/"
            ],
            [
                "Peter Battaglia",
                "https://scholar.google.com/citations?user=nQ7Ij30AAAAJ"
            ],
            [
                "Neslihan Bulut",
                "https://scholar.google.com/citations?user=k_cadGsAAAAJ"
            ],
            [
                "Jonathan Halcrow",
                "https://scholar.google.com/citations?user=2zZucy4AAAAJ"
            ],
            [
                "Filipe Miguel Gonçalves de Almeida",
                "https://github.com/fmgda"
            ],
            [
                "Pedro Gonnet",
                "https://research.google/people/pedro-gonnet/"
            ],
            [
                "Liangze Jiang",
                "https://liangzejiang.github.io/"
            ],
            [
                "Parth Kothari",
                "https://thedebugger811.github.io/"
            ],
            [
                "Silvio Lattanzi",
                "https://sites.google.com/site/silviolattanzi/"
            ],
            [
                "André Linhares",
                "https://scholar.google.com/citations?user=YYRnhTkAAAAJ"
            ],
            [
                "Brandon Mayer",
                "https://github.com/brandonmayer-zz"
            ],
            [
                "Vahab Mirrokni",
                "https://people.csail.mit.edu/mirrokni/Welcome.html"
            ],
            [
                "John Palowitch",
                "http://ml.johnpalowitch.com/"
            ],
            [
                "Mihir Paradkar",
                "https://www.linkedin.com/in/mihir-paradkar-22b88579"
            ],
            [
                "Jennifer She",
                "https://scholar.google.com/citations?user=Gjf_sd0AAAAJ"
            ],
            [
                "Anton Tsitsulin",
                "https://tsitsul.in/"
            ],
            [
                "Kevin Villela",
                "https://www.linkedin.com/in/kevin-villela-612a6443"
            ],
            [
                "Lisa Wang",
                "https://scholar.google.com/citations?user=5KmYPkIAAAAJ"
            ],
            [
                "Bryan Perozzi",
                "http://www.perozzi.net/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/tensorflow/gnn",
                1372
            ],
            [
                "tf",
                "https://blog.tensorflow.org/2024/02/graph-neural-networks-in-tensorflow.html"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2207.03522"
            ],
            [
                "tf",
                "https://blog.tensorflow.org/2021/11/introducing-tensorflow-gnn.html"
            ],
            [
                "medium",
                "https://medium.com/@techtes.com/getting-started-with-tf-gnn-with-python-26d8e341db05"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/code/fidels/introduction-to-tf-gnn"
            ],
            [
                "yt",
                "https://www.youtube.com/playlist?list=PL2PZTwLd0HMJC1fU_NkwwpRkcjoGqAECX"
            ],
            [
                "yt",
                "https://youtu.be/JqWROPYeqjA"
            ],
            [
                "yt",
                "https://youtu.be/YdGN-J322y4"
            ],
            [
                "yt",
                "https://youtu.be/VDzrvhgyxsU"
            ],
            [
                "yt",
                "https://www.youtube.com/live/e6WHg1l7AMs"
            ],
            [
                "yt",
                "https://youtu.be/a75Q6dtg1_s"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tensorflow/gnn/blob/master/examples/notebooks/graph_network_shortest_path.ipynb",
        "update": 1723201699.0
    },
    {
        "name": "TensorFlowTTS",
        "description": "Real-time state-of-the-art speech synthesis architectures such as Tacotron-2, Melgan, Multiband-Melgan, FastSpeech, FastSpeech2 based-on TensorFlow 2",
        "author": [
            [
                "Minh Nguyen Quan Anh",
                "https://github.com/dathudeptrai"
            ],
            [
                "Eren Gölge",
                "https://github.com/erogol"
            ],
            [
                "Kuan Chen",
                "https://github.com/azraelkuan"
            ],
            [
                "Takuya Ebata",
                "https://github.com/MokkeMeguru"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/TensorSpeech/TensorFlowTTS",
                3850
            ],
            [
                "project",
                "https://tensorspeech.github.io/TensorFlowTTS/"
            ],
            [
                "tf",
                "https://www.tensorflow.org/model_optimization/guide/quantization/training_comprehensive_guide"
            ],
            [
                "tf",
                "https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras"
            ],
            [
                "hf",
                "https://huggingface.co/spaces/akhaliq/TensorFlowTTS"
            ],
            [
                "hf",
                "https://huggingface.co/tensorspeech"
            ],
            [
                "git",
                "https://github.com/thorstenMueller/Thorsten-Voice"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/datasets/bryanpark/korean-single-speaker-speech-dataset"
            ],
            [
                "pypi",
                "https://pypi.org/project/TensorFlowTTS/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/TensorSpeech/TensorFlowTTS/blob/master/notebooks/TensorFlowTTS_FastSpeech_with_TFLite.ipynb",
        "update": 1622544338.0
    },
    {
        "name": "Train a GPT-2 Text-Generating Model",
        "description": "Retrain an advanced text generating neural network on any text dataset for free on a GPU using Colaboratory using aitextgen!",
        "author": [
            [
                "Max Woolf",
                "https://minimaxir.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/minimaxir/aitextgen",
                1843
            ],
            [
                "docs",
                "https://docs.aitextgen.io/"
            ],
            [
                "data",
                "https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
            ],
            [
                "pwc",
                "https://paperswithcode.com/task/text-generation"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/15qBZx5y9rdaQSyWpsreMDnTiZ5IlN0zD",
        "update": 1621222440.007
    },
    {
        "name": "Custom GPT-2 + Tokenizer",
        "description": "Train a custom GPT-2 model for free on a GPU using aitextgen!",
        "author": [
            [
                "Max Woolf",
                "https://minimaxir.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/minimaxir/aitextgen",
                1843
            ],
            [
                "docs",
                "https://docs.aitextgen.io/"
            ],
            [
                "data",
                "https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/144MdX5aLqrQ3-YW-po81CQMrD6kpgpYh",
        "update": 1621222464.69
    },
    {
        "name": "textgenrnn",
        "description": "Generate text using a pretrained neural network with a few lines of code, or easily train your own text-generating neural network of any size and complexity",
        "author": [
            [
                "Max Woolf",
                "https://minimaxir.com/"
            ]
        ],
        "links": [
            [
                "blog post",
                "http://minimaxir.com/2018/05/text-neural-networks/"
            ],
            [
                "yt",
                "https://www.youtube.com/watch?v=RW7mP6BfZuY"
            ],
            [
                "git",
                "https://github.com/minimaxir/textgenrnn",
                4944
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1mMKGnVxirJnqDViH7BDJxFqWrsXlPSoK",
        "update": 1626144610.804
    },
    {
        "name": "YOLOv4",
        "description": "This tutorial will help you build YOLOv4 easily in the cloud with GPU enabled so that you can run object detections in milliseconds!",
        "author": [
            [
                "Alexey Bochkovskiy",
                "http://www.alexeyab.com/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2004.10934"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2011.08036"
            ],
            [
                "git",
                "https://github.com/AlexeyAB/darknet",
                21800
            ],
            [
                "project",
                "https://pjreddie.com/darknet/"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/MachineLearning/comments/gydxzd/p_yolov4_the_most_accurate_realtime_neural/"
            ],
            [
                "medium",
                "https://alexeyab84.medium.com/yolov4-the-most-accurate-real-time-neural-network-on-ms-coco-dataset-73adfd3602fe"
            ],
            [
                "medium",
                "https://alexeyab84.medium.com/scaled-yolo-v4-is-the-best-neural-network-for-object-detection-on-ms-coco-dataset-39dfa22fa982"
            ],
            [
                "yt",
                "https://youtu.be/1_SiUOYUoOI"
            ],
            [
                "yt",
                "https://youtu.be/YDFf-TqJOFE"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1_GdoqCJWXsChrOiY8sZMr_zbr_fH-0Fg",
        "update": 1593048824.334
    },
    {
        "name": "YOLOv3",
        "description": "You Only Look Once",
        "author": [
            [
                "Glenn Jocher",
                "https://github.com/glenn-jocher"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/ultralytics/yolov3",
                10250
            ],
            [
                "kaggle",
                "https://www.kaggle.com/ultralytics/yolov3"
            ],
            [
                "data",
                "http://cocodataset.org/#upload"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/ultralytics/coco128"
            ]
        ],
        "colab": "https://colab.research.google.com/github/ultralytics/yolov3/blob/master/tutorial.ipynb",
        "update": 1729352748.0
    },
    {
        "name": "YOLOv5",
        "description": "You Only Look Once",
        "author": [
            [
                "Glenn Jocher",
                "https://github.com/glenn-jocher"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/ultralytics/yolov5",
                51257
            ],
            [
                "kaggle",
                "https://www.kaggle.com/ultralytics/yolov5"
            ],
            [
                "data",
                "http://cocodataset.org/#upload"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/ultralytics/coco128"
            ]
        ],
        "colab": "https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb",
        "update": 1729352771.0
    },
    {
        "name": "YOLOv8",
        "description": "State-of-the-art model that builds upon the success of previous YOLO versions and introduces new features and improvements to further boost performance and flexibility",
        "author": [
            [
                "Glenn Jocher",
                "https://github.com/glenn-jocher"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/ultralytics/ultralytics",
                33515
            ],
            [
                "docker",
                "https://hub.docker.com/r/ultralytics/ultralytics"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/ultralytics/yolov8"
            ],
            [
                "docs",
                "https://docs.ultralytics.com/"
            ],
            [
                "discord",
                "https://ultralytics.com/discord"
            ],
            [
                "twitter",
                "https://twitter.com/ultralytics"
            ],
            [
                "yt",
                "https://youtube.com/ultralytics"
            ],
            [
                "COCO",
                "http://cocodataset.org/"
            ],
            [
                "ImageNet",
                "https://www.image-net.org/"
            ],
            [
                "yt",
                "https://youtu.be/m9fH9OWn8YM"
            ],
            [
                "yt",
                "https://youtu.be/wuZtUMEiKWY"
            ],
            [
                "yt",
                "https://youtu.be/gRAyOPjQ9_s"
            ],
            [
                "yt",
                "https://youtu.be/fhzCwJkDONE"
            ],
            [
                "yt",
                "https://youtu.be/IHbJcOex6dk"
            ],
            [
                "blog post",
                "https://habr.com/ru/articles/710016/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/ultralytics/ultralytics/blob/main/examples/tutorial.ipynb",
        "update": 1733249230.0
    },
    {
        "name": "YOLOv5 on Custom Objects",
        "description": "This notebook shows training on your own custom objects",
        "author": [
            [
                "Jacob Solawetz",
                "https://blog.roboflow.com/author/jacob/"
            ]
        ],
        "links": [
            [
                "blog post",
                "https://blog.roboflow.com/how-to-train-yolov5-on-a-custom-dataset/"
            ],
            [
                "data",
                "https://public.roboflow.ai/object-detection/bccd"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1gDZ2xcTOgR39tGGs-EZ6i3RTs16wmzZQ",
        "update": 1658345581.74
    },
    {
        "name": "Python Data Science Handbook",
        "description": "Jupyter notebook version of the Python Data Science Handbook by Jake VanderPlas",
        "author": [
            [
                "Jake Vanderplas",
                "http://vanderplas.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/jakevdp/PythonDataScienceHandbook",
                43371
            ],
            [
                "project",
                "https://jakevdp.github.io/PythonDataScienceHandbook/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/Index.ipynb",
        "update": 1683328845.0
    },
    {
        "name": "TensorNetwork",
        "description": "A library for easy and efficient manipulation of tensor networks",
        "author": [
            [
                "Chase Roberts",
                "http://thenerdstation.github.io/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/google/TensorNetwork",
                1823
            ],
            [
                "yt",
                "https://www.youtube.com/watch?v=YN2YBB0viKo"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1708.00006"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1306.2164"
            ],
            [
                "docs",
                "https://tensornetwork.readthedocs.io/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/google/TensorNetwork/blob/master/colabs/Tensor_Networks_in_Neural_Networks.ipynb",
        "update": 1611192277.0
    },
    {
        "name": "BIG-bench",
        "description": "A collaborative benchmark intended to probe large language models and extrapolate their future capabilities",
        "author": [
            [
                "Jaehoon Lee",
                "https://jaehlee.github.io/"
            ],
            [
                "Jascha Sohl-Dickstein",
                "http://www.sohldickstein.com/"
            ],
            [
                "Vinay Ramasesh",
                "https://ramasesh.github.io/"
            ],
            [
                "Sajant Anand",
                "https://github.com/sajantanand"
            ],
            [
                "Alicia Parrish",
                "https://aliciaparrish.com/"
            ],
            [
                "Ethan Dyer",
                "https://github.com/ethansdyer"
            ],
            [
                "Liam Dugan",
                "http://liamdugan.com/"
            ],
            [
                "Dieuwke Hupkes",
                "https://github.com/dieuwkehupkes"
            ],
            [
                "Daniel Freeman",
                "https://github.com/cdfreeman-google"
            ],
            [
                "Guy Gur-Ari",
                "https://github.com/guygurari"
            ],
            [
                "Aitor Lewkowycz",
                "https://github.com/lewkowycz"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2206.04615"
            ],
            [
                "git",
                "https://github.com/google/BIG-bench",
                2887
            ],
            [
                "API",
                "https://google.github.io/BIG-bench/docs/html/bigbench/index.html"
            ]
        ],
        "colab": "https://colab.research.google.com/github/google/BIG-bench/blob/master/notebooks/colab_examples.ipynb",
        "update": 1656367904.0
    },
    {
        "name": "The Autodiff Cookbook",
        "description": "You'll go through a whole bunch of neat autodiff ideas that you can cherry pick for your own work, starting with the basics",
        "author": [
            [
                "Alex Wiltschko",
                "https://github.com/alexbw"
            ],
            [
                "Matthew Johnson",
                "http://people.csail.mit.edu/mattjj/"
            ]
        ],
        "links": [
            [
                "book",
                "https://mitpress.mit.edu/sites/default/files/titles/content/sicm_edition_2/book.html"
            ],
            [
                "book",
                "https://mitpress.mit.edu/books/functional-differential-geometry"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Truncated_Newton_method"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Pullback_(differential_geometry)"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Holomorphic_function"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Cauchy%E2%80%93Riemann_equations"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1406.2572"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1706.04454"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1802.03451"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1811.07062"
            ],
            [
                "tutorial",
                "http://videolectures.net/deeplearning2017_johnson_automatic_differentiation/"
            ],
            [
                "git",
                "https://github.com/google/jax/issues/446#issuecomment-467105048",
                30661
            ],
            [
                "git",
                "https://github.com/google/jax#auto-vectorization-with-vmap"
            ],
            [
                "git",
                "https://github.com/hips/autograd"
            ]
        ],
        "colab": "https://colab.research.google.com/github/google/jax/blob/main/docs/notebooks/autodiff_cookbook.ipynb",
        "update": 1726843953.0
    },
    {
        "name": "EfficientNetV2",
        "description": "A family of image classification models, which achieve better parameter efficiency and faster training speed than prior arts",
        "author": [
            [
                "Mingxing Tan",
                "https://scholar.google.com/citations?user=6POeyBoAAAAJ"
            ],
            [
                "Quoc Le",
                "https://cs.stanford.edu/~quocle/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2104.00298"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1905.11946"
            ],
            [
                "git",
                "https://github.com/google/automl/tree/master/efficientnetv2",
                6266
            ],
            [
                "git",
                "https://github.com/NVIDIA/TensorRT/tree/master/samples/python/efficientnet"
            ]
        ],
        "colab": "https://colab.research.google.com/github/google/automl/blob/master/efficientnetv2/tutorial.ipynb",
        "update": 1632453890.0
    },
    {
        "name": "EfficientDet",
        "description": "New family of object detectors, called EfficientDet, which consistently achieve much better efficiency than prior art across a wide spectrum of resource constraints",
        "author": [
            [
                "Mingxing Tan",
                "https://scholar.google.com/citations?user=6POeyBoAAAAJ"
            ],
            [
                "Ruoming Pang",
                "https://scholar.google.com/citations?user=1fsmwB8AAAAJ"
            ],
            [
                "Quoc Le",
                "https://cs.stanford.edu/~quocle/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1911.09070"
            ],
            [
                "doi",
                "https://doi.org/10.1109/CVPR42600.2020.01079",
                4217
            ],
            [
                "git",
                "https://github.com/google/automl/tree/master/efficientdet",
                6266
            ],
            [
                "tf",
                "https://tfhub.dev/s?network-architecture=efficientdet"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2103.13886"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1905.11946"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1804.02767"
            ],
            [
                "tutorial",
                "https://cloud.google.com/tpu/docs/tutorials/efficientnet"
            ],
            [
                "medium",
                "https://medium.com/tensorflow/fitting-larger-networks-into-memory-583e3c758ff9"
            ],
            [
                "blog post",
                "https://ai.googleblog.com/2020/04/efficientdet-towards-scalable-and.html"
            ],
            [
                "yt",
                "https://youtu.be/yJg1FX2goCo"
            ],
            [
                "yt",
                "https://youtu.be/OsA3zH5NKYc"
            ],
            [
                "yt",
                "https://youtu.be/qZobxWXlJ0g"
            ]
        ],
        "colab": "https://colab.research.google.com/github/google/automl/blob/master/efficientdet/tf2/tutorial.ipynb",
        "update": 1664300124.0
    },
    {
        "name": "SentencePiece",
        "description": "An unsupervised text tokenizer and detokenizer mainly for Neural Network-based text generation systems where the vocabulary size is predetermined prior to the neural model training",
        "author": [
            [
                "Taku Kudo",
                "http://chasen.org/~taku/"
            ],
            [
                "John Richardson",
                "https://scholar.google.com/citations?user=PEvmYfgAAAAJ"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1808.06226"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1508.07909"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1804.10959"
            ],
            [
                "git",
                "https://github.com/google/sentencepiece",
                10337
            ],
            [
                "git",
                "https://github.com/moses-smt/mosesdecoder/blob/master/scripts/tokenizer/tokenizer.perl"
            ],
            [
                "git",
                "https://github.com/rsennrich/subword-nmt"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1910.13267"
            ],
            [
                "medium",
                "https://jacky2wong.medium.com/understanding-sentencepiece-under-standing-sentence-piece-ac8da59f6b08"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1609.08144"
            ],
            [
                "git",
                "https://github.com/gperftools/gperftools"
            ],
            [
                "git",
                "https://github.com/Microsoft/vcpkg"
            ],
            [
                "yt",
                "https://youtu.be/U51ranzJBpY"
            ]
        ],
        "colab": "https://colab.research.google.com/github/google/sentencepiece/blob/master/python/sentencepiece_python_module_example.ipynb",
        "update": 1716320482.0
    },
    {
        "name": "Analyzing Tennis Serve",
        "description": "We'll use the Video Intelligence API to analyze a tennis serve, including the angle of the arms and legs during the serve",
        "author": [
            [
                "Dale Markowitz",
                "https://daleonai.com/"
            ]
        ],
        "links": [
            [
                "blog post",
                "https://daleonai.com/machine-learning-for-sports"
            ],
            [
                "git",
                "https://github.com/google/making_with_ml/tree/master/sports_ai",
                344
            ],
            [
                "medium",
                "https://manivannan-ai.medium.com/find-the-angle-between-three-points-from-2d-using-python-348c513e2cd"
            ],
            [
                "yt",
                "https://www.youtube.com/watch?v=yLrOy2Xedgk"
            ]
        ],
        "colab": "https://colab.research.google.com/github/google/making_with_ml/blob/master/sports_ai/Sports_AI_Analysis.ipynb",
        "update": 1594756419.0
    },
    {
        "name": "Brax",
        "description": "A differentiable physics engine that simulates environments made up of rigid bodies, joints, and actuators",
        "author": [
            [
                "Daniel Freeman",
                "https://github.com/cdfreeman-google"
            ],
            [
                "Erik Frey",
                "https://fawx.com/"
            ],
            [
                "Anton Raichuk",
                "https://scholar.google.com/citations?user=fquIpvgAAAAJ"
            ],
            [
                "Sertan Girgin",
                "https://sites.google.com/site/girgint/home"
            ],
            [
                "Igor Mordatch",
                "https://scholar.google.com/citations?user=Vzr1RukAAAAJ"
            ],
            [
                "Olivier Bachem",
                "http://olivierbachem.ch/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/google/brax",
                2381
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2106.13281"
            ],
            [
                "neurips",
                "https://neurips.cc/Conferences/2021/CallForDatasetsBenchmarks"
            ]
        ],
        "colab": "https://colab.research.google.com/github/google/brax/blob/main/notebooks/basics.ipynb",
        "update": 1717776765.0
    },
    {
        "name": "Trax",
        "description": "End-to-end library for deep learning that focuses on clear code and speed",
        "author": [
            [
                "Google",
                "https://research.google/teams/brain/"
            ]
        ],
        "links": [
            [
                "docs",
                "https://trax-ml.readthedocs.io/en/latest/"
            ],
            [
                "git",
                "https://github.com/google/trax",
                8112
            ],
            [
                "kaggle",
                "https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1910.00177"
            ],
            [
                "tf",
                "https://www.tensorflow.org/datasets/catalog/overview"
            ],
            [
                "discuss",
                "https://groups.google.com/u/1/g/trax-discuss"
            ],
            [
                "tf",
                "https://tensorflow.org/guide/tf_numpy"
            ],
            [
                "yt",
                "https://youtu.be/qlTsaHAtJBY"
            ],
            [
                "medium",
                "https://towardsdatascience.com/get-started-with-google-trax-for-nlp-ff8dcd3119cf"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/code/dschettler8845/exploration-of-trax-framework"
            ],
            [
                "medium",
                "https://medium.com/analytics-vidhya/brief-view-of-googles-trax-library-b78eae008cb6"
            ]
        ],
        "colab": "https://colab.research.google.com/github/google/trax/blob/master/trax/intro.ipynb",
        "update": 1613603836.0
    },
    {
        "name": "Flax",
        "description": "Neural network library and ecosystem for JAX designed for flexibility",
        "author": [
            [
                "Jonathan Heek",
                "https://github.com/jheek"
            ],
            [
                "Anselm Levskaya",
                "https://anselmlevskaya.com/"
            ],
            [
                "Avital Oliver",
                "https://github.com/avital"
            ],
            [
                "Marvin Ritter",
                "https://github.com/Marvin182"
            ],
            [
                "Bertrand Rondepierre",
                "https://github.com/BertrandRdp"
            ],
            [
                "Andreas Steiner",
                "https://github.com/andsteing"
            ],
            [
                "Marc van Zee",
                "https://research.google/people/marc-van-zee/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/google/flax",
                6171
            ],
            [
                "docs",
                "https://flax.readthedocs.io/"
            ],
            [
                "hf",
                "https://github.com/huggingface/transformers/tree/main/examples/flax"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/MachineLearning/comments/erpdf7/p_flax_a_neural_network_library_for_jax_designed/"
            ],
            [
                "medium",
                "https://medium.com/syncedreview/google-introduces-flax-a-neural-network-library-for-jax-84bdc6f8f160"
            ],
            [
                "yt",
                "https://youtu.be/e8StU6WQCqw"
            ],
            [
                "yt",
                "https://youtu.be/HOlQzrn84A4"
            ],
            [
                "yt",
                "https://youtu.be/5eUSmJvK8WA"
            ]
        ],
        "colab": "https://colab.research.google.com/github/google/flax/blob/main/docs/quick_start.ipynb",
        "update": 1704850635.0
    },
    {
        "name": "Dopamine",
        "description": "Research framework for fast prototyping of reinforcement learning algorithms",
        "author": [
            [
                "Pablo Castro",
                "https://psc-g.github.io/"
            ],
            [
                "Subhodeep Moitra",
                "http://www.deepmoitra.com/"
            ],
            [
                "Carles Gelada",
                "https://github.com/cgel"
            ],
            [
                "Saurabh Kumar",
                "https://scholar.google.com/citations?user=Rkr2uT8AAAAJ"
            ],
            [
                "Marc Bellemare",
                "http://www.marcgbellemare.info/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/google/dopamine",
                10583
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1812.06110"
            ],
            [
                "docs",
                "https://google.github.io/dopamine/docs/"
            ],
            [
                "baselines",
                "https://google.github.io/dopamine/baselines/"
            ],
            [
                "docker",
                "https://google.github.io/dopamine/docker/"
            ],
            [
                "git",
                "https://github.com/openai/atari-py#roms"
            ],
            [
                "git",
                "https://github.com/openai/mujoco-py#install-mujoco"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1511.05952"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1812.05905"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1806.06923"
            ],
            [
                "medium",
                "https://medium.com/the-21st-century/google-dopamine-new-rl-framework-f84a35b7fb3f"
            ],
            [
                "blog post",
                "https://opensource.googleblog.com/2019/02/dopamine-2.0.html"
            ],
            [
                "yt",
                "https://www.youtube.com/live/FWFoyFjeAaM?feature=share"
            ],
            [
                "yt",
                "https://youtu.be/bd4CsDp00RA"
            ]
        ],
        "colab": "https://colab.research.google.com/github/google/dopamine/blob/master/dopamine/colab/jax_agent_visualizer.ipynb",
        "update": 1596498663.0
    },
    {
        "name": "Gin Config",
        "description": "Lightweight configuration framework for Python, based on dependency injection",
        "author": [
            [
                "Dan Holtmann-Rice",
                "https://github.com/dhr"
            ],
            [
                "Sergio Guadarrama",
                "https://github.com/sguada"
            ],
            [
                "Nathan Silberman",
                "http://nsilberman.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/google/gin-config",
                2068
            ],
            [
                "medium",
                "https://towardsdatascience.com/stop-worrying-about-configs-with-gin-218562dd5c91"
            ]
        ],
        "colab": "https://colab.research.google.com/github/google/gin-config/blob/master/gin/gin_intro.ipynb",
        "update": 1597302744.0
    },
    {
        "name": "Batch RL",
        "description": "Offline RL using the DQN replay dataset comprising the entire replay experience of a DQN agent on 60 Atari 2600 games",
        "author": [
            [
                "Rishabh Agarwal",
                "https://agarwl.github.io/"
            ],
            [
                "Dale Schuurmans",
                "https://webdocs.cs.ualberta.ca/~dale/"
            ],
            [
                "Mohammad Norouzi",
                "https://norouzi.github.io/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/google-research/batch_rl",
                536
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1907.04543"
            ],
            [
                "project",
                "https://offline-rl.github.io/"
            ],
            [
                "git",
                "https://github.com/openai/atari-py/tree/0.2.5/atari_py/atari_roms"
            ],
            [
                "git",
                "https://github.com/mgbellemare/Arcade-Learning-Environment"
            ],
            [
                "DQN",
                "https://www.nature.com/articles/nature14236?wm=book_wap_0005"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1709.06009"
            ],
            [
                "data",
                "https://console.cloud.google.com/storage/browser/atari-replay-datasets"
            ],
            [
                "tf",
                "https://www.tensorflow.org/install/install_linux"
            ],
            [
                "blog post",
                "https://ai.googleblog.com/2020/04/an-optimistic-perspective-on-offline.html"
            ],
            [
                "talk",
                "https://slideslive.com/38928373/an-optimistic-perspective-on-offline-deep-reinforcement-learning"
            ],
            [
                "git",
                "https://github.com/mila-iqia/SGI/blob/master/src/offline_dataset.py"
            ],
            [
                "git",
                "https://github.com/kzl/decision-transformer/tree/master/atari"
            ],
            [
                "slides",
                "https://docs.google.com/presentation/d/1ROltXr6FIeYKrnGl0tKHGWI0pL4Zo8CnvAK2-cdpQyY"
            ],
            [
                "data",
                "https://research.google/resources/datasets/dqn-replay/"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1ktlNni_vwFpFtCgUez-RHW0OdGc2U_Wv",
        "update": 1664836133.194
    },
    {
        "name": "RLDS",
        "description": "Reinforcement Learning Datasets and it is an ecosystem of tools to store, retrieve and manipulate episodic data in the context of Sequential Decision Making including RL, Learning for Demonstrations, Offline RL or Imitation Learning",
        "author": [
            [
                "Sabela Ramos",
                "https://github.com/sabelaraga"
            ],
            [
                "Sertan Girgin",
                "https://sites.google.com/site/girgint/home"
            ],
            [
                "Léonard Hussenot",
                "https://leonardhussenot.github.io/"
            ],
            [
                "Damien Vincent",
                "https://www.linkedin.com/in/damien-vincent-1958381"
            ],
            [
                "Hanna Yakubovich",
                "https://github.com/yakubanna"
            ],
            [
                "Daniel Toyama",
                "https://github.com/kenjitoyama"
            ],
            [
                "Anita Gergely",
                "https://www.linkedin.com/in/anita-g-318064b2/"
            ],
            [
                "Piotr Stanczyk",
                "https://scholar.google.com/citations?user=fKVK0dYAAAAJ"
            ],
            [
                "Raphaël Marinier",
                "https://github.com/RaphaelMarinier"
            ],
            [
                "Jeremiah Harmsen",
                "https://github.com/jharmsen"
            ],
            [
                "Olivier Pietquin",
                "https://research.google/people/105812/"
            ],
            [
                "Nikola Momchev",
                "https://scholar.google.com/citations?user=PbWgaswAAAAJ"
            ]
        ],
        "links": [
            [
                "blog post",
                "https://ai.googleblog.com/2021/12/rlds-ecosystem-to-generate-share-and.html"
            ],
            [
                "git",
                "https://github.com/google-research/rlds",
                300
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2111.02767"
            ],
            [
                "git",
                "https://github.com/deepmind/envlogger"
            ],
            [
                "tf",
                "http://www.tensorflow.org/datasets/catalog/overview"
            ],
            [
                "git",
                "https://github.com/google-research/rlds-creator"
            ],
            [
                "git",
                "https://github.com/Farama-Foundation/D4RL"
            ],
            [
                "tf",
                "https://www.tensorflow.org/datasets/catalog/robosuite_panda_pick_place_can"
            ],
            [
                "tf",
                "https://www.tensorflow.org/datasets/catalog/locomotion"
            ],
            [
                "tf",
                "https://www.tensorflow.org/datasets/catalog/mt_opt"
            ],
            [
                "git",
                "https://github.com/deepmind/dm_env/blob/master/docs/index.md"
            ],
            [
                "tf",
                "https://www.tensorflow.org/datasets/external_tfrecord?hl=en#load_dataset_with_tfds"
            ],
            [
                "tf",
                "https://www.tensorflow.org/api_docs/python/tf/data"
            ],
            [
                "tf",
                "https://www.tensorflow.org/guide/data_performance#optimize_performance"
            ],
            [
                "tf",
                "https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle"
            ],
            [
                "tf",
                "https://www.tensorflow.org/datasets/splits"
            ],
            [
                "tf",
                "https://www.tensorflow.org/datasets/api_docs/python/tfds/load"
            ]
        ],
        "colab": "https://colab.research.google.com/github/google-research/rlds/blob/main/rlds/examples/rlds_tutorial.ipynb",
        "update": 1647458665.0
    },
    {
        "name": "Big Vision",
        "description": "This codebase is designed for training large-scale vision models using Cloud TPU VMs or GPU machines",
        "author": [
            [
                "Lucas Beyer",
                "http://lucasb.eyer.be/"
            ],
            [
                "Xiaohua Zhai",
                "https://github.com/xiaohuazhai"
            ],
            [
                "Alexander Kolesnikov",
                "https://github.com/akolesnikoff"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/google-research/big_vision",
                2405
            ],
            [
                "tf",
                "https://www.tensorflow.org/guide/data"
            ],
            [
                "tf",
                "https://www.tensorflow.org/datasets"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2010.11929"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2106.04560"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2105.01601"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2205.01580"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2212.08013"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2305.13035"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2303.17376"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2306.07915"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2305.16999"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2302.08242"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2006.07159"
            ]
        ],
        "colab": "https://colab.research.google.com/github/google-research/big_vision/blob/main/big_vision/configs/proj/image_text/lit.ipynb",
        "update": 1704303158.0
    },
    {
        "name": "Scenic",
        "description": "Codebase with a focus on research around attention-based models for computer vision",
        "author": [
            [
                "Mostafa Dehghani",
                "https://www.mostafadehghani.com/"
            ],
            [
                "Alexey Gritsenko",
                "https://github.com/AlexeyG"
            ],
            [
                "Anurag Arnab",
                "https://github.com/anuragarnab"
            ],
            [
                "Matthias Minderer",
                "https://matthias.minderer.net/"
            ],
            [
                "Yi Tay",
                "https://vanzytay.github.io/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/google-research/scenic",
                3348
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2110.11403"
            ],
            [
                "doi",
                "https://doi.org/10.1109/CVPR52688.2022.02070",
                18
            ],
            [
                "medium",
                "https://medium.com/syncedreview/google-open-sources-scenic-a-jax-library-for-rapid-computer-vision-model-prototyping-and-894dbdeddbae"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/deeplearning/comments/qgyjck/r_google_opensources_scenic_a_jax_library_for/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/google-research/scenic/blob/main/scenic/common_lib/colabs/scenic_playground.ipynb",
        "update": 1651695688.0
    },
    {
        "name": "rliable",
        "description": "Library for reliable evaluation, even with a handful of runs, on reinforcement learning and machine learnings benchmarks",
        "author": [
            [
                "Rishabh Agarwal",
                "https://agarwl.github.io/"
            ],
            [
                "Max Schwarzer",
                "https://scholar.google.com/citations?user=YmWRSvgAAAAJ"
            ],
            [
                "Pablo Castro",
                "https://psc-g.github.io/"
            ],
            [
                "Aaron Courville",
                "https://mila.quebec/en/directory/aaron-courville"
            ],
            [
                "Marc Bellemare",
                "http://www.marcgbellemare.info/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/google-research/rliable",
                780
            ],
            [
                "project",
                "https://agarwl.github.io/rliable/"
            ],
            [
                "blog post",
                "https://research.google/blog/rliable-towards-reliable-evaluation-reporting-in-reinforcement-learning/"
            ],
            [
                "arxiv",
                "https://psc-g.github.io/"
            ],
            [
                "twitter",
                "https://x.com/agarwl_/status/1432800830621687817"
            ],
            [
                "blog post",
                "https://araffin.github.io/post/rliable/"
            ],
            [
                "slides",
                "https://agarwl.github.io/rliable/assets/slides_mlc.pdf"
            ],
            [
                "poster",
                "https://agarwl.github.io/rliable/pdfs/Precipice_poster.pdf"
            ],
            [
                "yt",
                "https://youtu.be/XSY9JwqD-bw"
            ],
            [
                "yt",
                "https://youtu.be/gO33pSls-jI"
            ],
            [
                "yt",
                "https://youtu.be/HDyK3oNN2i0"
            ],
            [
                "yt",
                "https://youtu.be/mqcnHYwWzD8"
            ],
            [
                "yt",
                "https://youtu.be/E00gxHrHzZ4"
            ],
            [
                "yt",
                "https://youtu.be/M3OzJDAjz3o"
            ],
            [
                "podcast",
                "https://podcasts.apple.com/dk/podcast/deep-reinforcement-learning-at-the-edge-of/id1116303051?i=1000551066163"
            ],
            [
                "neurips",
                "https://proceedings.neurips.cc/paper/2021/hash/f514cec81cb148559cf475e7426eed5e-Abstract.html"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1a0pSD-1tWhMmeJeeoyZM1A-HCW3yf1xR",
        "update": 1671457973.221
    },
    {
        "name": "Detectron2",
        "description": "FAIR's next-generation platform for object detection and segmentation",
        "author": [
            [
                "Yuxin Wu",
                "http://ppwwyyxx.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/facebookresearch/detectron2",
                30701
            ],
            [
                "blog post",
                "https://ai.facebook.com/blog/-detectron2-a-pytorch-based-modular-object-detection-library-/"
            ],
            [
                "docs",
                "https://detectron2.readthedocs.io/en/latest/"
            ],
            [
                "git",
                "https://github.com/matterport/Mask_RCNN/tree/master/samples/balloon"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5",
        "update": 1685069239.579
    },
    {
        "name": "Droidlet",
        "description": "A modular embodied agent architecture and platform for building embodied agents",
        "author": [
            [
                "Anurag Pratik",
                "https://github.com/anuragprat1k"
            ],
            [
                "Soumith Chintala",
                "https://soumith.ch/"
            ],
            [
                "Kavya Srinet",
                "https://github.com/kavyasrinet"
            ],
            [
                "Dhiraj Gandhi",
                "https://dhiraj100892.github.io/"
            ],
            [
                "Rebecca Qian",
                "https://github.com/Rebecca-Qian"
            ],
            [
                "Yuxuan Sun",
                "https://github.com/snyxan"
            ],
            [
                "Ryan Drew",
                "https://rdrew.dev/"
            ],
            [
                "Sara Elkafrawy",
                "https://github.com/saraEbrahim"
            ],
            [
                "Anoushka Tiwari",
                "https://www.linkedin.com/in/anoushka-tiwari"
            ],
            [
                "Tucker Hart",
                "https://www.linkedin.com/in/tucker-hart-05a638133"
            ],
            [
                "Mary Williamson",
                "https://scholar.google.com/citations?user=Ys4xB-QAAAAJ"
            ],
            [
                "Abhinav Gupta",
                "http://www.cs.cmu.edu/~abhinavg/"
            ],
            [
                "Arthur Szlam",
                "https://scholar.google.com/citations?user=u3-FxUgAAAAJ"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2101.10384"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1907.08584"
            ],
            [
                "git",
                "https://github.com/facebookresearch/droidlet",
                854
            ],
            [
                "docs",
                "https://facebookresearch.github.io/droidlet/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/facebookresearch/droidlet/blob/master/examples_and_tutorials/tutorials/droidlet_for_physical_robots.ipynb",
        "update": 1631731324.0
    },
    {
        "name": "CompilerGym",
        "description": "A reinforcement learning toolkit for compiler optimizations",
        "author": [
            [
                "Chris Cummins",
                "https://chriscummins.cc/"
            ],
            [
                "Bram Wasti",
                "https://github.com/bwasti"
            ],
            [
                "Jiadong Guo",
                "https://jd-eth.github.io/"
            ],
            [
                "Brandon Cui",
                "https://www.linkedin.com/in/bcui19/"
            ],
            [
                "Jason Ansel",
                "https://jasonansel.com/"
            ],
            [
                "Sahir Gomez",
                "https://github.com/sahirgomez1"
            ],
            [
                "Olivier Teytaud",
                "https://github.com/teytaud"
            ],
            [
                "Benoit Steiner",
                "http://bsteiner.info/"
            ],
            [
                "Yuandong Tian",
                "http://yuandong-tian.com/"
            ],
            [
                "Hugh Leather",
                "https://github.com/hughleat"
            ]
        ],
        "links": [
            [
                "docs",
                "https://facebookresearch.github.io/CompilerGym/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2109.08267"
            ],
            [
                "git",
                "https://github.com/facebookresearch/CompilerGym",
                916
            ]
        ],
        "colab": "https://colab.research.google.com/github/facebookresearch/CompilerGym/blob/development/examples/getting-started.ipynb",
        "update": 1637060984.0
    },
    {
        "name": "MyoSuite",
        "description": "A collection of musculoskeletal environments and tasks simulated with the MuJoCo physics engine and wrapped in the OpenAI gym API to enable the application of Machine Learning to bio-mechanic control problems",
        "author": [
            [
                "Vittorio Caggiano",
                "https://github.com/Vittorio-Caggiano"
            ],
            [
                "Huawei Wang",
                "https://huaweiwang.github.io/"
            ],
            [
                "Guillaume Durandau",
                "https://people.utwente.nl/g.v.durandau"
            ],
            [
                "Massimo Sartori",
                "https://people.utwente.nl/m.sartori"
            ],
            [
                "Vikash Kumar",
                "https://vikashplus.github.io/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2205.13600"
            ],
            [
                "git",
                "https://github.com/facebookresearch/myosuite",
                866
            ],
            [
                "docs",
                "https://myosuite.readthedocs.io/en/latest/"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1U6vo6Q_rPhDaq6oUMV7EAZRm6s0fD1wn",
        "update": 1686945401.905
    },
    {
        "name": "BANMo",
        "description": "Given multiple casual videos capturing a deformable object, BANMo reconstructs an animatable 3D model, including an implicit canonical 3D shape, appearance, skinning weights, and time-varying articulations, without pre-defined shape templates or registered cameras",
        "author": [
            [
                "Gengshan Yang",
                "https://gengshan-y.github.io/"
            ],
            [
                "Minh Vo",
                "https://minhpvo.github.io/"
            ],
            [
                "Natalia Neverova",
                "https://nneverova.github.io/"
            ],
            [
                "Deva Ramanan",
                "http://www.cs.cmu.edu/~deva/"
            ],
            [
                "Andrea Vedaldi",
                "https://www.robots.ox.ac.uk/~vedaldi/"
            ],
            [
                "Hanbyul Joo",
                "https://jhugestar.github.io/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/facebookresearch/banmo",
                539
            ],
            [
                "project",
                "https://banmo-www.github.io/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2112.12761"
            ],
            [
                "git",
                "https://github.com/kwea123/nerf_pl"
            ],
            [
                "git",
                "https://github.com/gengshan-y/rigidmask"
            ],
            [
                "git",
                "https://github.com/ShichenLiu/SoftRas"
            ],
            [
                "git",
                "https://github.com/ThibaultGROUEIX/ChamferDistancePytorch"
            ],
            [
                "yt",
                "https://youtu.be/1NUa-yvFGA0"
            ],
            [
                "yt",
                "https://youtu.be/jDTy-liFoCQ"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1dQJn1vsuz0DkyRZbOA1SulkVQ0V1kMUP",
        "update": 1672373422.19
    },
    {
        "name": "AV-HuBERT",
        "description": "Self-supervised representation learning framework for audio-visual speech",
        "author": [
            [
                "Bowen Shi",
                "https://home.ttic.edu/~bshi/"
            ],
            [
                "Wei-Ning Hsu",
                "http://people.csail.mit.edu/wnhsu/"
            ],
            [
                "Kushal Lakhotia",
                "https://about.me/hikushalhere"
            ],
            [
                "Abdelrahman Mohamed",
                "http://www.cs.toronto.edu/~asamir/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/facebookresearch/av_hubert",
                856
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2201.02184"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2201.01763"
            ],
            [
                "blog post",
                "https://ai.facebook.com/blog/ai-that-understands-speech-by-looking-as-well-as-hearing/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1810.04805"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1911.04890"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1bNXkfpHiVHzXQH8WjGhzQ-fsDxolpUjD",
        "update": 1644689162.002
    },
    {
        "name": "textlesslib",
        "description": "A library aimed to facilitate research in Textless NLP",
        "author": [
            [
                "Eugene Kharitonov",
                "https://eugene-kharitonov.github.io/"
            ],
            [
                "Jade Copet",
                "https://scholar.google.com/citations?user=GRMLwjAAAAAJ"
            ],
            [
                "Kushal Lakhotia",
                "https://about.me/hikushalhere"
            ],
            [
                "Nguyễn Tú Anh",
                "https://tuanh208.github.io/"
            ],
            [
                "Paden Tomasello",
                "https://scholar.google.com/citations?user=sBtWMGYAAAAJ"
            ],
            [
                "Ann Lee",
                "https://ai.facebook.com/people/ann-lee"
            ],
            [
                "Ali Elkahky",
                "https://scholar.google.com/citations?user=KB3S8RoAAAAJ"
            ],
            [
                "Wei-Ning Hsu",
                "https://wnhsu.github.io/"
            ],
            [
                "Abdelrahman Mohamed",
                "https://ai.facebook.com/people/abdelrahman-mohamed/"
            ],
            [
                "Emmanuel Dupoux",
                "http://www.lscp.net/persons/dupoux/"
            ],
            [
                "Yossi Adi",
                "https://www.cs.huji.ac.il/~adiyoss/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/facebookresearch/textlesslib",
                528
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2202.07359"
            ],
            [
                "git",
                "https://github.com/NVIDIA/waveglow"
            ],
            [
                "git",
                "https://github.com/keithito/tacotron"
            ],
            [
                "git",
                "https://github.com/NVIDIA/tacotron2"
            ],
            [
                "git",
                "https://github.com/pseeth/torch-stft"
            ],
            [
                "pwc",
                "https://paperswithcode.com/dataset/librispeech"
            ]
        ],
        "colab": "https://colab.research.google.com/github/facebookresearch/textlesslib/blob/main/examples/resynthesis_and_continuation.ipynb",
        "update": 1644942469.0
    },
    {
        "name": "Home Robot",
        "description": "Low-level API for controlling various home robots",
        "author": [
            [
                "Chris Paxton",
                "https://cpaxton.github.io/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/facebookresearch/home-robot",
                954
            ],
            [
                "git",
                "https://github.com/cpaxton/contact_graspnet/tree/cpaxton/devel"
            ],
            [
                "git",
                "https://github.com/facebookresearch/fairo"
            ],
            [
                "git",
                "https://github.com/hello-robot/stretch_body"
            ],
            [
                "git",
                "https://github.com/hello-robot/stretch_firmware"
            ],
            [
                "git",
                "https://github.com/hello-robot/stretch_ros"
            ],
            [
                "git",
                "https://github.com/hello-robot/stretch_ros2"
            ],
            [
                "git",
                "https://github.com/hello-robot/stretch_web_interface"
            ],
            [
                "git",
                "https://github.com/RoboStack/ros-noetic"
            ],
            [
                "git",
                "https://github.com/codekansas/stretch-robot"
            ]
        ],
        "colab": "https://colab.research.google.com/github/facebookresearch/home-robot/blob/master/src/home_robot_sim/notebooks/velocity_control_sim.ipynb",
        "update": 1693428229.0
    },
    {
        "name": "PyTorchVideo",
        "description": "Deeplearning library with a focus on video understanding work",
        "author": [
            [
                "Haoqi Fan",
                "https://haoqifan.github.io/"
            ],
            [
                "Tullie Murrell",
                "https://github.com/tullie"
            ],
            [
                "Heng Wang",
                "https://hengcv.github.io/"
            ],
            [
                "Kalyan Vasudev Alwala",
                "https://github.com/kalyanvasudev"
            ],
            [
                "Yanghao Li",
                "https://github.com/lyttonhao"
            ],
            [
                "Yilei Li",
                "https://liyilui.github.io/personal_page/"
            ],
            [
                "Bo Xiong",
                "https://github.com/bxiong1202"
            ],
            [
                "Nikhila Ravi",
                "https://nikhilaravi.com/"
            ],
            [
                "Meng Li",
                "https://mengli.me/"
            ],
            [
                "Haichuan Yang",
                "https://hyang1990.github.io/"
            ],
            [
                "Jitendra Malik",
                "https://scholar.google.com/citations?user=oY9R5YQAAAAJ"
            ],
            [
                "Ross Girshick",
                "https://github.com/rbgirshick"
            ],
            [
                "Matt Feiszli",
                "https://scholar.google.com/citations?user=A-wA73gAAAAJ"
            ],
            [
                "Aaron Adcock",
                "https://scholar.google.com/citations?&user=oa78zHUAAAAJ"
            ],
            [
                "Wan-Yen Lo",
                "https://github.com/wanyenlo"
            ],
            [
                "Christoph Feichtenhofer",
                "http://feichtenhofer.github.io/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/facebookresearch/pytorchvideo",
                3347
            ],
            [
                "website",
                "https://github.com/facebookresearch/pytorchvideo"
            ],
            [
                "docs",
                "https://pytorchvideo.readthedocs.io/en/latest/index.html"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2111.09887"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2104.11227"
            ],
            [
                "doi",
                "https://doi.org/10.1145/3474085.3478329",
                23
            ],
            [
                "yt",
                "https://youtu.be/b7-gnpqz9Qg"
            ],
            [
                "blog post",
                "https://ai.facebook.com/blog/pytorchvideo-a-deep-learning-library-for-video-understanding/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/facebookresearch/pytorchvideo/blob/main/tutorials/accelerator/Build_your_model_with_PytorchVideo_Accelerator.ipynb",
        "update": 1618336951.0
    },
    {
        "name": "Audiocraft",
        "description": "PyTorch library for deep learning research on audio generation",
        "author": [
            [
                "Jade Copet",
                "https://scholar.google.com/citations?&user=GRMLwjAAAAAJ"
            ],
            [
                "Felix Kreuk",
                "https://felixkreuk.github.io/"
            ],
            [
                "Itai Gat",
                "https://itaigat.com/"
            ],
            [
                "Tal Remez",
                "https://talremez.github.io/"
            ],
            [
                "David Kant",
                "https://www.linkedin.com/in/david-kant-339a3b1b7"
            ],
            [
                "Gabriel Synnaeve",
                "https://syhw.github.io/"
            ],
            [
                "Yossi Adi",
                "https://www.cs.huji.ac.il/~adiyoss/"
            ],
            [
                "Alexandre Défossez",
                "https://ai.honu.io/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/facebookresearch/audiocraft",
                21099
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2306.05284"
            ],
            [
                "git",
                "https://github.com/facebookresearch/encodec"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2301.11325"
            ],
            [
                "project",
                "https://ai.honu.io/papers/musicgen/"
            ],
            [
                "git",
                "https://github.com/camenduru/MusicGen-colab"
            ],
            [
                "hf",
                "https://huggingface.co/facebook/musicgen-large"
            ],
            [
                "yt",
                "https://youtu.be/v-YpvPkhdO4"
            ],
            [
                "yt",
                "https://www.youtube.com/watch?v=EGfxuTy9Eeo"
            ],
            [
                "yt",
                "https://youtu.be/la2fGS0dW98"
            ],
            [
                "yt",
                "https://youtu.be/v-YpvPkhdO4"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1fxGqfg96RBUvGxZ1XXN07s3DthrKUl4-",
        "update": 1686490063.382
    },
    {
        "name": "MAGNeT",
        "description": "Masked generative sequence modeling method that operates directly over several streams of audio tokens",
        "author": [
            [
                "Alon Ziv",
                "https://www.cs.huji.ac.il/w~alonzi/"
            ],
            [
                "Itai Gat",
                "https://itaigat.com/"
            ],
            [
                "Gaël Le Lan",
                "https://github.com/gl3lan"
            ],
            [
                "Tal Remez",
                "https://talremez.github.io/"
            ],
            [
                "Felix Kreuk",
                "https://felixkreuk.github.io/"
            ],
            [
                "Alexandre Défossez",
                "https://ai.honu.io/"
            ],
            [
                "Jade Copet",
                "https://scholar.google.com/citations?&user=GRMLwjAAAAAJ"
            ],
            [
                "Gabriel Synnaeve",
                "https://syhw.github.io/"
            ],
            [
                "Yossi Adi",
                "https://www.cs.huji.ac.il/~adiyoss/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/facebookresearch/audiocraft/blob/main/docs/MAGNET.md",
                21099
            ],
            [
                "project",
                "https://pages.cs.huji.ac.il/adiyoss-lab/MAGNeT/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2401.04577"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2305.09636"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2307.04686"
            ],
            [
                "hf",
                "https://huggingface.co/facebook/magnet-medium-10secs"
            ],
            [
                "hf",
                "https://huggingface.co/facebook/magnet-medium-30secs"
            ],
            [
                "hf",
                "https://huggingface.co/facebook/audio-magnet-medium"
            ],
            [
                "git",
                "https://github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/AI-Music-Generation-Audiocraft-Tutorial.md#more-info-about-top-k-top-p-temperature-and-classifier-free-guidance-from-chatgpt"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/ArtificialInteligence/comments/19808gf/magnet_masked_audio_generation_using_a_single/"
            ],
            [
                "medium",
                "https://generativeai.pub/metas-ai-magnet-the-next-big-thing-in-text-to-audio-technology-7d524d9459ef"
            ]
        ],
        "colab": "https://colab.research.google.com/github/camenduru/MAGNeT-colab/blob/main/MAGNET_colab.ipynb",
        "update": 1705372092.0
    },
    {
        "name": "xFormers",
        "description": "Toolbox to Accelerate Research on Transformers",
        "author": [
            [
                "Benjamin Lefaudeux",
                "https://github.com/blefaudeux"
            ],
            [
                "Francisco Massa",
                "https://github.com/fmassa"
            ],
            [
                "Diana Liskovich",
                "https://www.linkedin.com/in/dianaliskovich"
            ],
            [
                "Wenhan Xiong",
                "https://xwhan.github.io/"
            ],
            [
                "Vittorio Caggiano",
                "https://vittorio-caggiano.github.io/"
            ],
            [
                "Sean Naren",
                "https://github.com/SeanNaren"
            ],
            [
                "Min Xu",
                "https://github.com/min-xu-ai"
            ],
            [
                "Jieru Hu",
                "https://github.com/jieru-hu"
            ],
            [
                "Marta Tintore",
                "https://github.com/MartaTintore"
            ],
            [
                "Susan Zhang",
                "https://suchenzang.github.io/"
            ],
            [
                "Patrick Labatut",
                "https://github.com/patricklabatut"
            ],
            [
                "Daniel Haziza",
                "https://scholar.google.com/citations?user=2eSKdFMAAAAJ"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/facebookresearch/xformers",
                8725
            ],
            [
                "docs",
                "https://facebookresearch.github.io/xformers/"
            ],
            [
                "git",
                "https://github.com/google-research/sputnik"
            ],
            [
                "git",
                "https://github.com/hgyhungry/ge-spmm"
            ],
            [
                "git",
                "https://github.com/openai/triton"
            ],
            [
                "git",
                "https://github.com/RobinBruegger/RevTorch"
            ],
            [
                "git",
                "https://github.com/mlpen/Nystromformer"
            ],
            [
                "git",
                "https://github.com/facebookresearch/fairscale"
            ],
            [
                "git",
                "https://github.com/huggingface/pytorch-image-models"
            ],
            [
                "git",
                "https://github.com/Dao-AILab/flash-attention"
            ],
            [
                "yt",
                "https://youtu.be/NJyZCdxnGe4"
            ]
        ],
        "colab": "https://colab.research.google.com/github/facebookresearch/xformers/blob/main/docs/source/xformers_mingpt.ipynb",
        "update": 1731506354.0
    },
    {
        "name": "Seamless Communication",
        "description": "Family of AI models that enable more natural and authentic communication across languages",
        "author": [
            [
                "Loïc Barrault",
                "https://loicbarrault.github.io/"
            ],
            [
                "Yu-An Chung",
                "https://iamyuanchung.github.io/"
            ],
            [
                "Mariano Coria",
                "https://www.linkedin.com/in/marianocoria"
            ],
            [
                "David Dale",
                "https://daviddale.ru/"
            ],
            [
                "Ning Dong",
                "https://scholar.google.com/citations?user=gg1hvjoAAAAJ"
            ],
            [
                "Mark Duppenthaler",
                "https://github.com/mduppes"
            ],
            [
                "Paul-Ambroise Duquenne",
                "https://scholar.google.com/citations?user=Uah8IcAAAAAJ"
            ],
            [
                "Hady Elsahar",
                "https://www.hadyelsahar.io/"
            ],
            [
                "Min-Jae Hwang",
                "https://mjhwang93.github.io/"
            ],
            [
                "Hirofumi Inaguma",
                "https://hirofumi0810.github.io/"
            ],
            [
                "Ilia Kulikov",
                "https://github.com/uralik"
            ],
            [
                "Pengwei Li",
                "https://scholar.google.com/citations?user=hQB3YsYAAAAJ"
            ],
            [
                "Daniel Licht",
                "https://github.com/Lichtphyz"
            ],
            [
                "Jean Maillard",
                "https://scholar.google.com/citations?user=_ewOoK0AAAAJ"
            ],
            [
                "Ruslan Mavlyutov",
                "https://github.com/mavlyutovr"
            ],
            [
                "Kaushik Ram Sadagopan",
                "https://github.com/kauterry"
            ],
            [
                "Abinesh Ramakrishnan",
                "https://github.com/ibanesh"
            ],
            [
                "Tuan Tran",
                "https://antoine-tran.github.io/"
            ],
            [
                "Guillaume Wenzek",
                "https://github.com/gwenzek"
            ],
            [
                "Yilin Yang",
                "https://yilinyang7.github.io/"
            ],
            [
                "Ethan Ye",
                "https://github.com/yeyinthtoon"
            ],
            [
                "Ivan Evtimov",
                "https://ivanevtimov.eu/"
            ],
            [
                "Pierre Fernandez",
                "https://pierrefdz.github.io/"
            ],
            [
                "Robin San Roman",
                "https://scholar.google.com/citations?user=AJ3ir84AAAAJ"
            ],
            [
                "Bokai Yu",
                "https://scholar.google.com/citations?user=7jNmPwUAAAAJ"
            ],
            [
                "Pierre Andrews",
                "https://github.com/Mortimerp9"
            ],
            [
                "Can Balioglu",
                "http://canbalioglu.com/"
            ],
            [
                "Peng-Jen Chen",
                "https://scholar.google.com/citations?user=rOXs9VMAAAAJ"
            ],
            [
                "Marta Costa-jussà",
                "https://costa-jussa.com/"
            ],
            [
                "Maha Elbayad",
                "http://elbayadm.github.io/"
            ],
            [
                "Hongyu Gong",
                "https://github.com/hygong-fb"
            ],
            [
                "Francisco Guzmán",
                "https://guzmanhe.github.io/"
            ],
            [
                "Kevin Heffernan",
                "https://github.com/heffernankevin"
            ],
            [
                "Somya Jain",
                "https://scholar.google.com/citations?user=AmBxU3kAAAAJ"
            ],
            [
                "Justine Kao",
                "https://scholar.google.com/citations?user=Y9BLeTAAAAAJ"
            ],
            [
                "Ann Lee",
                "https://www.stat.cmu.edu/~annlee/"
            ],
            [
                "Xutai Ma",
                "https://github.com/xutaima"
            ],
            [
                "Benjamin Peloquin",
                "https://scholar.google.com/citations?user=5GNAjB8AAAAJ"
            ],
            [
                "Juan Pino",
                "https://scholar.google.com/citations?user=weU_-4IAAAAJ"
            ],
            [
                "Sravya Popuri",
                "https://scholar.google.com/citations?user=MtmqG3UAAAAJ"
            ],
            [
                "Holger Schwenk",
                "https://github.com/hoschwenk"
            ],
            [
                "Anna Sun",
                "https://github.com/annasun28"
            ],
            [
                "Paden Tomasello",
                "https://scholar.google.com/citations?user=sBtWMGYAAAAJ"
            ],
            [
                "Changhan Wang",
                "https://www.changhan.me/"
            ],
            [
                "Skyler Wang",
                "https://www.skylerwang.com/"
            ],
            [
                "Mary Williamson",
                "https://scholar.google.com/citations?user=Ys4xB-QAAAAJ"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/facebookresearch/seamless_communication",
                10990
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2312.05187"
            ],
            [
                "blog post",
                "https://ai.meta.com/research/seamless-communication/"
            ],
            [
                "hf",
                "https://huggingface.co/facebook/seamless-m4t-v2-large"
            ],
            [
                "hf",
                "https://huggingface.co/facebook/seamless-expressive"
            ],
            [
                "hf",
                "https://huggingface.co/facebook/seamless-streaming"
            ],
            [
                "git",
                "https://github.com/libsndfile/libsndfile"
            ],
            [
                "git",
                "https://github.com/facebookresearch/fairseq2"
            ],
            [
                "git",
                "https://github.com/facebookresearch/SimulEval"
            ],
            [
                "git",
                "https://github.com/facebookresearch/stopes"
            ],
            [
                "git",
                "https://github.com/facebookresearch/SONAR"
            ],
            [
                "yt",
                "https://www.youtube.com/watch?v=0padjtkHXTE"
            ],
            [
                "yt",
                "https://youtu.be/rNN7qsoCKBo"
            ],
            [
                "yt",
                "https://youtu.be/RKEFZ44YOcc"
            ],
            [
                "medium",
                "https://ngwaifoong92.medium.com/beginners-guide-to-seamlessm4t-81efad6e8ca6"
            ]
        ],
        "colab": "https://colab.research.google.com/github/facebookresearch/seamless_communication/blob/main/Seamless_Tutorial.ipynb",
        "update": 1702591447.0
    },
    {
        "name": "PyTorch3D ",
        "description": "Library for deep learning with 3D data",
        "author": [
            [
                "Nikhila Ravi",
                "https://nikhilaravi.com/"
            ],
            [
                "Jeremy Reizenstein",
                "https://github.com/bottler"
            ],
            [
                "David Novotny",
                "https://d-novotny.github.io/"
            ],
            [
                "Taylor Gordon",
                "https://scholar.google.com/citations?user=CNOoeQ0AAAAJ"
            ],
            [
                "Wan-Yen Lo",
                "https://github.com/wanyenlo"
            ],
            [
                "Justin Johnson",
                "https://web.eecs.umich.edu/~justincj/"
            ],
            [
                "Georgia Gkioxari",
                "https://gkioxari.github.io/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/facebookresearch/pytorch3d",
                8861
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2007.08501"
            ],
            [
                "website",
                "https://pytorch3d.org/"
            ],
            [
                "blog post",
                "https://ai.meta.com/blog/implicitron-a-new-modular-extensible-framework-for-neural-implicit-representations-in-pytorch3d/"
            ],
            [
                "blog post",
                "https://ai.meta.com/blog/-introducing-pytorch3d-an-open-source-library-for-3d-deep-learning/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1906.02739"
            ],
            [
                "docs",
                "https://pytorch3d.readthedocs.org/"
            ],
            [
                "yt",
                "https://youtu.be/0JEb7knenps"
            ],
            [
                "yt",
                "https://youtu.be/Pph1r-x9nyY"
            ],
            [
                "yt",
                "https://youtu.be/eCDBA_SbxCE"
            ],
            [
                "yt",
                "https://youtu.be/MOBAJb5nJRI"
            ],
            [
                "yt",
                "https://youtu.be/g50RiDnfIfY"
            ],
            [
                "yt",
                "https://youtu.be/hgBk9WlF-XA"
            ],
            [
                "yt",
                "https://youtu.be/Sb9gCCnSAUg"
            ],
            [
                "yt",
                "https://youtu.be/ZLqJ33Ey-MU"
            ],
            [
                "medium",
                "https://towardsdatascience.com/glimpse-into-pytorch3d-an-open-source-3d-deep-learning-library-291a4beba30f"
            ],
            [
                "medium",
                "https://medium.com/@phamtdong0406/crafting-realistic-renderings-with-pytorch3d-947a38194f0a"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/code/sohonjit/rendering-with-pytorch3d"
            ],
            [
                "medium",
                "https://towardsdatascience.com/how-to-render-3d-files-using-pytorch3d-ef9de72483f8"
            ]
        ],
        "colab": "https://colab.research.google.com/github/facebookresearch/pytorch3d/blob/master/docs/tutorials/implicitron_config_system.ipynb",
        "update": 1720697738.0
    },
    {
        "name": "Spleeter",
        "description": "Deezer source separation library including pretrained models",
        "author": [
            [
                "Romain Hennequin",
                "http://romain-hennequin.fr/"
            ],
            [
                "Anis Khlif",
                "https://github.com/alreadytaikeune"
            ],
            [
                "Félix Voituret",
                "https://github.com/Faylixe"
            ],
            [
                "Manuel Moussallam",
                "https://mmoussallam.github.io/"
            ]
        ],
        "links": [
            [
                "blog post",
                "https://deezer.io/releasing-spleeter-deezer-r-d-source-separation-engine-2b88985e797e"
            ],
            [
                "project",
                "https://research.deezer.com/projects/spleeter.html"
            ],
            [
                "git",
                "https://github.com/deezer/spleeter",
                26010
            ],
            [
                "data",
                "https://sigsep.github.io/datasets/musdb.html"
            ]
        ],
        "colab": "https://colab.research.google.com/github/deezer/spleeter/blob/master/spleeter.ipynb",
        "update": 1610318662.0
    },
    {
        "name": "GPT Neo",
        "description": "An implementation of model & data parallel GPT2 & GPT3 -like models, with the ability to scale up to full GPT3 sizes (and possibly more!), using the mesh-tensorflow library",
        "author": [
            [
                "EleutherAI",
                "https://www.eleuther.ai/"
            ]
        ],
        "links": [
            [
                "GPT-2",
                "https://openai.com/blog/better-language-models/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2005.14165"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2004.05150"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1701.06538"
            ],
            [
                "git",
                "https://github.com/EleutherAI/gpt-neo",
                8238
            ],
            [
                "git",
                "https://github.com/tensorflow/mesh"
            ],
            [
                "git",
                "https://github.com/EleutherAI/gpt-neox/"
            ],
            [
                "pretrained",
                "https://the-eye.eu/public/AI/gptneo-release/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/EleutherAI/GPTNeo/blob/master/GPTNeo_example_notebook.ipynb",
        "update": 1616948356.0
    },
    {
        "name": "LM Evaluation Harness",
        "description": "Framework for few-shot evaluation of language models.",
        "author": [
            [
                "EleutherAI",
                "https://www.eleuther.ai/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/EleutherAI/lm-evaluation-harness",
                7131
            ],
            [
                "discord",
                "https://discord.gg/eleutherai"
            ],
            [
                "git",
                "https://github.com/AutoGPTQ/AutoGPTQ"
            ],
            [
                "git",
                "https://github.com/EleutherAI/gpt-neox"
            ],
            [
                "git",
                "https://github.com/microsoft/Megatron-DeepSpeed"
            ],
            [
                "git",
                "https://github.com/vllm-project/vllm"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2005.14165"
            ],
            [
                "project",
                "https://www.eleuther.ai/projects/large-language-model-evaluation"
            ]
        ],
        "colab": "https://colab.research.google.com/github/EleutherAI/lm-evaluation-harness/blob/main/examples/lm-eval-overview.ipynb",
        "update": 1728056672.0
    },
    {
        "name": "Lucid Sonic Dreams",
        "description": "Syncs GAN-generated visuals to music",
        "author": [
            [
                "Mikael Alafriz",
                "https://github.com/mikaelalafriz"
            ]
        ],
        "links": [
            [
                "yt",
                "https://youtu.be/l-nGC-ve7sI"
            ],
            [
                "medium",
                "https://towardsdatascience.com/introducing-lucid-sonic-dreams-sync-gan-art-to-music-with-a-few-lines-of-python-code-b04f88722de1"
            ],
            [
                "git",
                "https://github.com/mikaelalafriz/lucid-sonic-dreams",
                775
            ],
            [
                "git",
                "https://github.com/NVlabs/stylegan2"
            ],
            [
                "git",
                "https://github.com/justinpinkney/awesome-pretrained-stylegan2"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1Y5i50xSFIuN3V4Md8TB30_GOAtts7RQD",
        "update": 1629785030.562
    },
    {
        "name": "ruGPT3",
        "description": "Example of inference of RuGPT3XL",
        "author": [
            [
                "Anton Emelyanov",
                "https://github.com/king-menin"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/ai-forever/ru-gpts",
                2077
            ],
            [
                "git",
                "https://github.com/microsoft/DeepSpeedExamples/tree/master/Megatron-LM"
            ],
            [
                "hf",
                "https://huggingface.co/transformers/main_classes/model.html#transformers.generation_utils.GenerationMixin.generate"
            ],
            [
                "sparse attention",
                "https://www.deepspeed.ai/tutorials/sparse-attention/"
            ],
            [
                "cristofari",
                "https://sbercloud.ru/ru/christofari"
            ]
        ],
        "colab": "https://colab.research.google.com/github/ai-forever/ru-gpts/blob/master/examples/ruGPT3XL_generation.ipynb",
        "update": 1670407785.0
    },
    {
        "name": "RuDOLPH",
        "description": "A fast and light text-image-text transformer designed for a quick and easy fine-tuning setup for the solution of various tasks: from generating images by text description and image classification to visual question answering and more",
        "author": [
            [
                "Alex Shonenkov",
                "https://github.com/shonenkov"
            ],
            [
                "Misha Konstantinov",
                "https://github.com/zeroshot-ai"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/ai-forever/ru-dolph",
                255
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2005.14165"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2102.12092"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2103.00020"
            ],
            [
                "pypi",
                "https://pypi.org/project/rudolph/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/ai-forever/ru-dolph/blob/master/jupyters/RUDOLPH_tune_i2t_pl.ipynb",
        "update": 1665035920.0
    },
    {
        "name": "SAGE",
        "description": "Methodology for generative spelling correction, which was tested on English and Russian languages and potentially can be extended to any language with minor changes",
        "author": [
            [
                "Nikita Martynov",
                "https://github.com/meduzick"
            ],
            [
                "Mark Baushenko",
                "https://github.com/e0xextazy"
            ],
            [
                "Anastasia Kozlova",
                "https://github.com/anastasia-kozlova"
            ],
            [
                "Katerina Kolomeytseva",
                "https://www.linkedin.com/in/katerina-kolomeytseva-394a7a21a"
            ],
            [
                "Aleksandr Abramov",
                "https://github.com/Ab1992ao"
            ],
            [
                "Alena Fenogenova",
                "https://github.com/Alenush"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/ai-forever/sage",
                135
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2308.09435"
            ],
            [
                "yt",
                "https://youtu.be/yFfkV0Qjuu0"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Levenshtein_distance"
            ],
            [
                "git",
                "https://github.com/ai-forever/augmentex"
            ],
            [
                "hf",
                "https://huggingface.co/ai-forever/RuM2M100-1.2B"
            ],
            [
                "hf",
                "https://huggingface.co/ai-forever/FRED-T5-large-spell"
            ],
            [
                "hf",
                "https://huggingface.co/ai-forever/RuM2M100-418M"
            ],
            [
                "hf",
                "https://huggingface.co/ai-forever/T5-large-spell"
            ],
            [
                "hf",
                "https://huggingface.co/datasets/ai-forever/spellcheck_benchmark"
            ]
        ],
        "colab": "https://colab.research.google.com/github/ai-forever/sage/blob/main/notebooks/text_correction_demo.ipynb",
        "update": 1712816612.0
    },
    {
        "name": "GPT-J-6B",
        "description": "A 6 billion parameter, autoregressive text generation model trained on The Pile",
        "author": [
            [
                "Ben Wang",
                "https://benwang.dev/"
            ],
            [
                "Aran Komatsuzaki",
                "https://arankomatsuzaki.wordpress.com/about-me/"
            ],
            [
                "Janko Prester",
                "https://www.jankoprester.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/kingoflolz/mesh-transformer-jax",
                6306
            ],
            [
                "blog post",
                "https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/"
            ],
            [
                "web demo",
                "https://6b.eleuther.ai/"
            ],
            [
                "The Pile",
                "https://pile.eleuther.ai/"
            ],
            [
                "git",
                "https://github.com/EleutherAI/gpt-neox"
            ],
            [
                "git",
                "https://github.com/microsoft/DeepSpeed"
            ]
        ],
        "colab": "https://colab.research.google.com/github/kingoflolz/mesh-transformer-jax/blob/master/colab_demo.ipynb",
        "update": 1631678038.0
    },
    {
        "name": "highway-env",
        "description": "A collection of environments for autonomous driving and tactical decision-making tasks",
        "author": [
            [
                "Edouard Leurent",
                "https://edouardleurent.com/"
            ]
        ],
        "links": [
            [
                "docs",
                "https://highway-env.readthedocs.io/en/latest/"
            ],
            [
                "git",
                "https://github.com/eleurent/highway-env",
                2669
            ],
            [
                "git",
                "https://github.com/eleurent/rl-agents"
            ],
            [
                "git",
                "https://github.com/eleurent/finite-mdp"
            ],
            [
                "git",
                "https://github.com/openai/baselines/tree/master/baselines/her"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2102.03483"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2105.05701"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2101.07140"
            ]
        ],
        "colab": "https://colab.research.google.com/github/eleurent/highway-env/blob/master/scripts/parking_model_based.ipynb",
        "update": 1723221534.0
    },
    {
        "name": "GAN steerability",
        "description": "We will navigate in GAN latent space to simulate various camera transformations",
        "author": [
            [
                "Ali Jahanian",
                "http://people.csail.mit.edu/jahanian/"
            ],
            [
                "Lucy Chai",
                "http://people.csail.mit.edu/lrchai/"
            ],
            [
                "Phillip Isola",
                "http://web.mit.edu/phillipi/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1907.07171"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1809.11096"
            ],
            [
                "git",
                "https://github.com/ali-design/gan_steerability",
                266
            ],
            [
                "yt",
                "https://youtu.be/nS0V64sF7Cw"
            ],
            [
                "project",
                "https://ali-design.github.io/gan_steerability/"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1kn6yG8PqD1U2bUcy32V1iAVjzlcQWcG3",
        "update": 1614894616.124
    },
    {
        "name": "GAN Dissection",
        "description": "Visualizing and Understanding Generative Adversarial Networks",
        "author": [
            [
                "David Bau",
                "https://people.csail.mit.edu/davidbau/home/"
            ],
            [
                "Jun-Yan Zhu",
                "https://www.cs.cmu.edu/~junyanz/"
            ],
            [
                "Hendrik Strobelt",
                "http://hendrik.strobelt.com/"
            ],
            [
                "Bolei Zhou",
                "https://boleizhou.github.io/"
            ],
            [
                "Joshua Tenenbaum",
                "https://mitibmwatsonailab.mit.edu/people/joshua-tenenbaum/"
            ],
            [
                "William Freeman",
                "https://billf.mit.edu/"
            ],
            [
                "Antonio Torralba",
                "https://groups.csail.mit.edu/vision/torralbalab/"
            ]
        ],
        "links": [
            [
                "project",
                "https://gandissect.csail.mit.edu/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1811.10597"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1901.09887"
            ],
            [
                "yt",
                "https://www.youtube.com/watch?v=yVCgUYe4JTM"
            ],
            [
                "demo",
                "http://gandissect.res.ibm.com/ganpaint.html"
            ],
            [
                "git",
                "https://github.com/CSAILVision/GANDissect",
                1771
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1807.10221"
            ],
            [
                "git",
                "https://github.com/CSAILVision/NetDissect"
            ],
            [
                "git",
                "https://github.com/junyanz/iGAN"
            ]
        ],
        "colab": "https://colab.research.google.com/github/SIDN-IAP/global-model-repr/blob/master/notebooks/gandissect_solutions.ipynb",
        "update": 1588616339.0
    },
    {
        "name": "EasyNMT",
        "description": "Easy to use, state-of-the-art machine translation for more than 100+ languages",
        "author": [
            [
                "Nils Reimers",
                "https://www.nils-reimers.de/"
            ]
        ],
        "links": [
            [
                "demo",
                "http://easynmt.net/demo/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2008.00401"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2010.11125"
            ],
            [
                "git",
                "https://github.com/UKPLab/EasyNMT",
                1177
            ],
            [
                "git",
                "https://github.com/Helsinki-NLP/Opus-MT"
            ],
            [
                "git",
                "https://github.com/facebookresearch/fairseq/tree/main/examples/multilingual"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1X47vgSiOphpxS5w_LPtjQgJmiSTNfRNC",
        "update": 1619468765.741
    },
    {
        "name": "Sentence Transformers",
        "description": "Multilingual Sentence, Paragraph, and Image Embeddings using BERT & Co",
        "author": [
            [
                "Nils Reimers",
                "https://www.nils-reimers.de/"
            ],
            [
                "Iryna Gurevych",
                "https://www.informatik.tu-darmstadt.de/ukp/ukp_home/head_ukp/index.en.jsp"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/UKPLab/sentence-transformers",
                15481
            ],
            [
                "docs",
                "https://www.sbert.net/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1908.10084"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2004.09813"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2010.08240"
            ]
        ],
        "colab": "https://colab.research.google.com/github/UKPLab/sentence-transformers/blob/master/examples/applications/retrieve_rerank/retrieve_rerank_simple_wikipedia.ipynb",
        "update": 1701956185.0
    },
    {
        "name": "FLAML",
        "description": "Lightweight Python library that finds accurate machine learning models automatically, efficiently and economically",
        "author": [
            [
                "Chi Wang",
                "https://github.com/sonichi"
            ],
            [
                "Qingyun Wu",
                "https://qingyun-wu.github.io/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/microsoft/FLAML",
                3943
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2106.04815"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2005.01571"
            ],
            [
                "docs",
                "https://microsoft.github.io/FLAML/"
            ],
            [
                "yt",
                "https://www.youtube.com/channel/UCfU0zfFXHXdAd5x-WvFBk5A"
            ],
            [
                "yt",
                "https://youtu.be/euXpDYGgkGM"
            ],
            [
                "paper",
                "https://www.microsoft.com/en-us/research/publication/flaml-a-fast-and-lightweight-automl-library/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/microsoft/FLAML/blob/master/notebook/flaml_automl.ipynb",
        "update": 1639703493.0
    },
    {
        "name": "AutoGen",
        "description": "Framework that enables development of LLM applications using multiple agents that can converse with each other to solve tasks",
        "author": [
            [
                "microsoft",
                "https://github.com/microsoft"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/microsoft/autogen",
                35386
            ],
            [
                "project",
                "https://microsoft.github.io/autogen/"
            ],
            [
                "discord",
                "https://discord.gg/pAbnFJrkgZ"
            ],
            [
                "yt",
                "https://youtu.be/zdcCD--IieY"
            ],
            [
                "yt",
                "https://youtu.be/dCCr52uT0W8"
            ],
            [
                "yt",
                "https://youtu.be/JMpgsx74XDI"
            ],
            [
                "blog post",
                "https://www.microsoft.com/en-us/research/blog/autogen-enabling-next-generation-large-language-model-applications/"
            ],
            [
                "medium",
                "https://medium.com/@multiplatform.ai/microsoft-autogen-transforming-ai-frameworks-for-enhanced-problem-solving-video-ac2655e7cdf"
            ]
        ],
        "colab": "https://colab.research.google.com/github/microsoft/autogen/blob/main/python/packages/autogen-core/docs/src/user-guide/core-user-guide/quickstart.ipynb",
        "update": 1733274044.0
    },
    {
        "name": "TorchGeo",
        "description": "PyTorch domain library that provides datasets, transforms, samplers, and pre-trained models specific to geospatial data",
        "author": [
            [
                "Adam Stewart",
                "https://github.com/adamjstewart"
            ],
            [
                "Caleb Robinson",
                "https://calebrob.com/"
            ],
            [
                "Isaac Corley",
                "https://github.com/isaaccorley"
            ],
            [
                "Anthony Ortiz",
                "https://github.com/anthonymlortiz"
            ],
            [
                "Juan Lavista Ferres",
                "https://www.microsoft.com/en-us/research/people/jlavista/"
            ],
            [
                "Arindam Banerjee",
                "https://arindam.cs.illinois.edu/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/microsoft/torchgeo",
                2800
            ],
            [
                "git",
                "https://github.com/davemlz/awesome-spectral-indices"
            ],
            [
                "NDVI",
                "https://gisgeography.com/ndvi-normalized-difference-vegetation-index/"
            ],
            [
                "NDWI",
                "https://custom-scripts.sentinel-hub.com/custom-scripts/sentinel-2/ndwi/"
            ],
            [
                "NDBI",
                "https://www.linkedin.com/pulse/ndvi-ndbi-ndwi-calculation-using-landsat-7-8-tek-bahadur-kshetri/"
            ],
            [
                "data",
                "https://docs.sentinel-hub.com/api/latest/data/sentinel-2-l2a/"
            ],
            [
                "data",
                "https://www.cogeo.org/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2111.08872"
            ]
        ],
        "colab": "https://colab.research.google.com/github/microsoft/torchgeo/blob/main/docs/tutorials/indices.ipynb",
        "update": 1714757414.0
    },
    {
        "name": "Generative AI for Beginners - A Course",
        "description": "A 12 Lesson course teaching everything you need to know to start building Generative AI applications",
        "author": [
            [
                "microsoft",
                "https://www.microsoft.com/"
            ]
        ],
        "links": [
            [
                "project",
                "https://microsoft.github.io/generative-ai-for-beginners/"
            ],
            [
                "discord",
                "https://aka.ms/genai-discord"
            ],
            [
                "git",
                "https://github.com/microsoft/xr-development-for-beginners",
                482
            ],
            [
                "git",
                "https://github.com/microsoft/Web-Dev-For-Beginners"
            ]
        ],
        "colab": "https://colab.research.google.com/github/microsoft/generative-ai-for-beginners/blob/main/06-text-generation-apps/notebook-azure-openai.ipynb",
        "update": 1708594932.0
    },
    {
        "name": "Imagededup",
        "description": "This package provides functionality to make use of hashing algorithms that are particularly good at finding exact duplicates as well as convolutional neural networks which are also adept at finding near duplicates",
        "author": [
            [
                "Tanuj Jain",
                "https://github.com/tanujjain"
            ],
            [
                "Christopher Lennan",
                "https://github.com/clennan"
            ],
            [
                "Dat Tran",
                "https://dat-tran.com/"
            ]
        ],
        "links": [
            [
                "project",
                "https://idealo.github.io/imagededup/"
            ],
            [
                "git",
                "https://github.com/idealo/imagededup",
                5184
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1704.04861"
            ],
            [
                "medium",
                "https://fullstackml.com/wavelet-image-hash-in-python-3504fdd282b5"
            ]
        ],
        "colab": "https://colab.research.google.com/github/idealo/imagededup/blob/master/examples/CIFAR10_duplicates.ipynb",
        "update": 1570116455.0
    },
    {
        "name": "MLP",
        "description": "The most basic neural network architectures, a multilayer perceptron, also known as a feedforward network",
        "author": [
            [
                "Ben Trevett",
                "https://bentrevett.com/"
            ]
        ],
        "links": [
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Multilayer_perceptron"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1702.03118"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2108.12943"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2111.04020"
            ],
            [
                "pt",
                "https://pytorch.org/vision/stable/transforms.html#transforms-on-pil-image-only"
            ],
            [
                "pt",
                "https://pytorch.org/vision/stable/transforms.html#transforms-on-torch-tensor-only"
            ],
            [
                "optimization",
                "https://ruder.io/optimizing-gradient-descent/"
            ],
            [
                "NN and DL",
                "http://neuralnetworksanddeeplearning.com/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/bentrevett/pytorch-image-classification/blob/master/1_mlp.ipynb",
        "update": 1640520294.0
    },
    {
        "name": "LeNet",
        "description": "A neural network model that uses convolutional neural network layers and was designed for classifying handwritten characters",
        "author": [
            [
                "Ben Trevett",
                "https://bentrevett.com/"
            ]
        ],
        "links": [
            [
                "LeNet-5",
                "http://yann.lecun.com/exdb/lenet/"
            ],
            [
                "paper",
                "http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Convolution"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Sobel_operator"
            ],
            [
                "guide",
                "https://adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/"
            ],
            [
                "CNN",
                "https://cs231n.github.io/convolutional-networks/"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Gaussian_blur"
            ],
            [
                "pwc",
                "https://paperswithcode.com/method/lenet"
            ]
        ],
        "colab": "https://colab.research.google.com/github/bentrevett/pytorch-image-classification/blob/master/2_lenet.ipynb",
        "update": 1640519150.0
    },
    {
        "name": "AlexNet",
        "description": "A neural network model that uses convolutional neural network layers and was designed for the ImageNet challenge",
        "author": [
            [
                "Ben Trevett",
                "https://bentrevett.com/"
            ]
        ],
        "links": [
            [
                "neurips",
                "https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html"
            ],
            [
                "ILSVRC",
                "https://image-net.org/challenges/LSVRC/"
            ],
            [
                "cifar-10",
                "https://www.cs.toronto.edu/~kriz/cifar.html"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Regularization_(mathematics)"
            ],
            [
                "dropout",
                "https://sebastianraschka.com/faq/docs/dropout-activation.html"
            ],
            [
                "PMLR",
                "https://proceedings.mlr.press/v9/glorot10a.html"
            ],
            [
                "git",
                "https://github.com/davidtvs/pytorch-lr-finder",
                928
            ],
            [
                "LR",
                "https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1409.0575"
            ],
            [
                "pt",
                "https://pytorch.org/vision/stable/models.html"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/AlexNet"
            ],
            [
                "pwc",
                "https://paperswithcode.com/method/alexnet"
            ]
        ],
        "colab": "https://colab.research.google.com/github/bentrevett/pytorch-image-classification/blob/master/3_alexnet.ipynb",
        "update": 1640520294.0
    },
    {
        "name": "VGG",
        "description": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
        "author": [
            [
                "Ben Trevett",
                "https://bentrevett.com/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1409.1556"
            ],
            [
                "ILSVRC",
                "https://image-net.org/challenges/LSVRC/"
            ],
            [
                "cifar-10",
                "https://www.cs.toronto.edu/~kriz/cifar.html"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1506.01186"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1801.06146"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1502.03167"
            ],
            [
                "yt",
                "https://youtu.be/HR0lt1hlR6U?t=5900"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1805.11604"
            ],
            [
                "pt",
                "https://pytorch.org/vision/stable/models.html"
            ],
            [
                "git",
                "https://github.com/pytorch/vision/blob/main/torchvision/models/vgg.py#L47",
                16340
            ],
            [
                "pwc",
                "https://paperswithcode.com/method/vgg"
            ],
            [
                "yt",
                "https://youtu.be/j1jIoHN3m0s"
            ],
            [
                "yt",
                "https://youtu.be/RNnKtNrsrmg"
            ]
        ],
        "colab": "https://colab.research.google.com/github/bentrevett/pytorch-image-classification/blob/master/4_vgg.ipynb",
        "update": 1640520294.0
    },
    {
        "name": "Semantic Segmentation",
        "description": "Pytorch implementation for Semantic Segmentation/Scene Parsing on MIT ADE20K dataset",
        "author": [
            [
                "Bolei Zhou",
                "https://boleizhou.github.io/"
            ],
            [
                "Hang Zhao",
                "https://hangzhaomit.github.io/"
            ],
            [
                "Xavier Puig",
                "https://people.csail.mit.edu/xavierpuig/"
            ],
            [
                "Sanja Fidler",
                "http://www.cs.toronto.edu/~fidler/index.html"
            ],
            [
                "Antonio Torralba",
                "https://groups.csail.mit.edu/vision/torralbalab/"
            ]
        ],
        "links": [
            [
                "project",
                "http://sceneparsing.csail.mit.edu/"
            ],
            [
                "git",
                "https://github.com/CSAILVision/semantic-segmentation-pytorch",
                4956
            ],
            [
                "git",
                "https://github.com/CSAILVision/sceneparsing"
            ],
            [
                "git",
                "https://github.com/vacancy/Synchronized-BatchNorm-PyTorch"
            ],
            [
                "git",
                "https://github.com/hszhao/semseg"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1608.05442"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1612.01105"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1807.10221"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1904.04514"
            ]
        ],
        "colab": "https://colab.research.google.com/github/CSAILVision/semantic-segmentation-pytorch/blob/master/notebooks/DemoSegmenter.ipynb",
        "update": 1597999460.0
    },
    {
        "name": "Real-Time Voice Cloning",
        "description": "SV2TTS with a vocoder that works in real-time",
        "author": [
            [
                "Corentin Jemine",
                "https://github.com/CorentinJ"
            ],
            [
                "Erdene-Ochir Tuguldur",
                "https://github.com/tugstugi"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/CorentinJ/Real-Time-Voice-Cloning",
                52880
            ],
            [
                "git",
                "https://github.com/fatchord/WaveRNN"
            ],
            [
                "git",
                "https://github.com/coqui-ai/tts"
            ],
            [
                "git",
                "https://github.com/resemble-ai/Resemblyzer"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1806.04558"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1802.08435"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1703.10135"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1710.10467"
            ],
            [
                "yt",
                "https://youtu.be/-O_hYhToKoA"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tugstugi/dl-colab-notebooks/blob/master/notebooks/RealTimeVoiceCloning.ipynb",
        "update": 1646694224.0
    },
    {
        "name": "NeMo",
        "description": "A conversational AI toolkit built for researchers working on automatic speech recognition, natural language processing, and text-to-speech synthesis",
        "author": [
            [
                "Oleksii Kuchaiev",
                "http://kuchaev.com/"
            ],
            [
                "Jason Li",
                "https://scholar.google.com/citations?user=V28bxDwAAAAJ"
            ],
            [
                "Chip Huyen",
                "https://huyenchip.com/"
            ],
            [
                "Oleksii Hrinchuk",
                "https://github.com/AlexGrinch"
            ],
            [
                "Ryan Leary",
                "https://github.com/ryanleary"
            ],
            [
                "Boris Ginsburg",
                "https://github.com/borisgin"
            ],
            [
                "Samuel Kriman",
                "https://github.com/sam1373"
            ],
            [
                "Stanislav Beliaev",
                "https://github.com/stasbel"
            ],
            [
                "Vitaly Lavrukhin",
                "https://github.com/vsl9"
            ],
            [
                "Jack Cook",
                "https://jackcook.com/"
            ]
        ],
        "links": [
            [
                "project",
                "https://docs.nvidia.com/deeplearning/nemo/"
            ],
            [
                "yt",
                "https://youtu.be/wBgpMf_KQVw"
            ],
            [
                "git",
                "https://github.com/NVIDIA/NeMo",
                12336
            ]
        ],
        "colab": "https://colab.research.google.com/github/NVIDIA/NeMo/blob/master/tutorials/00_NeMo_Primer.ipynb",
        "update": 1716610723.0
    },
    {
        "name": "TensorRT",
        "description": "SDK for high-performance deep learning inference, includes a deep learning inference optimizer and runtime that delivers low latency and high throughput for inference applications",
        "author": [
            [
                "nvidia",
                "https://developer.nvidia.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/NVIDIA/TensorRT",
                10893
            ],
            [
                "website",
                "https://developer.nvidia.com/tensorrt"
            ],
            [
                "blog post",
                "https://developer.nvidia.com/blog/speeding-up-deep-learning-inference-using-tensorrt-updated/"
            ],
            [
                "docs",
                "https://docs.nvidia.com/deeplearning/tensorrt/"
            ],
            [
                "forum",
                "https://forums.developer.nvidia.com/c/ai-data-science/deep-learning/tensorrt"
            ],
            [
                "yt",
                "https://youtu.be/TU5BMU6iYZ0"
            ],
            [
                "yt",
                "https://youtu.be/6rZNLaS775w"
            ],
            [
                "yt",
                "https://youtu.be/G_KhUFCUSsY"
            ],
            [
                "yt",
                "https://youtu.be/7kJ-jph9gCw"
            ]
        ],
        "colab": "https://colab.research.google.com/github/NVIDIA/TensorRT/blob/main/quickstart/IntroNotebooks/0.%20Running%20This%20Guide.ipynb",
        "update": 1726100810.0
    },
    {
        "name": "DeepStyle",
        "description": "The Neural Style algorithm synthesizes a pastiche by separating and combining the content of one image with the style of another image using convolutional neural networks",
        "author": [
            [
                "Cameron Smith",
                "https://github.com/cysmith"
            ],
            [
                "Alexander Spirin",
                "https://github.com/Sxela"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/cysmith/neural-style-tf",
                3105
            ],
            [
                "cvpr",
                "https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1604.08610"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1606.05897"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1508.06576"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Pastiche"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/The_Starry_Night"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/YUV"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Lab_color_space"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/YCbCr"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/CIELUV"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Pareidolia"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/14aJ7HQPbcP0sNRIY-FRO4u6lxtlyyxI_",
        "update": 1633120599.161
    },
    {
        "name": "Silero Models",
        "description": "Pre-trained speech-to-text, text-to-speech and text-enhancement models made embarrassingly simple",
        "author": [
            [
                "Silero team",
                "https://www.silero.ai/about/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/snakers4/silero-models",
                5015
            ],
            [
                "website",
                "https://www.silero.ai/"
            ],
            [
                "STT",
                "https://thegradient.pub/towards-an-imagenet-moment-for-speech-to-text/"
            ],
            [
                "STT",
                "https://thegradient.pub/a-speech-to-text-practitioners-criticisms-of-industry-and-academia/"
            ],
            [
                "STT",
                "https://habr.com/ru/post/519562/"
            ],
            [
                "TTS",
                "https://habr.com/ru/post/660571/"
            ],
            [
                "TTS",
                "https://habr.com/ru/post/549482/"
            ],
            [
                "VAD",
                "https://thegradient.pub/one-voice-detector-to-rule-them-all/"
            ],
            [
                "VAD",
                "https://habr.com/ru/post/537276/"
            ],
            [
                "Text Enhancement",
                "https://habr.com/ru/post/581960/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/snakers4/silero-models/blob/master/examples.ipynb",
        "update": 1645989642.0
    },
    {
        "name": "Cirq",
        "description": "A python framework for creating, editing, and invoking Noisy Intermediate Scale Quantum circuits",
        "author": [
            [
                "Balint Pato",
                "https://refactorium.com/"
            ],
            [
                "Matthew Harrigan",
                "https://mpharrigan.com/"
            ],
            [
                "Animesh Sinha",
                "https://github.com/AnimeshSinha1309"
            ],
            [
                "Matthew Neeley",
                "https://github.com/maffoo"
            ],
            [
                "Dave Bacon",
                "https://dabacon.org/"
            ],
            [
                "Matteo Pompili",
                "https://github.com/matpompili"
            ],
            [
                "Michael Broughton",
                "https://github.com/MichaelBroughton"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/quantumlib/Cirq",
                4295
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Quantum_logic_gate#Hadamard_gate"
            ],
            [
                "yt",
                "https://youtu.be/16ZfkPRVf2w"
            ]
        ],
        "colab": "https://colab.research.google.com/github/quantumlib/Cirq/blob/master/docs/tutorials/basics.ipynb",
        "update": 1655847519.0
    },
    {
        "name": "Neural Tangents",
        "description": "Library designed to enable research into infinite-width neural networks",
        "author": [
            [
                "Roman Novak",
                "https://github.com/romanngg"
            ],
            [
                "Lechao Xiao",
                "https://sites.google.com/site/lechaoxiao/"
            ],
            [
                "Jiri Hron",
                "https://sites.google.com/view/jirihron"
            ],
            [
                "Jaehoon Lee",
                "https://jaehlee.github.io/"
            ],
            [
                "Alexander Alemi",
                "https://www.alexalemi.com/"
            ],
            [
                "Jascha Sohl-Dickstein",
                "https://sohldickstein.com/"
            ],
            [
                "Samuel Schoenholz",
                "https://scholar.google.com/citations?user=mk-zQBsAAAAJ"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/google/neural-tangents",
                2286
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1912.02803"
            ],
            [
                "docs",
                "https://neural-tangents.readthedocs.io/en/latest/"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Neural_network_Gaussian_process"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Neural_tangent_kernel"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1605.07146"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1902.06720"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1806.07572"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2001.07301"
            ],
            [
                "arxiv",
                "https://arxiv.org/2003.02237"
            ],
            [
                "ICLR",
                "https://iclr.cc/virtual_2020/poster_SklD9yrFPS.html"
            ],
            [
                "pypi",
                "https://pypi.org/project/neural-tangents/"
            ],
            [
                "medium",
                "https://towardsdatascience.com/infinitely-wide-neural-networks-neural-tangents-explained-d6c6d896fcbf"
            ],
            [
                "yt",
                "https://youtu.be/VUX2bsrYag8"
            ]
        ],
        "colab": "https://colab.research.google.com/github/google/neural-tangents/blob/main/notebooks/neural_tangents_cookbook.ipynb",
        "update": 1693328686.0
    },
    {
        "name": "SeqIO",
        "description": "Library for processing sequential data to be fed into downstream sequence models",
        "author": [
            [
                "Adam Roberts",
                "https://github.com/adarob"
            ],
            [
                "Hyung Won Chung",
                "https://github.com/hwchung27"
            ],
            [
                "Anselm Levskaya",
                "https://anselmlevskaya.com/"
            ],
            [
                "Gaurav Mishra",
                "https://github.com/gauravmishra"
            ],
            [
                "James Bradbury",
                "https://github.com/jekbradbury"
            ],
            [
                "Daniel Andor",
                "https://github.com/andorardo"
            ],
            [
                "Sharan Narang",
                "https://github.com/sharannarang"
            ],
            [
                "Brian Lester",
                "https://blester125.com/"
            ],
            [
                "Colin Gaffney",
                "https://github.com/cpgaffney1"
            ],
            [
                "Afroz Mohiuddin",
                "https://github.com/afrozenator"
            ],
            [
                "Curtis Hawthorne",
                "https://github.com/cghawthorne"
            ],
            [
                "Aitor Lewkowycz",
                "https://scholar.google.com/citations?user=Yum1ah0AAAAJ"
            ],
            [
                "Alex Salcianu",
                "https://scholar.google.com/citations?user=HSrT1wsAAAAJ"
            ],
            [
                "Marc van Zee",
                "https://github.com/marcvanzee"
            ],
            [
                "Jacob Austin",
                "https://jacobaustin123.github.io/"
            ],
            [
                "Sebastian Goodman",
                "https://github.com/0x0539"
            ],
            [
                "Livio Baldini Soares",
                "https://liviosoares.github.io/"
            ],
            [
                "Haitang Hu",
                "https://hthu.github.io/"
            ],
            [
                "Sasha Tsvyashchenko",
                "https://endl.ch/"
            ],
            [
                "Aakanksha Chowdhery",
                "http://www.achowdhery.com/"
            ],
            [
                "Jasmijn Bastings",
                "https://jasmijn.ninja/"
            ],
            [
                "Jannis Bulian",
                "http://bulian.org/"
            ],
            [
                "Xavier Garcia",
                "https://scholar.google.com/citations?user=Y2Hio6MAAAAJ"
            ],
            [
                "Jianmo Ni",
                "https://nijianmo.github.io/"
            ],
            [
                "Andrew Chen",
                "https://github.com/andrewluchen"
            ],
            [
                "Kathleen Kenealy",
                "https://github.com/kkenealy"
            ],
            [
                "Jonathan Clark",
                "http://www.cs.cmu.edu/~jhclark/"
            ],
            [
                "Stephan Lee",
                "https://github.com/stephanwlee"
            ],
            [
                "Dan Garrette",
                "https://www.dhgarrette.com/"
            ],
            [
                "James Lee-Thorp",
                "https://scholar.google.com/citations?user=qsPv098AAAAJ"
            ],
            [
                "Colin Raffel",
                "https://www.colinraffel.com/"
            ],
            [
                "Noam Shazeer",
                "https://github.com/nshazeer"
            ],
            [
                "Marvin Ritter",
                "https://github.com/Marvin182"
            ],
            [
                "Maarten Bosma",
                "https://scholar.google.com/citations?user=wkeFQPgAAAAJ"
            ],
            [
                "Alexandre Passos",
                "https://www.ic.unicamp.br/~tachard/"
            ],
            [
                "Jeremy Maitin-Shepard",
                "https://research.google/people/JeremyMaitinShepard/"
            ],
            [
                "Noah Fiedel",
                "https://scholar.google.com/citations?user=XWpV9DsAAAAJ"
            ],
            [
                "Mark Omernick",
                "https://github.com/markomernick"
            ],
            [
                "Brennan Saeta",
                "https://github.com/saeta"
            ],
            [
                "Ryan Sepassi",
                "https://ryansepassi.com/"
            ],
            [
                "Alexander Spiridonov",
                "https://research.google/people/AlexanderSpiridonov/"
            ],
            [
                "Joshua Newlan",
                "https://github.com/joshnewlan"
            ],
            [
                "Andrea Gesmundo",
                "https://github.com/agesmundo"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/google/seqio",
                564
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2203.17189"
            ],
            [
                "docs",
                "https://seqio.readthedocs.io/en/latest/"
            ],
            [
                "tf",
                "https://www.tensorflow.org/api_docs/python/tf/data/Dataset"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1910.10683"
            ],
            [
                "tf",
                "https://www.tensorflow.org/datasets"
            ],
            [
                "tf",
                "https://www.tensorflow.org/tutorials/load_data/tfrecord"
            ],
            [
                "tf",
                "https://www.tensorflow.org/guide/function#autograph_transformations"
            ],
            [
                "tf",
                "https://www.tensorflow.org/api_docs/python/tf/py_function"
            ],
            [
                "tf",
                "https://www.tensorflow.org/guide/random_numbers#stateless_rngs"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1810.04805"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2002.08910"
            ]
        ],
        "colab": "https://colab.research.google.com/github/google/seqio/blob/main/seqio/notebooks/Evaluation.ipynb",
        "update": 1694207397.0
    },
    {
        "name": "dm_control",
        "description": "DeepMind Infrastructure for Physics-Based Simulation",
        "author": [
            [
                "Saran Tunyasuvunakool",
                "https://github.com/saran-t"
            ],
            [
                "Alistair Muldal",
                "https://github.com/alimuldal"
            ],
            [
                "Yotam Doron",
                "http://www.yotamdoron.com/"
            ],
            [
                "Siqi Liu",
                "http://siqi.fr/"
            ],
            [
                "Steven Bohez",
                "https://github.com/sbohez"
            ],
            [
                "Josh Merel",
                "https://sites.google.com/site/jsmerel/"
            ],
            [
                "Tom Erez",
                "https://github.com/erez-tom"
            ],
            [
                "Timothy Lillicrap",
                "https://contrastiveconvergence.net/~timothylillicrap/index.php"
            ],
            [
                "Nicolas Heess",
                "https://scholar.google.com/citations?user=79k7bGEAAAAJ"
            ],
            [
                "Yuval Tassa",
                "https://github.com/yuvaltassa"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/deepmind/dm_control",
                3831
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2006.12983"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Tippe_top"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1801.00690"
            ],
            [
                "yt",
                "https://youtu.be/CMjoiU482Jk"
            ],
            [
                "yt",
                "https://youtu.be/rAai4QzcYbs"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1902.07151"
            ],
            [
                "blog post",
                "https://www.deepmind.com/publications/dm-control-software-and-tasks-for-continuous-control"
            ],
            [
                "yt",
                "https://youtu.be/WhaRsrlaXLk"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1707.02286"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1802.09564"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1802.10567"
            ]
        ],
        "colab": "https://colab.research.google.com/github/deepmind/dm_control/blob/master/tutorial.ipynb",
        "update": 1733260189.0
    },
    {
        "name": "MuJoCo",
        "description": "A general purpose physics engine that aims to facilitate research and development in robotics, biomechanics, graphics and animation, machine learning, and other areas which demand fast and accurate simulation of articulated structures interacting with their environment",
        "author": [
            [
                "Emo Todorov",
                "https://homes.cs.washington.edu/~todorov/"
            ],
            [
                "Tom Erez",
                "https://github.com/erez-tom"
            ],
            [
                "Yuval Tassa",
                "https://github.com/yuvaltassa"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/deepmind/mujoco",
                8301
            ],
            [
                "docs",
                "https://mujoco.readthedocs.io/en/latest/overview.html"
            ],
            [
                "website",
                "https://mujoco.org/"
            ],
            [
                "deepmind",
                "https://www.deepmind.com/blog/opening-up-a-physics-simulator-for-robotics"
            ],
            [
                "deepmind",
                "https://www.deepmind.com/blog/open-sourcing-mujoco"
            ],
            [
                "yt",
                "https://youtu.be/0ORsj_E17B0"
            ],
            [
                "yt",
                "https://youtu.be/yHZVVfsJ8mc"
            ],
            [
                "yt",
                "https://youtu.be/eyzzsGJ1iic"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Tippe_top"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Chaos_theory"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/3D_projection#Mathematical_formula"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2006.12983"
            ]
        ],
        "colab": "https://colab.research.google.com/github/deepmind/dm_control/blob/master/dm_control/mujoco/tutorial.ipynb",
        "update": 1733260189.0
    },
    {
        "name": "Haiku",
        "description": "A library built on top of JAX designed to provide simple, composable abstractions for machine learning research",
        "author": [
            [
                "Tom Hennigan",
                "https://github.com/tomhennigan"
            ],
            [
                "Trevor Cai",
                "https://github.com/trevorcai"
            ],
            [
                "Tamara Norman",
                "https://github.com/tamaranorman"
            ],
            [
                "Igor Babuschkin",
                "https://www.babushk.in/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/deepmind/dm-haiku",
                2913
            ],
            [
                "docs",
                "https://dm-haiku.readthedocs.io/en/latest/"
            ],
            [
                "website",
                "https://www.haiku-os.org/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/deepmind/dm-haiku/blob/main/examples/haiku_lstms.ipynb",
        "update": 1677762935.0
    },
    {
        "name": "Epistemic Neural Networks",
        "description": "A library for neural networks that know what they don't know",
        "author": [
            [
                "Ian Osband",
                "http://iosband.github.io/"
            ],
            [
                "Zheng Wen",
                "http://zheng-wen.com/"
            ],
            [
                "Seyed Mohammad Asghari",
                "https://github.com/mohammadasghari"
            ],
            [
                "Vikranth Dwaracherla",
                "https://github.com/dvikranth"
            ],
            [
                "Morteza Ibrahimi",
                "https://github.com/mibrahimi"
            ],
            [
                "Xiuyuan Lu",
                "https://scholar.google.com/citations?user=SPL_2lIAAAAJ"
            ],
            [
                "Benjamin Van Roy",
                "https://web.stanford.edu/~bvr/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2107.08924"
            ],
            [
                "git",
                "https://github.com/deepmind/enn",
                296
            ],
            [
                "yt",
                "https://youtu.be/j8an0dKcX4A"
            ],
            [
                "medium",
                "https://medium.com/syncedreview/deepminds-epistemic-neural-networks-open-new-avenues-for-uncertainty-modelling-in-large-and-fa83ab00aba3"
            ]
        ],
        "colab": "https://colab.research.google.com/github/deepmind/enn/blob/master/enn/colabs/enn_demo.ipynb",
        "update": 1687819550.0
    },
    {
        "name": "ACME",
        "description": "A library of reinforcement learning components and agents",
        "author": [
            [
                "Matt Hoffman",
                "https://www.mwhoffman.com/"
            ],
            [
                "Bobak Shahriari",
                "https://github.com/bshahr"
            ],
            [
                "John Aslanides",
                "https://www.aslanides.io/"
            ],
            [
                "Gabriel Barth-Maron",
                "https://github.com/fastturtle"
            ],
            [
                "Feryal Behbahani",
                "https://feryal.github.io/"
            ],
            [
                "Tamara Norman",
                "https://github.com/tamaranorman"
            ],
            [
                "Abbas Abdolmaleki",
                "https://scholar.google.com/citations?user=cCYTVWQAAAAJ"
            ],
            [
                "Albin Cassirer",
                "https://github.com/acassirer"
            ],
            [
                "Fan Yang",
                "https://github.com/ddmbr"
            ],
            [
                "Kate Baumli",
                "https://github.com/katebaumli"
            ],
            [
                "Sarah Henderson",
                "https://www.linkedin.com/in/sarah-henderson-agilecoach/"
            ],
            [
                "Alex Novikov",
                "https://scholar.google.ru/citations?user=jMUkLqwAAAAJ"
            ],
            [
                "Sergio Gómez Colmenarejo",
                "https://scholar.google.ru/citations?user=0Dkf68EAAAAJ"
            ],
            [
                "Serkan Cabi",
                "https://scholar.google.ru/citations?&user=l-HhJaUAAAAJ"
            ],
            [
                "Caglar Gulcehre",
                "https://www.caglarg.com/"
            ],
            [
                "Tom Le Paine",
                "http://tomlepaine.github.io/"
            ],
            [
                "Andrew Cowie",
                "https://scholar.google.ru/citations?&user=aTvi5mUAAAAJ"
            ],
            [
                "Ziyu Wang",
                "https://ziyuw.github.io/"
            ],
            [
                "Bilal Piot",
                "https://scholar.google.ru/citations?&user=fqxNUREAAAAJ"
            ],
            [
                "Nando de Freitas",
                "https://github.com/nandodf"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/deepmind/acme",
                3527
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2006.00979"
            ],
            [
                "docs",
                "https://dm-acme.readthedocs.io/en/latest/"
            ],
            [
                "git",
                "https://github.com/deepmind/dm_env"
            ],
            [
                "yt",
                "https://youtu.be/NUwDr42bPOw"
            ],
            [
                "yt",
                "https://youtu.be/J1XCWjuyRaI"
            ],
            [
                "yt",
                "https://youtu.be/pFMuQWpHI5k"
            ],
            [
                "blog post",
                "https://www.deepmind.com/publications/acme-a-new-framework-for-distributed-reinforcement-learning"
            ]
        ],
        "colab": "https://colab.research.google.com/github/deepmind/acme/blob/master/examples/tutorial.ipynb",
        "update": 1664192177.0
    },
    {
        "name": "Sonnet",
        "description": "Library built on top of TensorFlow 2 designed to provide simple, composable abstractions for machine learning research",
        "author": [
            [
                "Malcolm Reynolds",
                "https://github.com/malcolmreynolds"
            ],
            [
                "Jack Rae",
                "https://github.com/dm-jrae"
            ],
            [
                "Andreas Fidjeland",
                "https://github.com/akfidjeland"
            ],
            [
                "Fabio Viola",
                "https://github.com/fabioviola"
            ],
            [
                "Adrià Puigdomènech",
                "https://github.com/adria-p"
            ],
            [
                "Frederic Besse",
                "https://github.com/fbesse"
            ],
            [
                "Tim Green",
                "http://tfgg.me/"
            ],
            [
                "Sébastien Racanière",
                "https://scholar.google.com/citations?user=o-h0vrQAAAAJ"
            ],
            [
                "Gabriel Barth-Maron",
                "https://github.com/fastturtle"
            ],
            [
                "Diego Casas",
                "https://github.com/diegolascasas"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/deepmind/sonnet",
                9785
            ],
            [
                "docs",
                "https://sonnet.readthedocs.io/en/latest/index.html"
            ],
            [
                "deepmind",
                "https://www.deepmind.com/blog/open-sourcing-sonnet-a-new-library-for-constructing-neural-networks"
            ],
            [
                "yt",
                "https://youtu.be/rlpQjnUvoKw"
            ],
            [
                "tf",
                "https://www.tensorflow.org/guide/checkpoint"
            ],
            [
                "tf",
                "https://www.tensorflow.org/guide/saved_model"
            ],
            [
                "neurips",
                "https://papers.nips.cc/paper/2016/hash/fb87582825f9d28a8d42c5e5e5e8b23d-Abstract.html"
            ]
        ],
        "colab": "https://colab.research.google.com/github/deepmind/sonnet/blob/v2/examples/little_gan_on_mnist.ipynb",
        "update": 1587111581.0
    },
    {
        "name": "bsuite",
        "description": "A collection of carefully-designed experiments that investigate core capabilities of an RL agent with two main objectives",
        "author": [
            [
                "Ian Osband",
                "http://iosband.github.io/"
            ],
            [
                "Yotam Doron",
                "http://www.yotamdoron.com/"
            ],
            [
                "Matteo Hessel",
                "https://github.com/mtthss"
            ],
            [
                "John Aslanides",
                "https://www.aslanides.io/"
            ],
            [
                "Eren Sezener",
                "http://erensezener.com/"
            ],
            [
                "Andre Saraiva",
                "https://andresnds.wordpress.com/"
            ],
            [
                "Katrina McKinney",
                "https://medium.com/@katrinamckinney"
            ],
            [
                "Tor Lattimore",
                "http://tor-lattimore.com/"
            ],
            [
                "Csaba Szepesvari",
                "https://sites.ualberta.ca/~szepesva/"
            ],
            [
                "Satinder Singh",
                "http://web.eecs.umich.edu/~baveja/"
            ],
            [
                "Benjamin Van Roy",
                "https://web.stanford.edu/~bvr/"
            ],
            [
                "Richard Sutton",
                "http://www.incompleteideas.net/"
            ],
            [
                "David Silver",
                "https://www.davidsilver.uk/"
            ],
            [
                "Hado Van Hasselt",
                "https://hadovanhasselt.com/"
            ]
        ],
        "links": [
            [
                "paper",
                "https://openreview.net/forum?id=rygf-kSYwH"
            ],
            [
                "git",
                "https://github.com/deepmind/bsuite",
                1513
            ],
            [
                "git",
                "https://github.com/openai/gym"
            ],
            [
                "yt",
                "https://youtu.be/Wcv4eU_qtZU"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1rU20zJ281sZuMD1DHbsODFr1DbASL0RH",
        "update": 1613174366.054
    },
    {
        "name": "PGMax",
        "description": "General factor graphs for discrete probabilistic graphical models, and hardware-accelerated differentiable loopy belief propagation in JAX",
        "author": [
            [
                "Guangyao Zhou",
                "https://stanniszhou.github.io/"
            ],
            [
                "Nishanth Kumar",
                "http://nishanthjkumar.com/"
            ],
            [
                "Antoine Dedieu",
                "https://github.com/antoine-dedieu"
            ],
            [
                "Miguel Lázaro-Gredilla",
                "https://www.tsc.uc3m.es/~miguel/"
            ],
            [
                "Shrinu Kushagra",
                "https://cs.uwaterloo.ca/~skushagr/"
            ],
            [
                "Dileep George",
                "https://dileeplearning.github.io/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/deepmind/PGMax",
                131
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2202.04110"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Belief_propagation"
            ]
        ],
        "colab": "https://colab.research.google.com/github/deepmind/PGMax/blob/main/examples/rcn.ipynb",
        "update": 1683304710.0
    },
    {
        "name": "RL Unplugged",
        "description": "Suite of benchmarks for offline reinforcement learning",
        "author": [
            [
                "Caglar Gulcehre",
                "https://www.caglarg.com/"
            ],
            [
                "Ziyu Wang",
                "https://ziyuw.github.io/"
            ],
            [
                "Alexander Novikov",
                "https://scholar.google.com/citations?user=jMUkLqwAAAAJ"
            ],
            [
                "Tom Le Paine",
                "http://tomlepaine.github.io/"
            ],
            [
                "Sergio Gómez Colmenarejo",
                "https://scholar.google.com/citations?user=0Dkf68EAAAAJ"
            ],
            [
                "Konrad Żołna",
                "https://github.com/kondiz"
            ],
            [
                "Rishabh Agarwal",
                "https://agarwl.github.io/"
            ],
            [
                "Josh Merel",
                "https://sites.google.com/site/jsmerel/"
            ],
            [
                "Daniel Mankowitz",
                "https://danielmankowitz.wixsite.com/danielm"
            ],
            [
                "Cosmin Paduraru",
                "https://scholar.google.com/citations?user=oz4Ca9AAAAAJ"
            ],
            [
                "Gabriel Dulac-Arnold",
                "http://gabe.squirrelsoup.net/"
            ],
            [
                "Jerry Li",
                "https://github.com/jerryli27"
            ],
            [
                "Mohammad Norouzi",
                "https://norouzi.github.io/"
            ],
            [
                "Matt Hoffman",
                "https://www.mwhoffman.com/"
            ],
            [
                "Ofir Nachum",
                "https://scholar.google.com/citations?user=C-ZlBWMAAAAJ"
            ],
            [
                "George Tucker",
                "https://sites.google.com/view/gjt"
            ],
            [
                "Nicolas Heess",
                "https://scholar.google.com/citations?user=79k7bGEAAAAJ"
            ],
            [
                "Nando de Freitas",
                "https://github.com/nandodf"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/deepmind/deepmind-research/tree/master/rl_unplugged",
                13307
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2006.13888"
            ],
            [
                "data",
                "https://console.cloud.google.com/storage/browser/rl_unplugged"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1907.04543"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1709.06009"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1811.09656"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1811.11711"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1909.12238"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1911.09451"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1801.00690"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2003.11881"
            ],
            [
                "git",
                "https://github.com/deepmind/lab"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2103.09575"
            ],
            [
                "yt",
                "https://youtu.be/n8yNYzbUMJ0"
            ],
            [
                "git",
                "https://github.com/google-research/realworldrl_suite#installation"
            ]
        ],
        "colab": "https://colab.research.google.com/github/deepmind/deepmind_research/blob/master/rl_unplugged/dmlab_r2d2.ipynb",
        "update": 1653583353.0
    },
    {
        "name": "Jraph",
        "description": "library for graph neural networks in jax",
        "author": [
            [
                "Jonathan Godwin",
                "https://github.com/jg8610"
            ],
            [
                "Thomas Keck",
                "https://github.com/thomaskeck"
            ],
            [
                "Peter Battaglia",
                "https://scholar.google.com/citations?user=nQ7Ij30AAAAJ"
            ],
            [
                "Victor Bapst",
                "https://linkedin.com/in/victor-bapst-73430a89"
            ],
            [
                "Thomas Kipf",
                "https://tkipf.github.io/"
            ],
            [
                "Yujia Li",
                "https://yujiali.github.io/"
            ],
            [
                "Kimberly Stachenfeld",
                "https://neurokim.com/"
            ],
            [
                "Petar Veličković",
                "https://petar-v.com/"
            ],
            [
                "Alvaro Sanchez-Gonzalez",
                "https://github.com/alvarosg"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/google-deepmind/jraph",
                1379
            ],
            [
                "docs",
                "https://jraph.readthedocs.io/en/latest/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1806.01261"
            ],
            [
                "yt",
                "https://youtu.be/S3sRy4oqvCM"
            ]
        ],
        "colab": "https://colab.research.google.com/github/google-deepmind/educational/blob/master/colabs/summer_schools/intro_to_graph_nets_tutorial_with_jraph.ipynb",
        "update": 1649977960.0
    },
    {
        "name": "XManager",
        "description": "Framework for managing machine learning experiment",
        "author": [
            [
                "Andrew Chen",
                "https://github.com/andrewluchen"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/google-deepmind/xmanager",
                821
            ],
            [
                "slides",
                "https://storage.googleapis.com/gresearch/xmanager/deepmind_xmanager_slides.pdf"
            ],
            [
                "pypi",
                "https://pypi.org/project/xmanager/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/google-deepmind/xmanager/blob/main/colab_codelab.ipynb",
        "update": 1659116251.0
    },
    {
        "name": "Reverb",
        "description": "Efficient and easy-to-use data storage and transport system designed for machine learning research",
        "author": [
            [
                "Albin Cassirer",
                "https://github.com/acassirer"
            ],
            [
                "Gabriel Barth-Maron",
                "https://github.com/fastturtle"
            ],
            [
                "Eugene Brevdo",
                "https://ebrevdo.github.io/"
            ],
            [
                "Sabela Ramos",
                "https://github.com/sabelaraga"
            ],
            [
                "Toby Boyd",
                "https://github.com/tfboyd"
            ],
            [
                "Thibault Sottiaux",
                "https://github.com/thso"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/google-deepmind/reverb",
                709
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2102.04736"
            ],
            [
                "pypi",
                "https://pypi.org/project/dm-reverb/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1801.01290"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1509.02971"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1707.01495"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1511.05952"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1804.08617"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1802.01561"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1707.06347"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/reinforcementlearning/comments/lhnrkd/reverb_a_framework_for_experience_replay/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/deepmind/reverb/blob/master/examples/demo.ipynb",
        "update": 1684853783.0
    },
    {
        "name": "Accelerate",
        "description": "A simple way to train and use PyTorch models with multi-GPU, TPU, mixed-precision",
        "author": [
            [
                "Hugging Face",
                "https://huggingface.co/"
            ]
        ],
        "links": [
            [
                "docs",
                "https://huggingface.co/docs/accelerate/index"
            ],
            [
                "git",
                "https://github.com/huggingface/accelerate",
                8020
            ]
        ],
        "colab": "https://colab.research.google.com/github/huggingface/notebooks/blob/master/examples/accelerate/simple_nlp_example.ipynb",
        "update": 1658923497.0
    },
    {
        "name": "Diffusers",
        "description": "Provides pretrained diffusion models across multiple modalities, such as vision and audio, and serves as a modular toolbox for inference and training of diffusion models",
        "author": [
            [
                "Hugging Face",
                "https://huggingface.co/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/huggingface/diffusers",
                26470
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2006.11239"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2006.11239"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2010.02502"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2202.09778"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2204.13902"
            ],
            [
                "git",
                "https://github.com/hojonathanho/diffusion"
            ],
            [
                "git",
                "https://github.com/pesser/pytorch_diffusion"
            ],
            [
                "git",
                "https://github.com/ermongroup/ddim"
            ],
            [
                "git",
                "https://github.com/heejkoo/Awesome-Diffusion-Models"
            ],
            [
                "yt",
                "https://youtu.be/UzkdOg7wWmI"
            ],
            [
                "medium",
                "https://towardsdatascience.com/hugging-face-just-released-the-diffusers-library-846f32845e65"
            ],
            [
                "hf",
                "https://huggingface.co/spaces/CompVis/text2img-latent-diffusion"
            ],
            [
                "hf",
                "https://huggingface.co/spaces/CompVis/celeba-latent-diffusion"
            ],
            [
                "hf",
                "https://huggingface.co/spaces/fusing/celeba-diffusion"
            ],
            [
                "hf",
                "https://huggingface.co/spaces/huggingface/diffuse-the-rest"
            ],
            [
                "hf",
                "https://huggingface.co/spaces/Shuang59/Composable-Diffusion"
            ]
        ],
        "colab": "https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/diffusers_intro.ipynb",
        "update": 1673949411.0
    },
    {
        "name": "Deep RL Course",
        "description": "The Hugging Face Deep Reinforcement Learning Course",
        "author": [
            [
                "Thomas Simonini",
                "https://www.simoninithomas.com/"
            ],
            [
                "Omar Sanseviero",
                "https://osanseviero.github.io/hackerllama/"
            ],
            [
                "Sayak Paul",
                "https://sayak.dev/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/huggingface/deep-rl-class",
                3920
            ],
            [
                "hf",
                "https://huggingface.co/deep-rl-course/unit0/introduction"
            ],
            [
                "syllabus",
                "https://simoninithomas.github.io/deep-rl-course"
            ],
            [
                "git",
                "https://github.com/alex-petrenko/sample-factory"
            ],
            [
                "pt",
                "https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html"
            ],
            [
                "yt",
                "https://youtu.be/2GwBez0D20A"
            ],
            [
                "hf",
                "https://huggingface.co/spaces/huggingface-projects/Deep-Reinforcement-Learning-Leaderboard"
            ],
            [
                "yt",
                "https://youtu.be/CsuIANBnSq8"
            ],
            [
                "yt",
                "https://youtu.be/AQKAOXJa6qg"
            ]
        ],
        "colab": "https://colab.research.google.com/github/huggingface/deep-rl-class/blob/main/notebooks/unit1/unit1.ipynb",
        "update": 1719265708.0
    },
    {
        "name": "PEFT",
        "description": "Parameter-Efficient Fine-Tuning methods enable efficient adaptation of pre-trained language models to various downstream applications without fine-tuning all the model's parameters",
        "author": [
            [
                "Sourab Mangrulkar",
                "https://github.com/pacman100"
            ],
            [
                "Sylvain Gugger",
                "https://github.com/sgugger"
            ],
            [
                "Lysandre Debut",
                "http://lysand.re/"
            ],
            [
                "Younes Belkada",
                "https://github.com/younesbelkada"
            ],
            [
                "Sayak Paul",
                "https://sayak.dev/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/huggingface/peft",
                16614
            ],
            [
                "docs",
                "https://huggingface.co/docs/peft"
            ],
            [
                "hf",
                "https://huggingface.co/datasets/ought/raft/viewer/twitter_complaints"
            ],
            [
                "hf",
                "https://huggingface.co/bigscience/T0_3B"
            ],
            [
                "hf",
                "https://huggingface.co/bigscience/mt0-xxl"
            ],
            [
                "blog post",
                "https://www.philschmid.de/fine-tune-flan-t5-peft"
            ],
            [
                "hf",
                "https://huggingface.co/facebook/opt-6.7b"
            ],
            [
                "hf",
                "https://huggingface.co/roberta-large"
            ],
            [
                "hf",
                "https://huggingface.co/datasets/glue/viewer/mrpc"
            ],
            [
                "git",
                "https://github.com/microsoft/DeepSpeed/issues/3002"
            ],
            [
                "yt",
                "https://youtu.be/YVU5wAA6Txo"
            ],
            [
                "yt",
                "https://youtu.be/Us5ZFp16PaU"
            ],
            [
                "yt",
                "https://youtu.be/YKCtbIJC3kQ"
            ]
        ],
        "colab": "https://colab.research.google.com/github/huggingface/peft/blob/master/examples/int8_training/Finetune_flan_t5_large_bnb_peft.ipynb",
        "update": 1726243286.0
    },
    {
        "name": "TRL",
        "description": "Set of tools to train transformer language models with Reinforcement Learning, from the Supervised Fine-tuning step, Reward Modeling step to the Proximal Policy Optimization step",
        "author": [
            [
                "Leandro von Werra",
                "https://github.com/lvwerra"
            ],
            [
                "Younes Belkada",
                "https://github.com/younesbelkada"
            ],
            [
                "Lewis Tunstall",
                "https://lewtun.github.io/blog/"
            ],
            [
                "Edward Beeching",
                "https://edbeeching.github.io/"
            ],
            [
                "Tristan Thrush",
                "http://www.tristanthrush.com/"
            ],
            [
                "Nathan Lambert",
                "https://www.natolambert.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/huggingface/trl",
                10247
            ],
            [
                "docs",
                "http://hf.co/docs/trl"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1909.08593"
            ],
            [
                "git",
                "https://github.com/openai/lm-human-preferences"
            ],
            [
                "yt",
                "https://youtu.be/xQ5nc1CF7iQ"
            ],
            [
                "yt",
                "https://youtu.be/67SO20dszNA"
            ]
        ],
        "colab": "https://colab.research.google.com/github/huggingface/trl/blob/master/examples/notebooks/best_of_n.ipynb",
        "update": 1727186755.0
    },
    {
        "name": "Optimum",
        "description": "Extension of Transformers and Diffusers, providing a set of optimization tools enabling maximum efficiency to train and run models on targeted hardware, while keeping things easy to use",
        "author": [
            [
                "Hugging Face",
                "https://huggingface.co/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/huggingface/optimum",
                2601
            ],
            [
                "hf",
                "https://huggingface.co/docs/optimum/index"
            ],
            [
                "git",
                "https://github.com/openvinotoolkit/nncf"
            ],
            [
                "hf",
                "https://huggingface.co/docs/transformers/main_classes/trainer"
            ],
            [
                "yt",
                "https://youtu.be/UJnfePM0Ur8"
            ],
            [
                "yt",
                "https://www.youtube.com/live/b1Gk9q9empA"
            ],
            [
                "yt",
                "https://youtu.be/_AKFDOnrZz8"
            ]
        ],
        "colab": "https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/question_answering_ort.ipynb",
        "update": 1680777019.0
    },
    {
        "name": "Datasets",
        "description": "A Community Library for Natural Language Processing",
        "author": [
            [
                "Quentin Lhoest",
                "https://github.com/lhoestq"
            ],
            [
                "Albert Villanova",
                "https://albertvillanova.github.io/"
            ],
            [
                "Yacine Jernite",
                "https://yjernite.github.io/"
            ],
            [
                "Abhishek Thakur",
                "https://github.com/abhishekkrthakur"
            ],
            [
                "Patrick von Platen",
                "https://github.com/patrickvonplaten"
            ],
            [
                "Suraj Patil",
                "https://github.com/patil-suraj"
            ],
            [
                "Julien Chaumond",
                "https://github.com/julien-c"
            ],
            [
                "Mariama Dramé",
                "https://scholar.google.com/citations?user=0pwfXH0AAAAJ"
            ],
            [
                "Julien Plu",
                "https://jplu.github.io/"
            ],
            [
                "Lewis Tunstall",
                "https://lewtun.github.io/blog/"
            ],
            [
                "Joe Davison",
                "https://joeddav.github.io/"
            ],
            [
                "Mario Šaško",
                "https://github.com/mariosasko"
            ],
            [
                "Gunjan Chhablani",
                "https://gchhablani.github.io/"
            ],
            [
                "Bhavitvya Malik",
                "https://github.com/bhavitvyamalik"
            ],
            [
                "Simon Brandeis",
                "https://github.com/SBrandeis"
            ],
            [
                "Teven Le Scao",
                "https://github.com/TevenLeScao"
            ],
            [
                "Victor Sanh",
                "https://github.com/VictorSanh"
            ],
            [
                "Canwen Xu",
                "https://www.canwenxu.net/"
            ],
            [
                "Nicolas Patry",
                "https://github.com/Narsil"
            ],
            [
                "Angelina McMillan-Major",
                "https://github.com/mcmillanmajora"
            ],
            [
                "Philipp Schmid",
                "https://www.philschmid.de/"
            ],
            [
                "Sylvain Gugger",
                "https://github.com/sgugger"
            ],
            [
                "Clément Delangue",
                "https://scholar.google.com/citations?user=bRMboT8AAAAJ"
            ],
            [
                "Théo Matussière",
                "https://theo.matussie.re/"
            ],
            [
                "Lysandre Debut",
                "http://lysand.re/"
            ],
            [
                "Stas Bekman",
                "https://stasosphere.com/machine-learning/"
            ],
            [
                "Pierric Cistac",
                "https://github.com/Pierrci"
            ],
            [
                "Thibault Goehringer",
                "https://github.com/beurkinger"
            ],
            [
                "Victor Mustar",
                "https://github.com/gary149"
            ],
            [
                "François Lagunas",
                "https://github.com/madlag"
            ],
            [
                "Alexander Rush",
                "https://rush-nlp.com/"
            ],
            [
                "Thomas Wolf",
                "https://thomwolf.io/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/huggingface/datasets",
                19327
            ],
            [
                "docs",
                "https://huggingface.co/docs/datasets"
            ],
            [
                "hf",
                "https://huggingface.co/datasets"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2109.02846"
            ],
            [
                "yt",
                "https://youtu.be/uaIJ96syPnM"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/code/nbroad/intro-to-hugging-face-datasets"
            ]
        ],
        "colab": "https://colab.research.google.com/github/huggingface/notebooks/blob/main/datasets_doc/en/quickstart.ipynb",
        "update": 1710776746.0
    },
    {
        "name": "Evidently",
        "description": "An open-source framework to evaluate, test and monitor ML models in production",
        "author": [
            [
                "Elena Samuylova",
                "https://github.com/elenasamuylova"
            ],
            [
                "Emeli Dral",
                "https://github.com/emeli-dral"
            ],
            [
                "Olga Filippova",
                "https://github.com/0lgaF"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/evidentlyai/evidently",
                5481
            ],
            [
                "docs",
                "https://docs.evidentlyai.com/"
            ],
            [
                "website",
                "https://evidentlyai.com/"
            ],
            [
                "git",
                "https://github.com/0lgaF/my_tab_with_evidently"
            ],
            [
                "yt",
                "https://www.youtube.com/c/EvidentlyAI"
            ],
            [
                "yt",
                "https://youtu.be/L4Pv6ExBQPM"
            ]
        ],
        "colab": "https://colab.research.google.com/github/evidentlyai/evidently/blob/main/examples/sample_notebooks/getting_started_tutorial.ipynb",
        "update": 1710508027.0
    },
    {
        "name": "NL-Augmenter",
        "description": "A collaborative effort intended to add transformations of datasets dealing with natural language",
        "author": [
            [
                "Aadesh Gupta",
                "https://github.com/aadesh11"
            ],
            [
                "Timothy Sum Hon Mun",
                "https://github.com/timothy22000"
            ],
            [
                "Aditya Srivatsa",
                "https://github.com/kvadityasrivatsa"
            ],
            [
                "Xudong Shen",
                "https://github.com/XudongOliverShen"
            ],
            [
                "Juan Diego Rodriguez",
                "https://github.com/juand-r"
            ],
            [
                "Ashish Shrivastava",
                "https://github.com/ashish3586"
            ],
            [
                "Nagender Aneja",
                "https://researchid.co/naneja"
            ],
            [
                "Zijie Wang",
                "https://zijie.wang/"
            ],
            [
                "Yiwen Shi",
                "https://github.com/Yiwen-Shi"
            ],
            [
                "Afnan Mir",
                "https://github.com/afnanmmir"
            ],
            [
                "William Soto",
                "https://github.com/sotwi"
            ],
            [
                "Chandan Singh",
                "https://csinva.io/"
            ],
            [
                "Claude Roux",
                "https://github.com/ClaudeRoux"
            ],
            [
                "Abinaya Mahendiran",
                "https://github.com/AbinayaM02"
            ],
            [
                "Anna Shvets",
                "https://github.com/asnota"
            ],
            [
                "Kaustubh Dhole",
                "https://github.com/kaustubhdhole"
            ],
            [
                "Bryan Wilie",
                "https://github.com/bryanwilie"
            ],
            [
                "Jamie Simon",
                "https://james-simon.github.io/"
            ],
            [
                "Mukund Varma",
                "https://github.com/MukundVarmaT"
            ],
            [
                "Sang Han",
                "https://github.com/jjangsangy"
            ],
            [
                "Denis Kleyko",
                "https://github.com/denkle"
            ],
            [
                "Samuel Cahyawijaya",
                "https://github.com/SamuelCahyawijaya"
            ],
            [
                "Filip Cornell",
                "https://github.com/Filco306"
            ],
            [
                "Tanay Dixit",
                "https://tanay2001.github.io/"
            ],
            [
                "Connor Boyle",
                "https://github.com/boyleconnor"
            ],
            [
                "Genta Indra Winata",
                "https://gentawinata.com/"
            ],
            [
                "Seungjae Ryan Lee",
                "https://github.com/seungjaeryanlee"
            ],
            [
                "Marcin Namysl",
                "https://github.com/mnamysl"
            ],
            [
                "Roman Sitelew",
                "https://github.com/RomanPlusPlus"
            ],
            [
                "Zhenhao Li",
                "https://zhenhaoli.net/"
            ],
            [
                "Fiona Tan",
                "https://tanfiona.github.io/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2112.02721"
            ],
            [
                "website",
                "https://gem-benchmark.com/nl_augmenter"
            ],
            [
                "git",
                "https://github.com/GEM-benchmark/NL-Augmenter",
                778
            ]
        ],
        "colab": "https://colab.research.google.com/github/GEM-benchmark/NL-Augmenter/blob/main/notebooks/Write_a_sample_transformation.ipynb",
        "update": 1659777690.0
    },
    {
        "name": "Person Remover",
        "description": "Project that combines Pix2Pix and YOLO arhitectures in order to remove people or other objects from photos",
        "author": [
            [
                "Javier Gamazo",
                "https://www.javiergamazo.com/"
            ],
            [
                "Daryl Autar",
                "https://github.com/Daryl149"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/javirk/Person_remover",
                151
            ],
            [
                "git",
                "https://github.com/javirk/Person-remover-partial-convolutions"
            ],
            [
                "git",
                "https://github.com/zzh8829/yolov3-tf2"
            ],
            [
                "yt",
                "https://www.youtube.com/watch?v=_dRjY9gMcxE"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1JDpH8MAjaKoekQ_H9ZaxYJ9_axiDtDGm",
        "update": 1598098239.644
    },
    {
        "name": "Earth Engine Python API and Folium Interactive Mapping",
        "description": "This notebook demonstrates how to setup the Earth Engine and provides several examples for visualizing Earth Engine processed data interactively using the folium library",
        "author": [
            [
                "Qiusheng Wu",
                "https://wetlands.io/"
            ]
        ],
        "links": [
            [
                "api",
                "https://developers.google.com/earth-engine/python_install"
            ],
            [
                "git",
                "https://github.com/python-visualization/folium",
                6949
            ]
        ],
        "colab": "https://colab.research.google.com/github/giswqs/qgis-earthengine-examples/blob/master/Folium/ee-api-folium-setup.ipynb",
        "update": 1579533771.0
    },
    {
        "name": "Traffic counting",
        "description": "Making Road Traffic Counting App based on Computer Vision and OpenCV",
        "author": [
            [
                "Andrey Nikishaev",
                "https://github.com/creotiv"
            ]
        ],
        "links": [
            [
                "medium",
                "https://medium.com/machine-learning-world/tutorial-making-road-traffic-counting-app-based-on-computer-vision-and-opencv-166937911660"
            ],
            [
                "yt",
                "https://www.youtube.com/watch?v=_o5iLbRHKao"
            ],
            [
                "git",
                "https://github.com/creotiv/object_detection_projects/tree/master/opencv_traffic_counting",
                350
            ]
        ],
        "colab": "https://colab.research.google.com/drive/12N4m_RYKqrpozRzh9qe7nQE_sIqQH9U8",
        "update": 1578663579.317
    },
    {
        "name": "HuggingArtists",
        "description": "Choose your favorite Artist and train a language model to write new lyrics based on their unique voice",
        "author": [
            [
                "Aleksey Korshuk",
                "https://github.com/AlekseyKorshuk"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/AlekseyKorshuk/huggingartists",
                101
            ],
            [
                "hf",
                "https://huggingface.co/spaces/AlekseyKorshuk/huggingartists"
            ],
            [
                "hf",
                "https://huggingface.co/huggingartists"
            ]
        ],
        "colab": "https://colab.research.google.com/github/AlekseyKorshuk/huggingartists/blob/master/huggingartists-demo.ipynb",
        "update": 1656168858.0
    },
    {
        "name": "CLIPDraw",
        "description": "Synthesize drawings to match a text prompt",
        "author": [
            [
                "Kevin Frans",
                "https://www.kvfrans.com/"
            ],
            [
                "Lisa Soros",
                "https://scholar.google.com/citations?user=iUkpvMUAAAAJ"
            ],
            [
                "Olaf Witkowski",
                "https://olafwitkowski.com/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2106.14843"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1508.06576"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2105.00162"
            ],
            [
                "blog post",
                "https://kvfrans.com/clipdraw-exploring-text-to-drawing-synthesis/"
            ],
            [
                "git",
                "https://github.com/kvfrans/clipdraw",
                131
            ],
            [
                "git",
                "https://github.com/BachiLi/diffvg/blob/master/apps/painterly_rendering.py"
            ]
        ],
        "colab": "https://colab.research.google.com/github/kvfrans/clipdraw/blob/main/clipdraw.ipynb",
        "update": 1651185399.0
    },
    {
        "name": "OpenCLIP",
        "description": "An open source implementation of CLIP",
        "author": [
            [
                "Ross Wightman",
                "https://rwightman.com/"
            ],
            [
                "Cade Gordon",
                "https://cadegordon.io/"
            ],
            [
                "Vaishaal Shankar",
                "http://vaishaal.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/mlfoundations/open_clip",
                10490
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2109.01903"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2103.00020"
            ],
            [
                "data",
                "https://ai.google.com/research/ConceptualCaptions/download"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2111.02114"
            ],
            [
                "data",
                "https://laion.ai/blog/laion-5b/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2107.04649"
            ],
            [
                "git",
                "https://github.com/mlfoundations/wise-ft"
            ],
            [
                "git",
                "https://github.com/webdataset/webdataset"
            ],
            [
                "git",
                "https://github.com/webdataset/tarp"
            ],
            [
                "data",
                "https://laion.ai/blog/laion-400-open-dataset/"
            ],
            [
                "hf",
                "https://huggingface.co/datasets/laion/laion2B-en"
            ],
            [
                "hf",
                "https://huggingface.co/laion/CLIP-ViT-B-32-laion2B-s34B-b79K"
            ],
            [
                "hf",
                "https://huggingface.co/laion/CLIP-ViT-L-14-laion2B-s32B-b82K"
            ],
            [
                "hf",
                "https://huggingface.co/laion/CLIP-ViT-H-14-laion2B-s32B-b79K"
            ],
            [
                "hf",
                "https://huggingface.co/laion/CLIP-ViT-g-14-laion2B-s12B-b42K"
            ],
            [
                "git",
                "https://github.com/google-research-datasets/conceptual-12m"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1902.10811"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2107.04649"
            ]
        ],
        "colab": "https://colab.research.google.com/github/mlfoundations/open_clip/blob/master/docs/Interacting_with_open_clip.ipynb",
        "update": 1681665182.0
    },
    {
        "name": "ArcaneGAN",
        "description": "Process video in the style of the Arcane animated series",
        "author": [
            [
                "Alexander Spirin",
                "https://github.com/Sxela"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/Sxela/ArcaneGAN",
                656
            ],
            [
                "git",
                "https://github.com/Sxela/stylegan3_blending"
            ],
            [
                "yt",
                "https://youtu.be/Fi199uFW6jE"
            ],
            [
                "yt",
                "https://youtu.be/AJG4X7IokG8"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1r1hhciakk5wHaUn1eJk7TP58fV9mjy_W",
        "update": 1645095391.826
    },
    {
        "name": "Real-CUGAN",
        "description": "AI super resolution model for anime images, trained in a million scale anime dataset, using the same architecture as Waifu2x-CUNet",
        "author": [
            [
                "bilibili",
                "https://github.com/bilibili"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/bilibili/ailab/tree/main/Real-CUGAN",
                5649
            ],
            [
                "git",
                "https://github.com/nihui/realcugan-ncnn-vulkan"
            ],
            [
                "git",
                "https://github.com/nagadomi/nunif"
            ],
            [
                "git",
                "https://github.com/Justin62628/Squirrel-RIFE"
            ],
            [
                "hf",
                "https://huggingface.co/spaces/mayhug/Real-CUGAN"
            ],
            [
                "yt",
                "https://youtu.be/IVo19n4zFsc"
            ]
        ],
        "colab": "https://colab.research.google.com/github/bilibili/ailab/blob/main/Real-CUGAN/colab-demo.ipynb",
        "update": 1645977847.0
    },
    {
        "name": "Text2Animation",
        "description": "Generate images from text phrases with VQGAN and CLIP with animation and keyframes",
        "author": [
            [
                "Katherine Crowson",
                "https://kath.io/"
            ],
            [
                "Ryan Murdock",
                "https://twitter.com/advadnoun"
            ],
            [
                "Chigozie Nri",
                "https://github.com/chigozienri"
            ],
            [
                "Denis Malimonov",
                "https://github.com/tg-bomze"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/chigozienri/VQGAN-CLIP-animations",
                134
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2012.09841"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2103.00020"
            ],
            [
                "yt",
                "https://www.youtube.com/channel/UCToztRy9FSTIhEen_1x4FAw"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tg-bomze/collection-of-notebooks/blob/master/Text2Animation.ipynb",
        "update": 1632919392.0
    },
    {
        "name": "Toon-Me",
        "description": "A fun project to toon portrait images",
        "author": [
            [
                "Vijish Madhavan",
                "https://github.com/vijishmadhavan"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/1710.10196"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1707.02921"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1603.08155"
            ],
            [
                "git",
                "https://github.com/vijishmadhavan/Toon-Me",
                397
            ]
        ],
        "colab": "https://colab.research.google.com/github/vijishmadhavan/Light-Up/blob/master/Toon_Me_(Try_it_on_Colab).ipynb",
        "update": 1611311074.0
    },
    {
        "name": "MindsEye",
        "description": "Graphical user interface built to run multimodal ai art models for free from a Google Colab, without needing edit a single line of code or know any programming",
        "author": [
            [
                "multimodal.art",
                "https://multimodal.art/"
            ],
            [
                "João Paulo Apolinário Passos",
                "http://www.apolinariopassos.com.br/portfolio/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/multimodalart/mindseye",
                81
            ],
            [
                "project",
                "https://multimodal.art/mindseye"
            ],
            [
                "git",
                "https://github.com/openai/guided-diffusion"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1cg0LZ5OfN9LAIB37Xq49as0fSJxcKtC5",
        "update": 1657101595.331
    },
    {
        "name": "DALL·E Flow",
        "description": "An interactive workflow for generating high-definition images from text prompt",
        "author": [
            [
                "Han Xiao",
                "https://hanxiao.io/"
            ],
            [
                "Delgermurun Purevkhuu",
                "https://delgermurun.com/"
            ],
            [
                "Alex Cureton-Griffiths",
                "http://blog.alexcg.net/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/jina-ai/dalle-flow",
                2835
            ],
            [
                "git",
                "https://github.com/Jack000/glid-3-xl"
            ],
            [
                "git",
                "https://github.com/jina-ai/docarray"
            ],
            [
                "hf",
                "https://huggingface.co/CompVis/stable-diffusion-v-1-4-original"
            ],
            [
                "yt",
                "https://www.youtube.com/playlist?list=PL3UBBWOUVhFYRUa_gpYYKBqEAkO4sxmne"
            ],
            [
                "yt",
                "https://www.youtube.com/c/jina-ai"
            ]
        ],
        "colab": "https://colab.research.google.com/github/jina-ai/dalle-flow/blob/main/client.ipynb",
        "update": 1674724333.0
    },
    {
        "name": "CLIP-as-service",
        "description": "A low-latency high-scalability service for embedding images and text",
        "author": [
            [
                "Han Xiao",
                "https://hanxiao.io/"
            ]
        ],
        "links": [
            [
                "website",
                "https://clip-as-service.jina.ai/"
            ],
            [
                "git",
                "https://github.com/jina-ai/clip-as-service",
                12480
            ],
            [
                "git",
                "https://github.com/jina-ai/docarray"
            ],
            [
                "data",
                "https://sites.google.com/view/totally-looks-like-dataset"
            ],
            [
                "yt",
                "https://www.youtube.com/playlist?list=PL3UBBWOUVhFYRUa_gpYYKBqEAkO4sxmne"
            ],
            [
                "yt",
                "https://www.youtube.com/c/jina-ai"
            ]
        ],
        "colab": "https://colab.research.google.com/github/jina-ai/clip-as-service/blob/main/docs/hosting/cas-on-colab.ipynb",
        "update": 1655674969.0
    },
    {
        "name": "Clip retrieval",
        "description": "Easily compute clip embeddings and build a clip retrieval system with them",
        "author": [
            [
                "Romain Beaumont",
                "https://github.com/rom1504"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/rom1504/clip-retrieval",
                2431
            ],
            [
                "project",
                "https://rom1504.github.io/clip-retrieval"
            ],
            [
                "pypi",
                "https://pypi.python.org/pypi/clip-retrieval"
            ],
            [
                "discord",
                "https://discord.gg/eq3cAMZtCC"
            ],
            [
                "medium",
                "https://rom1504.medium.com/semantic-search-with-embeddings-index-anything-8fb18556443c"
            ],
            [
                "git",
                "https://github.com/LAION-AI/CLIP_benchmark"
            ],
            [
                "git",
                "https://github.com/rom1504/laion-prepro"
            ],
            [
                "git",
                "https://github.com/dzryk/antarctic-captions"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Locality_of_reference"
            ],
            [
                "git",
                "https://github.com/LAION-AI/CLIP-based-NSFW-Detector"
            ],
            [
                "git",
                "https://github.com/ml-research/OffImgDetectionCLIP"
            ]
        ],
        "colab": "https://colab.research.google.com/github/rom1504/clip-retrieval/blob/master/notebook/clip-retrieval-getting-started.ipynb",
        "update": 1632256935.0
    },
    {
        "name": "FuseDream",
        "description": "Training-Free Text-to-Image Generation with Improved CLIP+GAN Space Optimization",
        "author": [
            [
                "Xingchao Liu",
                "https://scholar.google.com/citations?user=VOTVE0UAAAAJ"
            ],
            [
                "Chengyue Gong",
                "https://github.com/ChengyueGongR"
            ],
            [
                "Lemeng Wu",
                "https://github.com/klightz"
            ],
            [
                "Hao Su",
                "https://cseweb.ucsd.edu//~haosu/"
            ],
            [
                "Qiang Liu",
                "https://www.cs.utexas.edu/~lqiang/"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2112.01573"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/190tKQf0aFj-Hi8STUrLc2m4DeOviv7NO",
        "update": 1641149798.191
    },
    {
        "name": "Jina",
        "description": "MLOps framework that empowers anyone to build cross-modal and multi-modal applications on the cloud",
        "author": [
            [
                "Han Xiao",
                "https://hanxiao.io/"
            ]
        ],
        "links": [
            [
                "docs",
                "https://docs.jina.ai/"
            ],
            [
                "git",
                "https://github.com/jina-ai/jina",
                21160
            ],
            [
                "hub",
                "https://hub.jina.ai/"
            ],
            [
                "git",
                "https://github.com/jina-ai/example-grafana-prometheus/blob/main/grafana-dashboards/flow.json"
            ],
            [
                "data",
                "https://sites.google.com/view/totally-looks-like-dataset"
            ],
            [
                "yt",
                "https://www.youtube.com/playlist?list=PL3UBBWOUVhFYRUa_gpYYKBqEAkO4sxmne"
            ],
            [
                "yt",
                "https://www.youtube.com/c/jina-ai"
            ]
        ],
        "colab": "https://colab.research.google.com/github/jina-ai/jina/blob/master/docs/Using_Jina_on_Colab.ipynb",
        "update": 1654981220.0
    },
    {
        "name": "Stable Diffusion",
        "description": "A latent text-to-image diffusion model",
        "author": [
            [
                "Robin Rombach",
                "https://github.com/rromb"
            ],
            [
                "Andreas Blattmann",
                "https://github.com/ablattmann"
            ],
            [
                "Dominik Lorenz",
                "https://github.com/qp-qp"
            ],
            [
                "Patrick Esser",
                "https://github.com/pesser"
            ],
            [
                "Björn Ommer",
                "https://ommer-lab.com/people/ommer/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/CompVis/stable-diffusion",
                68617
            ],
            [
                "git",
                "https://arxiv.org/abs/2112.10752"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2205.11487"
            ],
            [
                "hf",
                "https://huggingface.co/CompVis"
            ],
            [
                "hf",
                "https://huggingface.co/datasets/laion/laion2B-en"
            ],
            [
                "hf",
                "https://huggingface.co/datasets/laion/laion-high-resolution"
            ],
            [
                "git",
                "https://github.com/christophschuhmann/improved-aesthetic-predictor"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2207.12598"
            ],
            [
                "git",
                "https://github.com/ShieldMnt/invisible-watermark"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2202.09778"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2108.01073"
            ],
            [
                "git",
                "https://github.com/openai/guided-diffusion"
            ],
            [
                "git",
                "https://github.com/lucidrains/denoising-diffusion-pytorch"
            ],
            [
                "git",
                "https://github.com/lucidrains/x-transformers"
            ]
        ],
        "colab": "https://colab.research.google.com/github/CompVis/stable-diffusion/blob/main/scripts/latent_imagenet_diffusion.ipynb",
        "update": 1660141849.0
    },
    {
        "name": "Stable Diffusion 2",
        "description": "New stable diffusion model at 768x768 resolution. Same number of parameters in the U-Net as 1.5, but uses OpenCLIP-ViT/H as the text encoder and is trained from scratch",
        "author": [
            [
                "Robin Rombach",
                "https://github.com/rromb"
            ],
            [
                "Andreas Blattmann",
                "https://github.com/ablattmann"
            ],
            [
                "Dominik Lorenz",
                "https://github.com/qp-qp"
            ],
            [
                "Patrick Esser",
                "https://github.com/pesser"
            ],
            [
                "Björn Ommer",
                "https://ommer-lab.com/people/ommer/"
            ],
            [
                "qunash",
                "https://github.com/qunash"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/Stability-AI/stablediffusion",
                39361
            ],
            [
                "git",
                "https://github.com/qunash/stable-diffusion-2-gui"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2112.10752"
            ],
            [
                "hf",
                "https://huggingface.co/stabilityai/stable-diffusion-2-1"
            ],
            [
                "hf",
                "https://huggingface.co/stabilityai/stable-diffusion-2-1-base"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2202.00512"
            ],
            [
                "git",
                "https://github.com/isl-org/MiDaS"
            ],
            [
                "yt",
                "https://youtu.be/HytucGhwTRs"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2010.02502"
            ],
            [
                "hf",
                "https://huggingface.co/stabilityai/stable-diffusion-2-depth"
            ],
            [
                "hf",
                "https://huggingface.co/stabilityai/stable-diffusion-2-inpainting"
            ],
            [
                "git",
                "https://github.com/lucidrains/denoising-diffusion-pytorch"
            ],
            [
                "git",
                "https://github.com/runwayml/stable-diffusion/blob/main/scripts/inpaint_st.py"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2108.01073"
            ],
            [
                "git",
                "https://github.com/crowsonkb/k-diffusion"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2202.09778"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2206.00927"
            ]
        ],
        "colab": "https://colab.research.google.com/github/qunash/stable-diffusion-2-gui/blob/main/stable_diffusion_2_0.ipynb",
        "update": 1693078556.0
    },
    {
        "name": "StableLM",
        "description": "Stability AI Language Models",
        "author": [
            [
                "Stability AI",
                "https://stability.ai/research"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/Stability-AI/StableLM",
                15835
            ],
            [
                "hf",
                "https://huggingface.co/lmsys/vicuna-13b-delta-v0"
            ],
            [
                "git",
                "https://github.com/facebookresearch/llama"
            ],
            [
                "git",
                "https://github.com/tatsu-lab/stanford_alpaca"
            ],
            [
                "git",
                "https://github.com/nomic-ai/gpt4all"
            ],
            [
                "hf",
                "https://huggingface.co/datasets/RyokoAI/ShareGPT52K"
            ],
            [
                "git",
                "https://github.com/databrickslabs/dolly"
            ],
            [
                "git",
                "https://github.com/anthropics/hh-rlhf"
            ],
            [
                "hf",
                "https://huggingface.co/stabilityai"
            ],
            [
                "git",
                "https://github.com/ggerganov/llama.cpp"
            ],
            [
                "yt",
                "https://youtu.be/dypPSs4t77g"
            ],
            [
                "yt",
                "https://youtu.be/nWf1StvtoRw"
            ],
            [
                "yt",
                "https://youtu.be/Hg-s2RTaTFE"
            ],
            [
                "yt",
                "https://youtu.be/qXtJjoEfTnA"
            ],
            [
                "blog post",
                "https://stability.ai/blog/stability-ai-launches-the-first-of-its-stablelm-suite-of-language-models"
            ]
        ],
        "colab": "https://colab.research.google.com/github/Stability-AI/StableLM/blob/main/notebooks/stablelm-alpha.ipynb",
        "update": 1682607942.0
    },
    {
        "name": "Stable Cascade",
        "description": "Text to image model introduces an interesting three-stage approach, setting new benchmarks for quality, flexibility, fine-tuning, and efficiency with a focus on further eliminating hardware barriers",
        "author": [
            [
                "Stability AI",
                "https://stability.ai/research"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/Stability-AI/StableCascade",
                6556
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2306.00637"
            ],
            [
                "hf",
                "https://huggingface.co/stabilityai/stable-cascade"
            ],
            [
                "blog post",
                "https://stability.ai/news/introducing-stable-cascade"
            ],
            [
                "hf",
                "https://huggingface.co/datasets/nateraw/parti-prompts"
            ],
            [
                "discord",
                "https://discord.gg/stablediffusion"
            ],
            [
                "twitter",
                "https://twitter.com/stabilityai"
            ],
            [
                "medium",
                "https://medium.com/intelligent-art/stable-cascade-a-super-easy-local-installation-guide-ce0cbd06d800"
            ],
            [
                "medium",
                "https://medium.com/@yushantripleseven/stable-cascade-training-inference-a52e12ecc5fa"
            ],
            [
                "yt",
                "https://youtu.be/Ybu6qTbEsewc"
            ],
            [
                "yt",
                "https://youtu.be/JuX-uukwdkI"
            ],
            [
                "yt",
                "https://youtu.be/YMxXtaiVHks"
            ],
            [
                "yt",
                "https://youtu.be/UgM-z2q3Xe0"
            ],
            [
                "yt",
                "https://youtu.be/W6YLIyA3Kco"
            ],
            [
                "yt",
                "https://youtu.be/X1rLWFRagIw"
            ]
        ],
        "colab": "https://colab.research.google.com/github/mkshing/notebooks/blob/main/stable_cascade.ipynb",
        "update": 1707874087.0
    },
    {
        "name": "Stable Diffusion Videos",
        "description": "Create videos with Stable Diffusion by exploring the latent space and morphing between text prompts",
        "author": [
            [
                "Nathan Raw",
                "https://github.com/nateraw"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/nateraw/stable-diffusion-videos",
                4463
            ],
            [
                "git",
                "https://gist.github.com/karpathy/00103b0037c5aaea32fe1da1af553355"
            ],
            [
                "git",
                "https://gist.github.com/nateraw/c989468b74c616ebbc6474aa8cdd9e53"
            ]
        ],
        "colab": "https://colab.research.google.com/github/nateraw/stable-diffusion-videos/blob/main/stable_diffusion_videos.ipynb",
        "update": 1720676880.0
    },
    {
        "name": "Deforum Stable Diffusion",
        "description": "Open source project is designed to be free to use and easy to modify for custom needs and pipelines",
        "author": [
            [
                "EnzymeZoo",
                "https://linktr.ee/enzymezoo"
            ],
            [
                "Артем Храпов",
                "https://github.com/kabachuha"
            ],
            [
                "Forest Star Walz",
                "https://github.com/reallybigname"
            ],
            [
                "pharmapsychotic",
                "https://github.com/pharmapsychotic"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/deforum-art/deforum-stable-diffusion",
                2208
            ],
            [
                "project",
                "https://deforum.github.io/"
            ],
            [
                "docs",
                "https://docs.google.com/document/d/1RrQv7FntzOuLg4ohjRZPVL7iptIyBhwwbcEYEW2OfcI"
            ],
            [
                "discord",
                "https://discord.gg/deforum"
            ],
            [
                "yt",
                "https://youtu.be/w_sxuDMt_V0"
            ],
            [
                "yt",
                "https://youtu.be/bicPayZDI60"
            ],
            [
                "yt",
                "https://youtu.be/dqkQo2alZvU"
            ]
        ],
        "colab": "https://colab.research.google.com/github/deforum-art/deforum-stable-diffusion/blob/main/Deforum_Stable_Diffusion.ipynb",
        "update": 1725041453.0
    },
    {
        "name": "Tortoise",
        "description": "A multi-voice TTS system trained with an emphasis on quality",
        "author": [
            [
                "James Betker",
                "https://nonint.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/neonbjb/tortoise-tts",
                13311
            ],
            [
                "examples",
                "https://nonint.com/static/tortoise_v2_examples.html"
            ],
            [
                "git",
                "https://github.com/neonbjb/DL-Art-School"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2102.12092"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2102.09672"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2106.07889"
            ],
            [
                "hf",
                "https://huggingface.co/patrickvonplaten"
            ],
            [
                "yt",
                "https://youtu.be/J3-jfS29RF4"
            ],
            [
                "hf",
                "https://huggingface.co/spaces/osanseviero/tortoisse-tts"
            ]
        ],
        "colab": "https://colab.research.google.com/github/neonbjb/tortoise-tts/blob/main/tortoise_tts.ipynb",
        "update": 1689442219.0
    },
    {
        "name": "TTS",
        "description": "A library for advanced Text-to-Speech generation, built on the latest research, was designed to achieve the best trade-off among ease-of-training, speed and quality",
        "author": [
            [
                "Eren Gölge",
                "https://github.com/erogol"
            ],
            [
                "Aya-AlJafari",
                "https://github.com/Aya-AlJafari"
            ],
            [
                "Edresson Casanova",
                "https://github.com/Edresson"
            ],
            [
                "Josh Meyer",
                "http://jrmeyer.github.io/"
            ],
            [
                "Kelly Davis",
                "https://github.com/kdavis-coqui"
            ],
            [
                "Reuben Morais",
                "https://github.com/reuben"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/coqui-ai/TTS",
                35874
            ],
            [
                "samples",
                "https://erogol.github.io/ddc-samples/"
            ],
            [
                "blog post",
                "https://coqui.ai/blog/tts/solving-attention-problems-of-tts-models-with-double-decoder-consistency"
            ],
            [
                "yt",
                "https://youtu.be/ADnBCz0Wd1U"
            ],
            [
                "git",
                "https://github.com/coqui-ai/TTS-papers"
            ],
            [
                "docs",
                "https://tts.readthedocs.io/en/latest/"
            ],
            [
                "website",
                "https://coqui.ai/"
            ],
            [
                "yt",
                "https://youtu.be/Yglxf2WbkLU"
            ],
            [
                "yt",
                "https://youtu.be/alpI-DnVlO0"
            ]
        ],
        "colab": "https://colab.research.google.com/github/coqui-ai/TTS/blob/dev/notebooks/Tutorial_2_train_your_first_TTS_model.ipynb",
        "update": 1682515377.0
    },
    {
        "name": "MMAction2",
        "description": "An open-source toolbox for video understanding based on PyTorch",
        "author": [
            [
                "MMAction2 Contributors",
                "https://openmmlab.com/aboutus"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/open-mmlab/mmaction2",
                4343
            ],
            [
                "docs",
                "https://mmaction2.readthedocs.io/"
            ],
            [
                "git",
                "https://github.com/open-mmlab/mmcv"
            ],
            [
                "git",
                "https://github.com/SwinTransformer/Video-Swin-Transformer"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2106.13230"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2107.10161"
            ],
            [
                "git",
                "https://github.com/Cogito2012/DEAR"
            ],
            [
                "git",
                "https://github.com/xvjiarui/VFS"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2103.17263"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2104.13586"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2102.05095"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2003.13042"
            ],
            [
                "git",
                "https://github.com/holistic-video-understanding/HVU-Dataset"
            ],
            [
                "data",
                "https://sdolivia.github.io/FineGym/"
            ],
            [
                "data",
                "http://www.svcl.ucsd.edu/projects/resound/dataset.html"
            ],
            [
                "data",
                "https://research.google.com/ava/index.html"
            ],
            [
                "data",
                "https://www.deepmind.com/open-source/kinetics"
            ]
        ],
        "colab": "https://colab.research.google.com/github/open-mmlab/mmaction2/blob/master/demo/mmaction2_tutorial.ipynb",
        "update": 1694006548.0
    },
    {
        "name": "MMagic",
        "description": "AIGC toolbox for professional AI researchers and machine learning engineers to explore image and video processing, editing and generation",
        "author": [
            [
                "OpenMMLab",
                "https://openmmlab.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/open-mmlab/mmagic",
                6970
            ],
            [
                "docs",
                "https://mmagic.readthedocs.io/en/latest/"
            ],
            [
                "medium",
                "https://openmmlab.medium.com/"
            ],
            [
                "discord",
                "https://discord.gg/raweFPmdzG"
            ],
            [
                "twitter",
                "https://twitter.com/OpenMMLab"
            ],
            [
                "yt",
                "https://www.youtube.com/openmmlab"
            ],
            [
                "git",
                "https://github.com/open-mmlab/mmgeneration"
            ],
            [
                "git",
                "https://github.com/open-mmlab/mmengine/blob/main/mmengine/model/wrappers/seperate_distributed.py"
            ],
            [
                "git",
                "https://github.com/open-mmlab/mmcv"
            ],
            [
                "git",
                "https://github.com/open-mmlab/mim"
            ]
        ],
        "colab": "https://colab.research.google.com/github/open-mmlab/mmagic/blob/main/demo/mmagic_inference_tutorial.ipynb",
        "update": 1694418330.0
    },
    {
        "name": "MMDetection",
        "description": "Open source object detection toolbox based on PyTorch",
        "author": [
            [
                "OpenMMLab",
                "https://openmmlab.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/open-mmlab/mmdetection",
                29739
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1906.07155"
            ],
            [
                "docs",
                "https://mmdetection.readthedocs.io/en/latest/"
            ],
            [
                "pypi",
                "https://pypi.org/project/mmdet"
            ],
            [
                "medium",
                "https://openmmlab.medium.com/"
            ],
            [
                "discord",
                "https://discord.com/channels/1037617289144569886/1046608014234370059"
            ],
            [
                "twitter",
                "https://twitter.com/OpenMMLab"
            ],
            [
                "yt",
                "https://www.youtube.com/openmmlab"
            ],
            [
                "git",
                "https://github.com/tusen-ai/simpledet"
            ],
            [
                "git",
                "https://github.com/open-mmlab/mmcv"
            ],
            [
                "git",
                "https://github.com/open-mmlab/mmengine"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2401.02361"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2212.07784"
            ],
            [
                "pwc",
                "https://paperswithcode.com/sota/real-time-instance-segmentation-on-mscoco?p=rtmdet-an-empirical-study-of-designing-real"
            ],
            [
                "pwc",
                "https://paperswithcode.com/sota/object-detection-in-aerial-images-on-dota-1?p=rtmdet-an-empirical-study-of-designing-real"
            ],
            [
                "pwc",
                "https://paperswithcode.com/sota/object-detection-in-aerial-images-on-hrsc2016?p=rtmdet-an-empirical-study-of-designing-real"
            ],
            [
                "yt",
                "https://youtu.be/5kgWyo6Sg4E"
            ],
            [
                "yt",
                "https://youtu.be/4SuwN4xSM3Q"
            ],
            [
                "yt",
                "https://www.youtube.com/live/SWB2pTY3UDM"
            ],
            [
                "yt",
                "https://youtu.be/AEIDB6Dd6bM"
            ],
            [
                "yt",
                "https://youtu.be/7c2JKPMVPm0"
            ]
        ],
        "colab": "https://colab.research.google.com/github/open-mmlab/mmdetection/blob/main/demo/MMDet_Tutorial.ipynb",
        "update": 1684318005.0
    },
    {
        "name": "MMSegmentation",
        "description": "Open source semantic segmentation toolbox based on PyTorch",
        "author": [
            [
                "OpenMMLab",
                "https://openmmlab.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/open-mmlab/mmsegmentation",
                8366
            ],
            [
                "docs",
                "https://mmsegmentation.readthedocs.io/en/main/"
            ],
            [
                "pypi",
                "https://pypi.org/project/mmsegmentation"
            ],
            [
                "medium",
                "https://openmmlab.medium.com/"
            ],
            [
                "discord",
                "https://discord.gg/raweFPmdzG"
            ],
            [
                "twitter",
                "https://twitter.com/OpenMMLab"
            ],
            [
                "yt",
                "https://www.youtube.com/openmmlab"
            ],
            [
                "medium",
                "https://mducducd33.medium.com/sematic-segmentation-using-mmsegmentation-bcf58fb22e42"
            ]
        ],
        "colab": "https://colab.research.google.com/github/open-mmlab/mmsegmentation/blob/main/demo/MMSegmentation_Tutorial.ipynb",
        "update": 1680251190.0
    },
    {
        "name": "MMRotate",
        "description": "Toolbox for rotated object detection based on PyTorch",
        "author": [
            [
                "Yue Zhou",
                "https://zytx121.github.io/"
            ],
            [
                "Xue Yang",
                "https://yangxue0827.github.io/"
            ],
            [
                "Gefan Zhang",
                "https://github.com/zhanggefan"
            ],
            [
                "Jiabao Wang",
                "https://jbwang1997.github.io/"
            ],
            [
                "Yanyi Liu",
                "https://github.com/liuyanyi"
            ],
            [
                "Liping Hou",
                "https://scholar.google.com/citations?user=XoEzZukAAAAJ"
            ],
            [
                "Xue Jiang",
                "https://dl.acm.org/profile/99659833933"
            ],
            [
                "Xingzhao Liu",
                "https://dl.acm.org/profile/81430639972"
            ],
            [
                "Junchi Yan",
                "https://thinklab.sjtu.edu.cn/"
            ],
            [
                "Chengqi Lyu",
                "https://scholar.google.com/citations?user=kV3WvXcAAAAJ"
            ],
            [
                "Wenwei Zhang",
                "https://zhangwenwei.cn/"
            ],
            [
                "Kai Chen",
                "https://chenkai.site/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/open-mmlab/mmrotate",
                1889
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2204.13317"
            ],
            [
                "doi",
                "https://doi.org/10.1145/3503161.3548541",
                173
            ],
            [
                "pypi",
                "https://pypi.org/project/mmrotate"
            ],
            [
                "docs",
                "https://mmrotate.readthedocs.io/en/latest/"
            ],
            [
                "website",
                "https://openmmlab.com/"
            ],
            [
                "pwc",
                "https://paperswithcode.com/sota/real-time-instance-segmentation-on-mscoco?p=rtmdet-an-empirical-study-of-designing-real"
            ],
            [
                "pwc",
                "https://paperswithcode.com/sota/object-detection-in-aerial-images-on-hrsc2016?p=rtmdet-an-empirical-study-of-designing-real"
            ],
            [
                "pwc",
                "https://paperswithcode.com/sota/object-detection-in-aerial-images-on-dota-1?p=rtmdet-an-empirical-study-of-designing-real"
            ],
            [
                "git",
                "https://github.com/open-mmlab/mmcv"
            ],
            [
                "yt",
                "https://youtu.be/hKZUV0AySNk"
            ]
        ],
        "colab": "https://colab.research.google.com/github/open-mmlab/mmrotate/blob/main/demo/MMRotate_Tutorial.ipynb",
        "update": 1654847511.0
    },
    {
        "name": "MMOCR",
        "description": "Open source toolkit based on PyTorch and MMDetection, supporting numerous OCR-related models, including text detection, text recognition, and key information extraction",
        "author": [
            [
                "Zhanghui Kuang",
                "https://jeffreykuang.github.io"
            ],
            [
                "Hongbin Sun",
                "https://github.com/cuhk-hbsun"
            ],
            [
                "Zhizhong Li",
                "https://zhizhong.li/"
            ],
            [
                "Xiaoyu Yue",
                "https://yuexy.github.io/#/"
            ],
            [
                "Tsui Hin Lin",
                "https://dl.acm.org/profile/99659894554"
            ],
            [
                "Jianyong Chen",
                "https://github.com/HolyCrap96"
            ],
            [
                "Huaqiang Wei",
                "https://github.com/weihuaqiang"
            ],
            [
                "Yiqin Zhu",
                "https://scholar.google.com/citations?user=ZH9cp50AAAAJ"
            ],
            [
                "Tong Gao",
                "https://github.com/gaotongxiao"
            ],
            [
                "Wenwei Zhang",
                "https://zhangwenwei.cn/"
            ],
            [
                "Kai Chen",
                "https://chenkai.site/"
            ],
            [
                "Wayne Zhang",
                "https://www.statfe.com/"
            ],
            [
                "Dahua Lin",
                "http://dahua.site/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/open-mmlab/mmocr",
                4372
            ],
            [
                "docs",
                "https://mmocr.readthedocs.io/en/latest/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2108.06543"
            ],
            [
                "doi",
                "https://doi.org/10.1145/3474085.3478328",
                46
            ],
            [
                "medium",
                "https://openmmlab.medium.com/mmocr-a-comprehensive-toolbox-for-text-detection-recognition-and-understanding-795befa726b8"
            ],
            [
                "yt",
                "https://youtu.be/U7VYfHeE0KQ"
            ],
            [
                "yt",
                "https://youtu.be/Snyu-o8ZdDk"
            ],
            [
                "yt",
                "https://youtu.be/g7qfSYkkpUA"
            ],
            [
                "pypi",
                "https://pypi.org/project/mmocr/"
            ],
            [
                "discord",
                "https://discord.gg/raweFPmdzG"
            ],
            [
                "yt",
                "https://www.youtube.com/openmmlab"
            ],
            [
                "twitter",
                "https://twitter.com/OpenMMLab"
            ],
            [
                "git",
                "https://github.com/open-mmlab/mmengine"
            ],
            [
                "git",
                "https://github.com/open-mmlab/mmcv"
            ]
        ],
        "colab": "https://colab.research.google.com/github/open-mmlab/mmocr/blob/master/demo/tutorial.ipynb",
        "update": 1680773145.0
    },
    {
        "name": "MMPose",
        "description": "Toolbox for pose estimation based on PyTorch",
        "author": [
            [
                "OpenMMLab",
                "https://openmmlab.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/open-mmlab/mmpose",
                5924
            ],
            [
                "docs",
                "https://mmpose.readthedocs.io/en/latest/"
            ],
            [
                "pypi",
                "https://pypi.org/project/mmpose/"
            ],
            [
                "medium",
                "https://openmmlab.medium.com/"
            ],
            [
                "yt",
                "https://www.youtube.com/openmmlab"
            ],
            [
                "discord",
                "https://discord.com/channels/1037617289144569886/1072798105428299817"
            ],
            [
                "twitter",
                "https://twitter.com/OpenMMLab"
            ],
            [
                "yt",
                "https://youtu.be/nFcZ2H1Ix3w"
            ]
        ],
        "colab": "https://colab.research.google.com/github/open-mmlab/mmpose/blob/master/demo/MMPose_Tutorial.ipynb",
        "update": 1687140690.0
    },
    {
        "name": "pymdp",
        "description": "Package for simulating Active Inference agents in Markov Decision Process environments",
        "author": [
            [
                "Conor Heins",
                "https://github.com/conorheins"
            ],
            [
                "Alec Tschantz",
                "https://github.com/alec-tschantz"
            ],
            [
                "Beren Millidge",
                "https://www.beren.io/"
            ],
            [
                "Brennan Klein",
                "https://github.com/jkbren"
            ],
            [
                "Arun Niranjan",
                "https://github.com/Arun-Niranjan"
            ],
            [
                "Daphne Demekas",
                "https://github.com/daphnedemekas"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/infer-actively/pymdp",
                481
            ],
            [
                "docs",
                "https://pymdp-rtd.readthedocs.io/en/stable/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2201.03904"
            ]
        ],
        "colab": "https://colab.research.google.com/github/infer-actively/pymdp/blob/master/docs/notebooks/active_inference_from_scratch.ipynb",
        "update": 1679225898.0
    },
    {
        "name": "AmpliGraph",
        "description": "A suite of neural machine learning models for relational Learning, a branch of machine learning that deals with supervised learning on knowledge graphs",
        "author": [
            [
                "Luca Costabello",
                "https://luca.costabello.info/"
            ],
            [
                "Adrianna Janik",
                "https://github.com/adrijanik"
            ],
            [
                "Chan Le Van",
                "https://github.com/chanlevan"
            ],
            [
                "Nicholas McCarthy",
                "https://github.com/NicholasMcCarthy"
            ],
            [
                "Rory McGrath",
                "http://www.rorymcgrath.ie/"
            ],
            [
                "Sumit Pai",
                "https://github.com/sumitpai"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/Accenture/AmpliGraph",
                2161
            ],
            [
                "docs",
                "https://docs.ampligraph.org"
            ],
            [
                "arxiv",
                "http://arxiv.org/abs/1702.05563"
            ],
            [
                "arxiv",
                "http://arxiv.org/abs/1705.10744"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2105.08683"
            ],
            [
                "arxiv",
                "http://arxiv.org/abs/1612.03975"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1912.10000"
            ],
            [
                "neurips",
                "https://papers.nips.cc/paper/2013/hash/1cecc7a77928ca8133fa24680a88d2f9-Abstract.html"
            ],
            [
                "neurips",
                "https://papers.nips.cc/paper/2013/hash/b337e84de8752b27eda3a12363109e80-Abstract.html"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1412.6575"
            ],
            [
                "yt",
                "https://youtu.be/gX_KHaU8ChI"
            ]
        ],
        "colab": "https://colab.research.google.com/github/Accenture/AmpliGraph/blob/main/docs/tutorials/AmpliGraphBasicsTutorial.ipynb",
        "update": 1677169380.0
    },
    {
        "name": "BasicSR",
        "description": "Open Source Image and Video Restoration Toolbox for Super-resolution, Denoise, Deblurring, etc.",
        "author": [
            [
                "Xintao Wang",
                "https://xinntao.github.io/"
            ],
            [
                "Liangbin Xie",
                "https://liangbinxie.github.io/"
            ],
            [
                "Ke Yu",
                "https://github.com/yuke93"
            ],
            [
                "Kelvin Chan",
                "https://ckkelvinchan.github.io/"
            ],
            [
                "Chen Change Loy",
                "https://www.mmlab-ntu.com/person/ccloy/"
            ],
            [
                "Chao Dong",
                "https://scholar.google.com/citations?user=OSDCB0UAAAAJ"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/XPixelGroup/BasicSR",
                6926
            ],
            [
                "docs",
                "https://basicsr.readthedocs.io/en/latest/"
            ],
            [
                "git",
                "https://github.com/xinntao/ESRGAN"
            ],
            [
                "git",
                "https://github.com/xindongzhang/ECBSR"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2012.02181"
            ],
            [
                "git",
                "https://github.com/Lotayou/Face-Renovation"
            ],
            [
                "git",
                "https://github.com/csxmli2016/DFDNet"
            ],
            [
                "git",
                "https://github.com/rosinality/stylegan2-pytorch"
            ],
            [
                "git",
                "https://github.com/xinntao/facexlib"
            ],
            [
                "git",
                "https://github.com/xinntao/HandyView"
            ],
            [
                "git",
                "https://github.com/xinntao/HandyFigure"
            ],
            [
                "git",
                "https://github.com/xinntao/SFTGAN"
            ],
            [
                "git",
                "https://github.com/xinntao/DNI"
            ],
            [
                "git",
                "https://github.com/xinntao/HandyCrawler"
            ],
            [
                "git",
                "https://github.com/xinntao/HandyWriting"
            ],
            [
                "yt",
                "https://youtu.be/KaMYsxWkmww"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1JQScYICvEC3VqaabLu-lxvq9h7kSV1ML",
        "update": 1623075800.789
    },
    {
        "name": "Petals",
        "description": "Run 100B+ language models at home, BitTorrent-style",
        "author": [
            [
                "BigScience",
                "https://bigscience.huggingface.co/"
            ]
        ],
        "links": [
            [
                "project",
                "https://petals.ml/"
            ],
            [
                "git",
                "https://github.com/bigscience-workshop/petals",
                9273
            ],
            [
                "hf",
                "https://huggingface.co/bigscience/bloom"
            ],
            [
                "git",
                "https://github.com/borzunov/chat.petals.ml"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2209.01188"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/BitTorrent"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2108.07258"
            ],
            [
                "git",
                "https://github.com/timDettmers/bitsandbytes"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1Ervk6HPNS6AYVr3xVdQnY5a-TjjmLCdQ",
        "update": 1688561534.84
    },
    {
        "name": "py-irt",
        "description": "Fitting Item Response Theory models using variational inference",
        "author": [
            [
                "John Lalor",
                "https://jplalor.github.io/"
            ],
            [
                "Hong Yu",
                "https://scholar.google.com/citations?user=TyXe64wAAAAJ"
            ],
            [
                "Pedro Rodriguez",
                "https://www.pedro.ai/"
            ],
            [
                "Joe Barrow",
                "https://jbarrow.ai/"
            ],
            [
                "Alexander Hoyle",
                "https://alexanderhoyle.com/"
            ],
            [
                "Robin Jia",
                "https://robinjia.github.io/"
            ],
            [
                "Jordan Boyd-Graber",
                "https://github.com/ezubaric"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/nd-ball/py-irt",
                124
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1908.11421"
            ],
            [
                "doi",
                "https://doi.org/10.18653/v1/2021.acl-long.346",
                8
            ],
            [
                "paper",
                "https://www.frontiersin.org/articles/10.3389/fpsyg.2016.01422/full"
            ],
            [
                "yt",
                "https://youtu.be/akUxtt21Mlc"
            ]
        ],
        "colab": "https://colab.research.google.com/github/nd-ball/py-irt/blob/master/examples/py-irt_example.ipynb",
        "update": 1656592130.0
    },
    {
        "name": "Mubert",
        "description": "Prompt-based music generation via Mubert API",
        "author": [
            [
                "Ilya Belikov",
                "https://github.com/ferluht"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/MubertAI/Mubert-Text-to-Music",
                2736
            ],
            [
                "docs",
                "https://mubert2.docs.apiary.io/"
            ],
            [
                "project",
                "https://mubert.com/"
            ],
            [
                "yt",
                "https://youtu.be/YJu0iXn-T_U"
            ],
            [
                "yt",
                "https://youtu.be/5UsaxJsFvAI"
            ],
            [
                "yt",
                "https://youtu.be/B0kkIpWifG4"
            ]
        ],
        "colab": "https://colab.research.google.com/github/ferluht/Mubert-Text-to-Music/blob/main/Mubert_Text_to_Music.ipynb",
        "update": 1666072189.0
    },
    {
        "name": "Tzer",
        "description": "Coverage-Guided Tensor Compiler Fuzzing with Joint IR-Pass Mutation",
        "author": [
            [
                "Jiawei Liu",
                "https://jiawei-site.github.io/"
            ],
            [
                "Yuxiang Wei",
                "https://yuxiang.cs.illinois.edu/"
            ],
            [
                "Sen Yang",
                "https://github.com/syang-ng"
            ],
            [
                "Yinlin Deng",
                "https://dengyinlin.github.io/"
            ],
            [
                "Lingming Zhang",
                "http://lingming.cs.illinois.edu/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/ise-uiuc/tzer",
                70
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2202.09947"
            ],
            [
                "git",
                "https://github.com/ganler/memcov"
            ],
            [
                "docker",
                "https://hub.docker.com/repository/docker/tzerbot/oopsla"
            ],
            [
                "docs",
                "https://tzer.readthedocs.io/en/latest/index.html"
            ]
        ],
        "colab": "https://colab.research.google.com/github/ise-uiuc/tzer/blob/main/bug-report.ipynb",
        "update": 1678399197.0
    },
    {
        "name": "Anomalib",
        "description": "Deep learning library that aims to collect state-of-the-art anomaly detection algorithms for benchmarking on both public and private datasets",
        "author": [
            [
                "Samet Akcay",
                "https://github.com/samet-akcay"
            ],
            [
                "Dick Ameln",
                "https://github.com/djdameln"
            ],
            [
                "Ashwin Vaidya",
                "https://ashwinvaidya.com/"
            ],
            [
                "Barath Lakshmanan",
                "https://github.com/blakshma"
            ],
            [
                "Nilesh Ahuja",
                "https://github.com/nahuja-intel"
            ],
            [
                "Utku Genc",
                "https://github.com/ugenc-intel"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/openvinotoolkit/anomalib",
                3871
            ],
            [
                "docs",
                "https://openvinotoolkit.github.io/anomalib/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2011.08785"
            ],
            [
                "data",
                "https://www.mvtec.com/company/research/datasets/mvtec-ad"
            ],
            [
                "git",
                "https://github.com/rwightman/pytorch-image-models"
            ],
            [
                "medium",
                "https://towardsdatascience.com/getting-started-with-pytorch-image-models-timm-a-practitioners-guide-4e77b4bf9055"
            ],
            [
                "pwc",
                "https://paperswithcode.com/lib/timm"
            ],
            [
                "git",
                "https://github.com/vnk8071/anomaly-detection-in-industry-manufacturing/tree/master/anomalib_contribute"
            ]
        ],
        "colab": "https://colab.research.google.com/github/openvinotoolkit/anomalib/blob/main/notebooks/000_getting_started/001_getting_started.ipynb",
        "update": 1724932300.0
    },
    {
        "name": "OpenVINO",
        "description": "Open-source toolkit for optimizing and deploying AI inference",
        "author": [
            [
                "intel",
                "https://www.intel.com/content/www/us/en/developer/topic-technology/open/overview.html"
            ]
        ],
        "links": [
            [
                "blog post",
                "https://blog.openvino.ai/"
            ],
            [
                "git",
                "https://github.com/openvinotoolkit/openvino",
                7388
            ],
            [
                "docs",
                "https://docs.openvino.ai/"
            ],
            [
                "git",
                "https://github.com/openvinotoolkit/open_model_zoo"
            ],
            [
                "git",
                "https://github.com/Tencent/TNN"
            ],
            [
                "discord",
                "https://discord.gg/7pVRxUwdWG"
            ],
            [
                "forum",
                "https://software.intel.com/en-us/forums/computer-vision"
            ],
            [
                "git",
                "https://github.com/openvinotoolkit/openvino_contrib"
            ],
            [
                "git",
                "https://github.com/openvinotoolkit/training_extensions"
            ],
            [
                "git",
                "https://github.com/openvinotoolkit/model_server"
            ],
            [
                "git",
                "https://github.com/opencv/cvat"
            ],
            [
                "git",
                "https://github.com/openvinotoolkit/datumaro"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/OpenVINO"
            ],
            [
                "yt",
                "https://www.youtube.com/playlist?list=PLg-UKERBljNxdIQir1wrirZJ50yTp4eHv"
            ],
            [
                "yt",
                "https://youtu.be/Je8n8M0OwxQ"
            ],
            [
                "yt",
                "https://youtu.be/Ru51DELfc-Q"
            ],
            [
                "yt",
                "https://youtu.be/5X0RmlH6JI4"
            ],
            [
                "yt",
                "https://youtu.be/hhVRSLbpI5Q"
            ],
            [
                "yt",
                "https://youtu.be/JH8fsEAIaXo"
            ],
            [
                "yt",
                "https://www.youtube.com/playlist?list=PLWw98q-Xe7iH06qxEW5a22SBsSNsGnYjZ"
            ],
            [
                "medium",
                "https://medium.com/@openvino"
            ],
            [
                "hf",
                "https://huggingface.co/OpenVINO"
            ],
            [
                "medium",
                "https://medium.com/openvino-toolkit"
            ]
        ],
        "colab": "https://colab.research.google.com/github/openvinotoolkit/openvino_notebooks/blob/main/notebooks/001-hello-world/001-hello-world.ipynb",
        "update": 1711363030.0
    },
    {
        "name": "OCTIS",
        "description": "Framework for training, analyzing, and comparing Topic Models, whose optimal hyper-parameters are estimated using a Bayesian Optimization approach",
        "author": [
            [
                "Silvia Terragni",
                "https://silviatti.github.io/"
            ],
            [
                "Elisabetta Fersini",
                "https://www.unimib.it/elisabetta-fersini"
            ],
            [
                "Antonio Candelieri",
                "https://www.unimib.it/antonio-candelieri"
            ],
            [
                "Pietro Tropeano",
                "https://github.com/pietrotrope"
            ],
            [
                "Bruno Galuzzi",
                "https://github.com/brunoG89"
            ],
            [
                "Lorenzo Famiglini",
                "https://github.com/lorenzofamiglini"
            ],
            [
                "Davide Pietrasanta",
                "https://github.com/davidepietrasanta"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/mind-Lab/octis",
                734
            ],
            [
                "paper",
                "https://aclanthology.org/2021.eacl-demos.31/"
            ],
            [
                "medium",
                "https://towardsdatascience.com/a-beginners-guide-to-octis-optimizing-and-comparing-topic-models-is-simple-590554ec9ba6"
            ],
            [
                "medium",
                "https://towardsdatascience.com/a-beginners-guide-to-octis-vol-2-optimizing-topic-models-1214e58be1e5"
            ],
            [
                "pwc",
                "https://paperswithcode.com/dataset/20-newsgroups"
            ],
            [
                "data",
                "https://www.dbpedia.org/resources/ontology/"
            ],
            [
                "data",
                "https://www.statmt.org/europarl/"
            ],
            [
                "git",
                "https://github.com/estebandito22/PyTorchAVITM"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1703.01488"
            ],
            [
                "neurips",
                "https://papers.nips.cc/paper/2000/hash/f9d1152547c0bde01830b7e8bd60024c-Abstract.html"
            ],
            [
                "yt",
                "https://youtu.be/nPmiWBFFJ8E"
            ]
        ],
        "colab": "https://colab.research.google.com/github/MIND-Lab/OCTIS/blob/master/examples/OCTIS_Optimizing_CTM.ipynb",
        "update": 1618839165.0
    },
    {
        "name": "SAHI",
        "description": "A lightweight vision library for performing large scale object detection & instance segmentation",
        "author": [
            [
                "Fatih Cagatay Akyon",
                "https://github.com/fcakyon"
            ],
            [
                "Sinan Onur ALTINUÇ",
                "https://github.com/sinanonur"
            ],
            [
                "Alptekin Temizel",
                "https://blog.metu.edu.tr/atemizel/"
            ],
            [
                "Cemil Cengiz",
                "https://scholar.google.com/citations?user=1Ull07EAAAAJ"
            ],
            [
                "Devrim Çavuşoğlu",
                "https://github.com/devrimcavusoglu"
            ],
            [
                "Kadir Şahin",
                "https://github.com/ssahinnkadir"
            ],
            [
                "Oğulcan Eryüksel",
                "https://github.com/oulcan"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/obss/sahi",
                4148
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2202.06934"
            ],
            [
                "doi",
                "https://doi.org/10.1109/ICIP46576.2022.9897990",
                152
            ],
            [
                "hf",
                "https://huggingface.co/models?pipeline_tag=object-detection&sort=downloads"
            ],
            [
                "medium",
                "https://medium.com/codable/sahi-a-vision-library-for-performing-sliced-inference-on-large-images-small-objects-c8b086af3b80"
            ],
            [
                "git",
                "https://github.com/fcakyon/small-object-detection-benchmark"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/remekkinas/sahi-slicing-aided-hyper-inference-yv5-and-yx"
            ],
            [
                "medium",
                "https://medium.com/codable/convert-any-dataset-to-coco-object-detection-format-with-sahi-95349e1fe2b7"
            ]
        ],
        "colab": "https://colab.research.google.com/github/obss/sahi/blob/main/demo/inference_for_yolov5.ipynb",
        "update": 1677191201.0
    },
    {
        "name": "NetKet",
        "description": "Open-source project delivering cutting-edge methods for the study of many-body quantum systems with artificial neural networks and machine learning techniques",
        "author": [
            [
                "Filippo Vicentini",
                "https://filippovicentini.com/"
            ],
            [
                "Damian Hofmann",
                "https://github.com/femtobit"
            ],
            [
                "Attila Szabó",
                "https://github.com/attila-i-szabo"
            ],
            [
                "Dian Wu",
                "https://github.com/wdphy16"
            ],
            [
                "Christopher Roth",
                "https://github.com/chrisrothUT"
            ],
            [
                "Clemens Giuliani",
                "https://github.com/inailuig"
            ],
            [
                "Gabriel Pescia",
                "https://github.com/gpescia"
            ],
            [
                "Jannes Nys",
                "https://github.com/jwnys"
            ],
            [
                "Vladimir Vargas-Calderón",
                "https://github.com/VolodyaCO"
            ],
            [
                "Nikita Astrakhantsev",
                "https://github.com/nikita-astronaut"
            ],
            [
                "Giuseppe Carleo",
                "https://github.com/gcarleo"
            ],
            [
                "Kenny Choo",
                "https://github.com/kchoo1118"
            ],
            [
                "James Smith",
                "https://jamesetsmith.github.io/"
            ],
            [
                "Tom Westerhout",
                "https://github.com/twesterhout"
            ],
            [
                "Fabien Alet",
                "https://github.com/fabienalet"
            ],
            [
                "Emily Davis",
                "https://github.com/emilyjd"
            ],
            [
                "Stavros Efthymiou",
                "https://github.com/stavros11"
            ],
            [
                "Ivan Glasser",
                "https://www.researchgate.net/profile/Ivan-Glasser"
            ],
            [
                "Sheng-Hsuan Lin",
                "https://shhslin.github.io/"
            ],
            [
                "Marta Mauri",
                "https://github.com/martamau"
            ],
            [
                "Mazzola Guglielmo",
                "https://www.ics.uzh.ch/en/research/research-groups/Guglielmo-Mazzola0.html"
            ],
            [
                "Christian Mendl",
                "http://christian.mendl.net/"
            ],
            [
                "Evert Nieuwenburg",
                "https://evert.info/"
            ],
            [
                "Ossian O'Reilly",
                "https://github.com/ooreilly"
            ],
            [
                "Hugo Théveniaut",
                "https://github.com/theveniaut"
            ],
            [
                "Giacomo Torlai",
                "https://github.com/GTorlai"
            ],
            [
                "Alexander Wietek",
                "https://awietek.github.io/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/netket/netket",
                553
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2112.10526"
            ],
            [
                "website",
                "https://www.netket.org/"
            ],
            [
                "docs",
                "https://netket.readthedocs.io/en/latest/index.html"
            ],
            [
                "git",
                "https://github.com/mpi4jax/mpi4jax"
            ],
            [
                "git",
                "https://github.com/cloudhan/jax-windows-builder"
            ],
            [
                "yt",
                "https://youtu.be/Ryz-o71tuy8"
            ]
        ],
        "colab": "https://colab.research.google.com/github/PhilipVinc/Lectures/blob/main/2202_NetKet/01_intro.ipynb",
        "update": 1663237172.0
    },
    {
        "name": "Stable Baselines3",
        "description": "Set of reliable implementations of reinforcement learning algorithms in PyTorch",
        "author": [
            [
                "Antonin Raffin",
                "https://araffin.github.io/"
            ],
            [
                "Ashley Hill",
                "https://hill-a.me/"
            ],
            [
                "Adam Gleave",
                "https://www.gleave.me/"
            ],
            [
                "Anssi Kanervisto",
                "https://github.com/Miffyli"
            ],
            [
                "Maximilian Ernestus",
                "https://github.com/ernestum"
            ],
            [
                "Noah Dormann",
                "https://github.com/ndormann"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/DLR-RM/stable-baselines3",
                9269
            ],
            [
                "docs",
                "https://stable-baselines3.readthedocs"
            ],
            [
                "git",
                "https://github.com/Stable-Baselines-Team/stable-baselines3-contrib"
            ],
            [
                "paper",
                "https://jmlr.org/papers/v22/20-1364.html"
            ],
            [
                "git",
                "https://github.com/hill-a/stable-baselines"
            ],
            [
                "git",
                "https://github.com/openai/gym/wiki/Environments"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/reinforcementlearning/"
            ],
            [
                "yt",
                "https://www.youtube.com/playlist?list=PLQVvvaa0QuDf0O2DWwLZBfJeYY-JOeZB1"
            ]
        ],
        "colab": "https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/stable_baselines_getting_started.ipynb",
        "update": 1681470438.0
    },
    {
        "name": "RL Baselines3 Zoo",
        "description": "Training Framework for Stable Baselines3 Reinforcement Learning Agents",
        "author": [
            [
                "Antonin Raffin",
                "https://araffin.github.io/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/DLR-RM/rl-baselines3-zoo",
                2111
            ],
            [
                "git",
                "https://github.com/DLR-RM/rl-baselines3-zoo"
            ],
            [
                "docs",
                "https://stable-baselines3.readthedocs.io/en/master/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2005.05719"
            ],
            [
                "hf",
                "https://huggingface.co/sb3"
            ],
            [
                "git",
                "https://github.com/openai/roboschool"
            ],
            [
                "git",
                "https://github.com/Farama-Foundation/Minigrid"
            ]
        ],
        "colab": "https://colab.research.google.com/github/Stable-Baselines-Team/rl-colab-notebooks/blob/sb3/rl-baselines-zoo.ipynb",
        "update": 1681470438.0
    },
    {
        "name": "RL Games",
        "description": "High performance RL library",
        "author": [
            [
                "Denys Makoviichuk",
                "https://github.com/Denys88"
            ],
            [
                "Viktor Makoviychuk",
                "https://github.com/ViktorM"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/Denys88/rl_games",
                944
            ],
            [
                "discord",
                "https://discord.gg/hnYRq7DsQh"
            ],
            [
                "pypi",
                "https://pypi.org/project/rl-games/"
            ],
            [
                "git",
                "https://github.com/isaac-sim/IsaacGymEnvs"
            ],
            [
                "git",
                "https://github.com/NVlabs/cule"
            ],
            [
                "git",
                "https://github.com/NVlabs/tiny-cuda-nn"
            ]
        ],
        "colab": "https://colab.research.google.com/github/Denys88/rl_games/blob/master/notebooks/brax_training.ipynb",
        "update": 1664243171.0
    },
    {
        "name": "CleanRL",
        "description": "Deep Reinforcement Learning library that provides high-quality single-file implementation with research-friendly features",
        "author": [
            [
                "Shengyi Huang",
                "https://costa.sh/"
            ],
            [
                "Rousslan Dossa",
                "https://dosssman.github.io/"
            ],
            [
                "Chang Ye",
                "https://github.com/yooceii"
            ],
            [
                "Jeff Braga",
                "https://github.com/bragajj"
            ],
            [
                "Dipam Chakraborty",
                "https://github.com/dipamc"
            ],
            [
                "Kinal Mehta",
                "https://kinalmehta.github.io/"
            ],
            [
                "João Araújo",
                "https://github.com/joaogui1"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/vwxyzjn/cleanrl",
                5825
            ],
            [
                "paper",
                "https://www.jmlr.org/papers/v23/21-1342.html"
            ],
            [
                "yt",
                "https://www.youtube.com/channel/UCDdC6BIFRI0jvcwuhi3aI6w"
            ],
            [
                "hf",
                "https://huggingface.co/cleanrl"
            ],
            [
                "docs",
                "https://docs.cleanrl.dev/"
            ],
            [
                "git",
                "https://github.com/tinkoff-ai/CORL"
            ],
            [
                "git",
                "https://github.com/Farama-Foundation/Gymnasium"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1707.06347"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1707.06887"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1812.05905"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1509.02971"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1802.09477"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2009.04416"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1810.12894"
            ],
            [
                "git",
                "https://github.com/openai/baselines"
            ],
            [
                "git",
                "https://github.com/ikostrikov/jaxrl"
            ],
            [
                "yt",
                "https://youtu.be/dm4HdGujpPs"
            ]
        ],
        "colab": "https://colab.research.google.com/github/vwxyzjn/cleanrl/blob/master/docs/get-started/CleanRL_Huggingface_Integration_Demo.ipynb",
        "update": 1701135131.0
    },
    {
        "name": "Sample Factory",
        "description": "One of the fastest RL libraries focused on very efficient synchronous and asynchronous implementations of policy gradients",
        "author": [
            [
                "Aleksei Petrenko",
                "https://alex-petrenko.github.io/"
            ],
            [
                "Zhehui Huang",
                "https://zhehui-huang.github.io/"
            ],
            [
                "Tushar Kumar",
                "https://github.com/tushartk"
            ],
            [
                "Gaurav Sukhatme",
                "http://robotics.usc.edu/~gaurav/"
            ],
            [
                "Vladlen Koltun",
                "http://vladlen.info/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/alex-petrenko/sample-factory",
                835
            ],
            [
                "docs",
                "https://www.samplefactory.dev/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2006.11751"
            ],
            [
                "yt",
                "https://youtu.be/lLG17LKKSZc"
            ],
            [
                "git",
                "https://github.com/alex-petrenko/faster-fifo"
            ],
            [
                "ICML",
                "http://proceedings.mlr.press/v119/petrenko20a.html"
            ]
        ],
        "colab": "https://colab.research.google.com/github/alex-petrenko/sample-factory/blob/master/sf_examples/notebooks/samplefactory_hub_example.ipynb",
        "update": 1673915724.0
    },
    {
        "name": "Ray",
        "description": "Unified framework for scaling AI and Python applications",
        "author": [
            [
                "Philipp Moritz",
                "https://github.com/pcmoritz"
            ],
            [
                "Robert Nishihara",
                "https://github.com/robertnishihara"
            ],
            [
                "Stephanie Wang",
                "https://stephanie-wang.github.io/"
            ],
            [
                "Alexey Tumanov",
                "https://faculty.cc.gatech.edu/~atumanov/"
            ],
            [
                "Richard Liaw",
                "https://github.com/richardliaw"
            ],
            [
                "Eric Liang",
                "https://github.com/ericl"
            ],
            [
                "Melih Elibol",
                "https://research.nvidia.com/person/melih-elibol"
            ],
            [
                "Zongheng Yang",
                "https://zongheng.me/"
            ],
            [
                "William Paul",
                "https://github.com/Wapaul1"
            ],
            [
                "Michael Jordan",
                "https://people.eecs.berkeley.edu/~jordan/"
            ],
            [
                "Ion Stoica",
                "https://people.eecs.berkeley.edu/~istoica/"
            ]
        ],
        "links": [
            [
                "website",
                "https://www.ray.io/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1712.05889"
            ],
            [
                "git",
                "https://github.com/ray-project/ray",
                34293
            ],
            [
                "docs",
                "https://docs.ray.io/en/latest/index.html"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2203.05072"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1712.09381"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1807.05118"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1703.03924"
            ],
            [
                "yt",
                "https://youtu.be/LmROEotKhJA"
            ],
            [
                "yt",
                "https://youtu.be/uzt-CwohQC8"
            ],
            [
                "yt",
                "https://youtu.be/XME90SGL6Vs"
            ]
        ],
        "colab": "https://colab.research.google.com/github/ray-project/ray/blob/master/doc/source/tune/examples/optuna_example.ipynb",
        "update": 1693979720.0
    },
    {
        "name": "Hyperopt",
        "description": "Python library for serial and parallel optimization over awkward search spaces, which may include real-valued, discrete, and conditional dimensions",
        "author": [
            [
                "James Bergstra",
                "https://github.com/jaberg"
            ],
            [
                "Dan Yamins",
                "https://github.com/yamins81"
            ],
            [
                "David Cox",
                "https://scholar.google.com/citations?user=6S-WgLkAAAAJ"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/hyperopt/hyperopt",
                7280
            ],
            [
                "docs",
                "http://hyperopt.github.io/hyperopt/"
            ],
            [
                "neurips",
                "https://papers.nips.cc/paper/2011/hash/86e8f7ab32cfd12577bc2619bc635690-Abstract.html"
            ],
            [
                "git",
                "https://github.com/hyperopt/hyperopt-sklearn"
            ],
            [
                "git",
                "https://github.com/hyperopt/hyperopt-nnet"
            ],
            [
                "git",
                "https://github.com/hyperopt/hyperopt-nnet"
            ],
            [
                "git",
                "https://github.com/hyperopt/hyperopt-convnet"
            ],
            [
                "git",
                "https://github.com/hyperopt/hyperopt-gpsmbo"
            ],
            [
                "ICML",
                "https://proceedings.mlr.press/v28/bergstra13.html"
            ],
            [
                "yt",
                "https://youtu.be/Mp1xnPfE4PY"
            ],
            [
                "yt",
                "https://youtu.be/tdwgR1AqQ8Y"
            ],
            [
                "yt",
                "https://youtu.be/tteE_Vtmrv4"
            ]
        ],
        "colab": "https://colab.research.google.com/github/hyperopt/hyperopt/blob/master/tutorial/01.BasicTutorial.ipynb",
        "update": 1622533681.0
    },
    {
        "name": "Feast",
        "description": "An open source feature store for machine learning",
        "author": [
            [
                "Willem Pienaar",
                "https://github.com/woop"
            ],
            [
                "Danny Chiao",
                "https://github.com/adchia"
            ],
            [
                "Achal Shah",
                "http://achals.com/"
            ],
            [
                "Terence Lim",
                "https://terryyylim.github.io/portfolio/"
            ],
            [
                "Ches Martin",
                "https://github.com/ches"
            ],
            [
                "Judah Rand",
                "https://github.com/judahrand"
            ],
            [
                "Matt Delacour",
                "https://github.com/MattDelac"
            ],
            [
                "Miguel Trejo Marrufo",
                "https://github.com/TremaMiguel"
            ],
            [
                "Francisco Javier Arceo",
                "https://franciscojavierarceo.github.io/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/feast-dev/feast",
                5631
            ],
            [
                "website",
                "https://feast.dev/"
            ],
            [
                "docs",
                "https://docs.feast.dev/"
            ],
            [
                "git",
                "https://github.com/baineng/feast-hive"
            ],
            [
                "git",
                "https://github.com/Shopify/feast-trino"
            ],
            [
                "git",
                "https://github.com/Azure/feast-azure"
            ],
            [
                "git",
                "https://github.com/amundsen-io/amundsen/blob/main/databuilder/databuilder/extractor/feast_extractor.py"
            ],
            [
                "yt",
                "https://youtu.be/DaNv-Wf1MBA"
            ],
            [
                "yt",
                "https://youtu.be/p2cuq4eJ2BY"
            ]
        ],
        "colab": "https://colab.research.google.com/github/feast-dev/feast/blob/master/examples/quickstart/quickstart.ipynb",
        "update": 1732273110.0
    },
    {
        "name": "Optuna",
        "description": "An automatic hyperparameter optimization software framework, particularly designed for machine learning",
        "author": [
            [
                "Takuya Akiba",
                "https://iwiwi.github.io/"
            ],
            [
                "Shotaro Sano",
                "https://github.com/g-votte"
            ],
            [
                "Toshihiko Yanase",
                "https://github.com/toshihikoyanase"
            ],
            [
                "Takeru Ohta",
                "https://github.com/sile"
            ],
            [
                "Masanori Koyama",
                "https://scholar.google.com/citations?user=oY1gA10AAAAJ"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/optuna/optuna",
                11022
            ],
            [
                "website",
                "https://optuna.org/"
            ],
            [
                "docs",
                "https://optuna.readthedocs.io/en/stable/"
            ],
            [
                "git",
                "https://github.com/optuna/optuna-dashboard"
            ],
            [
                "docker",
                "https://hub.docker.com/r/optuna/optuna"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1907.10902"
            ],
            [
                "yt",
                "https://youtu.be/J_aymk4YXhg"
            ],
            [
                "yt",
                "https://youtu.be/tcrcLRopTX0"
            ],
            [
                "yt",
                "https://youtu.be/-UeC4MR3PHM"
            ],
            [
                "yt",
                "https://youtu.be/oC8zFYcfYXU"
            ]
        ],
        "colab": "https://colab.research.google.com/github/optuna/optuna-examples/blob/main/quickstart.ipynb",
        "update": 1707964058.0
    },
    {
        "name": "PyG",
        "description": "Library built upon PyTorch to easily write and train Graph Neural Networks for a wide range of applications related to structured data",
        "author": [
            [
                "Matthias Fey",
                "https://rusty1s.github.io/#/"
            ],
            [
                "Jan Eric Lenssen",
                "https://github.com/janericlenssen"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/pyg-team/pytorch_geometric",
                21519
            ],
            [
                "docs",
                "https://pytorch-geometric.readthedocs.io/en/latest/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1903.02428"
            ],
            [
                "git",
                "https://github.com/snap-stanford/ogb/tree/master/examples"
            ],
            [
                "pt",
                "https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html#full-implementation"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1801.07829"
            ],
            [
                "git",
                "https://github.com/pyg-team/pyg-lib"
            ],
            [
                "git",
                "https://github.com/rusty1s/pytorch_scatter"
            ],
            [
                "git",
                "https://github.com/rusty1s/pytorch_sparse"
            ],
            [
                "git",
                "https://github.com/rusty1s/pytorch_cluster"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1609.02907"
            ],
            [
                "neurips",
                "https://papers.nips.cc/paper/2018/hash/e77dbaf6759253c7c6d0efc5690369c7-Abstract.html"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2003.03123"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1905.05178"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1706.08566"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1907.10903"
            ],
            [
                "neurips",
                "https://papers.nips.cc/paper/2017/hash/5dd9db5e033da9c6fb5ba83c7a7ebea9-Abstract.html"
            ],
            [
                "neurips",
                "https://nips.cc/virtual/2020/public/poster_3fe230348e9a12c13120749e3f9fa4cd.html"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1905.07953"
            ],
            [
                "yt",
                "https://www.youtube.com/playlist?list=PLGMXrbDNfqTzqxB1IGgimuhtfAhGd8lHF"
            ],
            [
                "yt",
                "https://www.youtube.com/playlist?list=PLGMXrbDNfqTwPxitLVHEbT9Pd6-oR_cud"
            ],
            [
                "yt",
                "https://youtu.be/-UjytpbqX4A"
            ],
            [
                "git",
                "https://github.com/AntonioLonga/PytorchGeometricTutorial"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1h3-vJGRVloF5zStxL5I0rSy4ZUPNsjy8",
        "update": 1670482639.504
    },
    {
        "name": "Kornia",
        "description": "Library is composed by a subset of packages containing operators that can be inserted within neural networks to train models to perform image transformations, epipolar geometry, depth estimation, and low-level image processing such as filtering and edge detection that operate directly on tensors",
        "author": [
            [
                "Edgar Riba",
                "https://github.com/edgarriba"
            ],
            [
                "Dmytro Mishkin",
                "https://dmytro.ai/"
            ],
            [
                "Daniel Ponsa",
                "https://github.com/DanielPonsa"
            ],
            [
                "Ethan Rublee",
                "https://github.com/ethanrublee"
            ],
            [
                "Gary Bradski",
                "https://github.com/garybradski"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/kornia/kornia",
                10030
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1910.02190"
            ],
            [
                "doi",
                "https://doi.org/10.1109/WACV45572.2020.9093363",
                169
            ],
            [
                "docs",
                "https://kornia.readthedocs.io/en/latest/"
            ],
            [
                "blog post",
                "https://opencv.org/kornia-an-open-source-differentiable-computer-vision-library-for-pytorch/"
            ],
            [
                "yt",
                "https://www.youtube.com/channel/UCI1SE1Ij2Fast5BSKxoa7Ag"
            ],
            [
                "yt",
                "https://youtu.be/3RmCYFhwclE"
            ],
            [
                "yt",
                "https://youtu.be/AAZa-mXjYF0"
            ],
            [
                "slack",
                "https://join.slack.com/t/kornia/shared_invite/zt-csobk21g-2AQRi~X9Uu6PLMuUZdvfjA"
            ],
            [
                "website",
                "https://kornia.github.io/"
            ],
            [
                "twitter",
                "https://twitter.com/kornia_foss"
            ]
        ],
        "colab": "https://colab.research.google.com/github/kornia/kornia/blob/master/examples/augmentation/kornia_augmentation.ipynb",
        "update": 1733293098.0
    },
    {
        "name": "Composer",
        "description": "PyTorch library that enables you to train neural networks faster, at lower cost, and to higher accuracy",
        "author": [
            [
                "The Mosaic ML Team",
                "https://www.mosaicml.com/team"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/mosaicml/composer",
                5178
            ],
            [
                "docs",
                "http://docs.mosaicml.com/"
            ],
            [
                "website",
                "https://www.mosaicml.com/composer"
            ],
            [
                "blog post",
                "https://www.mosaicml.com/blog/5-best-practices-for-efficient-model-training"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Amdahl's_law"
            ],
            [
                "app",
                "https://app.mosaicml.com/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2202.05924"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2002.04688"
            ],
            [
                "yt",
                "https://www.youtube.com/@mosaicml6047/videos"
            ],
            [
                "yt",
                "https://youtu.be/n-1WV5QdIDc"
            ],
            [
                "yt",
                "https://youtu.be/Xi_5wq2MpOw"
            ],
            [
                "slack",
                "https://join.slack.com/t/mosaicml-community/shared_invite/zt-w0tiddn9-WGTlRpfjcO9J5jyrMub1dg"
            ],
            [
                "twitter",
                "https://twitter.com/mosaicml"
            ]
        ],
        "colab": "https://colab.research.google.com/github/mosaicml/composer/blob/dev/examples/getting_started.ipynb",
        "update": 1706825842.0
    },
    {
        "name": "deep-significance",
        "description": "Easy-to-use package containing different significance tests and utility functions specifically tailored towards research needs and usability",
        "author": [
            [
                "Dennis Ulmer",
                "http://dennisulmer.eu/"
            ],
            [
                "Christian Hardmeier",
                "https://christianhardmeier.rax.ch/"
            ],
            [
                "Jes Frellsen",
                "https://frellsen.org/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/Kaleidophon/deep-significance",
                330
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2204.06815"
            ],
            [
                "docs",
                "https://deep-significance.readthedocs.io/en/latest/"
            ],
            [
                "blog post",
                "https://machinelearningmastery.com/statistical-hypothesis-tests/"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Multiple_comparisons_problem"
            ],
            [
                "doi",
                "https://doi.org/10.18653/v1/p19-1266",
                26
            ],
            [
                "git",
                "https://github.com/rtmdrr/replicability-analysis-NLP"
            ],
            [
                "git",
                "https://github.com/rtmdrr/testSignificanceNLP"
            ],
            [
                "git",
                "https://github.com/rtmdrr/DeepComparison"
            ]
        ],
        "colab": "https://colab.research.google.com/github/Kaleidophon/deep-significance/blob/main/paper/deep-significance%20demo.ipynb",
        "update": 1649777069.0
    },
    {
        "name": "PyTerrier",
        "description": "A Python framework for performing information retrieval experiments",
        "author": [
            [
                "Craig Macdonald",
                "https://www.dcs.gla.ac.uk/~craigm/"
            ],
            [
                "Nicola Tonellotto",
                "https://github.com/tonellotto"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/terrier-org/pyterrier",
                420
            ],
            [
                "docs",
                "https://pyterrier.readthedocs.io"
            ],
            [
                "git",
                "https://github.com/terrier-org/ecir2021tutorial"
            ],
            [
                "git",
                "https://github.com/terrierteam/pyterrier_ance"
            ],
            [
                "git",
                "https://github.com/terrierteam/pyterrier_colbert"
            ],
            [
                "git",
                "https://github.com/terrierteam/pyterrier_pisa"
            ],
            [
                "git",
                "https://github.com/terrierteam/pyterrier_t5"
            ],
            [
                "git",
                "https://github.com/terrierteam/pyterrier_doc2query"
            ],
            [
                "git",
                "https://github.com/terrierteam/pyterrier_deepct"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2007.14271"
            ],
            [
                "doi",
                "https://doi.org/10.1145/3459637.3482013",
                49
            ]
        ],
        "colab": "https://colab.research.google.com/github/terrier-org/pyterrier/blob/master/examples/notebooks/non_en_retrieval.ipynb",
        "update": 1723802006.0
    },
    {
        "name": "normflows",
        "description": "PyTorch implementation of discrete normalizing flows",
        "author": [
            [
                "Vincent Stimper",
                "https://is.mpg.de/person/vstimper"
            ],
            [
                "David Liu",
                "https://davindicode.github.io/"
            ],
            [
                "Andrew Campbell",
                "https://github.com/andrew-cr"
            ],
            [
                "Vincent Berenz",
                "http://vincentberenz.is.tuebingen.mpg.de/"
            ],
            [
                "Lukas Ryll",
                "https://github.com/lukasryll"
            ],
            [
                "Bernhard Schölkopf",
                "https://scholar.google.com/citations?user=DZ-fHPgAAAAJ"
            ],
            [
                "José Miguel Hernández-Lobato",
                "https://jmhl.org/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/VincentStimper/normalizing-flows",
                741
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2302.12014"
            ],
            [
                "docs",
                "https://vincentstimper.github.io/normalizing-flows/"
            ],
            [
                "git",
                "https://github.com/VincentStimper/resampled-base-flows"
            ],
            [
                "git",
                "https://github.com/VincentStimper/hmc-hyperparameter-tuning"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Von_Mises_distribution"
            ]
        ],
        "colab": "https://colab.research.google.com/github/VincentStimper/normalizing-flows/blob/master/examples/paper_example_nsf_colab.ipynb",
        "update": 1687784391.0
    },
    {
        "name": "Open-Assistant",
        "description": "Chat-based assistant that understands tasks, can interact with third-party systems, and retrieve information dynamically to do so",
        "author": [
            [
                "Andreas Köpf",
                "https://github.com/andreaskoepf"
            ],
            [
                "Yannic Kilcher",
                "https://github.com/yk"
            ],
            [
                "Huu Nguyen",
                "https://github.com/ontocord"
            ],
            [
                "Christoph Schuhmann",
                "http://christoph-schuhmann.de/"
            ],
            [
                "Keith Stevens",
                "https://fozziethebeat.github.io/"
            ],
            [
                "Abdullah Barhoum",
                "https://github.com/AbdBarho"
            ],
            [
                "Nguyen Minh Duc",
                "https://github.com/notmd"
            ],
            [
                "Oliver Stanley",
                "https://olliestanley.github.io/"
            ],
            [
                "James Melvin Ebenezer",
                "https://github.com/melvinebenezer"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/LAION-AI/Open-Assistant",
                37101
            ],
            [
                "website",
                "https://open-assistant.io/"
            ],
            [
                "docs",
                "https://projects.laion.ai/Open-Assistant/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2203.02155"
            ],
            [
                "yt",
                "https://youtu.be/64Izfm24FKA"
            ],
            [
                "yt",
                "https://youtu.be/ddG2fM9i4Kk"
            ],
            [
                "yt",
                "https://youtu.be/FQIHLFLrTw0"
            ],
            [
                "hf",
                "https://huggingface.co/OpenAssistant"
            ],
            [
                "medium",
                "https://generativeai.pub/open-assistant-a-free-and-open-source-alternative-to-chatgpt-67d15229813"
            ]
        ],
        "colab": "https://colab.research.google.com/github/LAION-AI/Open-Assistant/blob/main/notebooks/data-augmentation/stackexchange-builder/stackexchange-builder.ipynb",
        "update": 1673736669.0
    },
    {
        "name": "Aesthetics Predictor",
        "description": "A linear estimator on top of clip to predict the aesthetic quality of pictures",
        "author": [
            [
                "LAION AI",
                "https://laion.ai/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/LAION-AI/aesthetic-predictor",
                490
            ],
            [
                "git",
                "https://github.com/rom1504/embedding-reader/blob/main/examples/aesthetic_inference.py"
            ],
            [
                "blog post",
                "https://laion.ai/blog/laion-aesthetics/"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/discussions/general/464229"
            ]
        ],
        "colab": "https://colab.research.google.com/github/LAION-AI/aesthetic-predictor/blob/main/asthetics_predictor.ipynb",
        "update": 1654334408.0
    },
    {
        "name": "DeepFloyd IF",
        "description": "State-of-the-art open-source text-to-image model with a high degree of photorealism and language understanding",
        "author": [
            [
                "Alex Shonenkov",
                "https://linktr.ee/shonenkovAI"
            ],
            [
                "Misha Konstantinov",
                "https://github.com/zeroshot-ai"
            ],
            [
                "Daria Bakshandaeva",
                "https://github.com/Gugutse"
            ],
            [
                "Christoph Schuhmann",
                "http://christoph-schuhmann.de/"
            ],
            [
                "Ksenia Ivanova",
                "https://github.com/ivksu"
            ],
            [
                "Nadiia Klokova",
                "https://github.com/vauimpuls"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/deep-floyd/IF",
                7701
            ],
            [
                "website",
                "https://deepfloyd.ai/deepfloyd-if"
            ],
            [
                "discord",
                "https://discord.gg/umz62Mgr"
            ],
            [
                "twitter",
                "https://twitter.com/deepfloydai"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2205.11487"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/code/shonenkov/deepfloyd-if-4-3b-generator-of-pictures"
            ],
            [
                "hf",
                "https://huggingface.co/DeepFloyd"
            ],
            [
                "hf",
                "https://huggingface.co/docs/diffusers/optimization/fp16#model-offloading-for-fast-inference-and-memory-savings"
            ],
            [
                "hf",
                "https://huggingface.co/docs/diffusers/api/pipelines/if#optimizing-for-speed"
            ],
            [
                "hf",
                "https://huggingface.co/docs/diffusers/api/pipelines/if#optimizing-for-memory"
            ],
            [
                "hf",
                "https://huggingface.co/blog/if"
            ],
            [
                "hf",
                "https://huggingface.co/docs/diffusers/main/en/api/pipelines/if"
            ],
            [
                "yt",
                "https://youtu.be/4Zkipll5Rjc"
            ],
            [
                "yt",
                "https://youtu.be/tq5ZXZWwTPA"
            ],
            [
                "yt",
                "https://youtu.be/rLtfd1TvYJk"
            ]
        ],
        "colab": "https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/deepfloyd_if_free_tier_google_colab.ipynb",
        "update": 1687806336.0
    },
    {
        "name": "Machine learning course",
        "description": "This course is broad and shallow, but author will provide additional links so that you can deepen your understanding of the ML method you need",
        "author": [
            [
                "Тимчишин Віталій",
                "https://github.com/fbeilstein"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/fbeilstein/machine_learning",
                169
            ],
            [
                "yt",
                "https://www.youtube.com/playlist?list=PLkDeTjsoxDVgnb2lIYo9-1l4XYhrIyS6A"
            ],
            [
                "blog post",
                "https://vas3k.com/blog/machine_learning/"
            ],
            [
                "yt",
                "https://youtu.be/-RdOwhmqP5s"
            ],
            [
                "yt",
                "https://youtu.be/R13BD8qKeTg"
            ],
            [
                "yt",
                "https://youtu.be/ZkjP5RJLQF4"
            ],
            [
                "yt",
                "https://youtu.be/J4Wdy0Wc_xQ"
            ],
            [
                "yt",
                "https://youtu.be/mBcLRGuAFUk"
            ],
            [
                "yt",
                "https://youtu.be/YIGtalP1mv0"
            ],
            [
                "yt",
                "https://youtu.be/Yz5pySyEtsU"
            ],
            [
                "yt",
                "https://youtu.be/x5zLaWT5KPs"
            ],
            [
                "yt",
                "https://youtu.be/yBwpo-L80Mc"
            ],
            [
                "yt",
                "https://www.youtube.com/playlist?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv"
            ]
        ],
        "colab": "https://colab.research.google.com/github/fbeilstein/machine_learning/blob/master/lecture_01_introduction.ipynb",
        "update": 1630595244.0
    },
    {
        "name": "NYU-DLSP20",
        "description": "This course concerns the latest techniques in deep learning and representation learning, focusing on supervised and unsupervised deep learning, embedding methods, metric learning, convolutional and recurrent nets, with applications to computer vision, natural language understanding, and speech recognition",
        "author": [
            [
                "Yann LeCun",
                "https://yann.lecun.com/"
            ],
            [
                "Alfredo Canziani",
                "https://atcold.github.io/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/Atcold/NYU-DLSP20",
                6697
            ],
            [
                "website",
                "https://atcold.github.io/NYU-DLSP20/"
            ],
            [
                "discord",
                "https://discord.gg/CthuqsX8Pb"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/NYU_DeepLearning/"
            ],
            [
                "yt",
                "https://www.youtube.com/playlist?list=PLLHTzKZzVU9eaEyErdV26ikyolxOsz6mq"
            ],
            [
                "git",
                "https://github.com/Atcold/NYU-DLSP21"
            ],
            [
                "git",
                "https://github.com/Atcold/NYU-DLFL22"
            ]
        ],
        "colab": "https://colab.research.google.com/github/Atcold/NYU-DLSP20/blob/master/00-logic_neuron_programming.ipynb",
        "update": 1572414730.0
    },
    {
        "name": "ARENA",
        "description": "Provide talented individuals with the skills, tools, and environment necessary for upskilling in ML engineering, for the purpose of contributing directly to AI alignment in technical roles",
        "author": [
            [
                "Callum McDougall",
                "https://www.perfectlynormal.co.uk/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/callummcdougall/ARENA_3.0",
                367
            ],
            [
                "website",
                "https://arena-resources.notion.site/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2211.00593"
            ],
            [
                "slack",
                "https://join.slack.com/t/arena-uk/shared_invite/zt-2noug8mpy-TRYbCnc3pzj7ITNrZIjKww"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1vuQOB2Gd7OcfzH2y9djXm9OdZA_DcxYz",
        "update": 1732589624.892
    },
    {
        "name": "DSP theory",
        "description": "Theory of digital signal processing: signals, filtration (IIR, FIR, CIC, MAF), transforms (FFT, DFT, Hilbert, Z-transform) etc",
        "author": [
            [
                "Alexander Kapitanov",
                "https://github.com/hukenovs"
            ],
            [
                "Vladimir Fadeev",
                "https://github.com/kirlf"
            ],
            [
                "Karina Kvanchiani",
                "https://github.com/karinakvanchiani"
            ],
            [
                "Elizaveta Petrova",
                "https://github.com/kleinsbotle"
            ],
            [
                "Andrei Makhliarchuk",
                "https://github.com/anotherhelloworld"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/hukenovs/dsp-theory",
                996
            ],
            [
                "blog post",
                "https://habr.com/ru/articles/460445/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/hukenovs/dsp-theory/blob/master/src/dsp_theory_1_signals.ipynb",
        "update": 1666089256.0
    },
    {
        "name": "mlcourse.ai",
        "description": "Open Machine Learning Course",
        "author": [
            [
                "Yury Kashnitsky",
                "https://yorko.github.io/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/Yorko/mlcourse.ai",
                9806
            ],
            [
                "slack",
                "https://opendatascience.slack.com/archives/C91N8TL83/p1567408586359500"
            ],
            [
                "project",
                "https://mlcourse.ai/book/index.html"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/kashnitsky/mlcourse"
            ],
            [
                "medium",
                "https://medium.com/open-machine-learning-course"
            ],
            [
                "blog post",
                "https://habr.com/company/ods/blog/344044/"
            ],
            [
                "yt",
                "https://www.youtube.com/playlist?list=PLVlY_7IJCMJeRfZ68eVfEcu-UcN9BbwiX"
            ]
        ],
        "colab": "https://colab.research.google.com/github/Yorko/mlcourse.ai/blob/main/jupyter_english/topic01_pandas_data_analysis/topic1_pandas_data_analysis.ipynb",
        "update": 1724080153.0
    },
    {
        "name": "Machine Learning Simplified",
        "description": "A Gentle Introduction to Supervised Learning",
        "author": [
            [
                "Andrew Wolf",
                "https://5x12.ai/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/5x12/themlsbook",
                427
            ],
            [
                "website",
                "https://www.themlsbook.com/"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/Python/comments/t8st9l/i_wrote_a_book_on_machine_learning_w_python_code/"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/learnmachinelearning/comments/snxlly/machine_learning_simplified_book/"
            ],
            [
                "medium",
                "https://medium.com/geekculture/i-found-a-great-machine-learning-book-deed11db2688"
            ]
        ],
        "colab": "https://colab.research.google.com/github/5x12/themlsbook/blob/master/chapter2/knn.ipynb",
        "update": 1724960156.0
    },
    {
        "name": "Nerfstudio",
        "description": "API that allows for a simplified end-to-end process of creating, training, and testing NeRFs",
        "author": [
            [
                "Matthew Tancik",
                "https://github.com/tancik"
            ],
            [
                "Ethan Weber",
                "https://ethanweber.me/"
            ],
            [
                "Evonne Ng",
                "http://people.eecs.berkeley.edu/~evonne_ng/"
            ],
            [
                "Ruilong Li",
                "http://www.liruilong.cn/"
            ],
            [
                "Brent Yi",
                "https://github.com/brentyi"
            ],
            [
                "Justin Kerr",
                "https://kerrj.github.io/"
            ],
            [
                "Terrance Wang",
                "https://github.com/terrancewang"
            ],
            [
                "Alexander Kristoffersen",
                "https://akristoffersen.com/"
            ],
            [
                "Jake Austin",
                "https://github.com/jake-austin"
            ],
            [
                "Kamyar Salahi",
                "https://github.com/TheQuantumFractal"
            ],
            [
                "Abhik Ahuja",
                "https://abhikahuja.com/"
            ],
            [
                "David McAllister",
                "https://github.com/mcallisterdavid"
            ],
            [
                "Angjoo Kanazawa",
                "https://github.com/akanazawa"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/nerfstudio-project/nerfstudio",
                9620
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2302.04264"
            ],
            [
                "Viewer",
                "https://viewer.nerf.studio/"
            ],
            [
                "git",
                "https://github.com/NVlabs/tiny-cuda-nn"
            ],
            [
                "docs",
                "https://docs.nerf.studio/en/latest/"
            ],
            [
                "yt",
                "https://youtu.be/XwKq7qDQCQk"
            ],
            [
                "discord",
                "https://discord.gg/uMbNqcraFc"
            ],
            [
                "twitter",
                "https://twitter.com/nerfstudioteam"
            ],
            [
                "yt",
                "https://youtu.be/nSFsugarWzk"
            ],
            [
                "yt",
                "https://youtu.be/h5EWiRRxYEQ"
            ],
            [
                "yt",
                "https://youtu.be/8cv9G7izdPY"
            ]
        ],
        "colab": "https://colab.research.google.com/github/nerfstudio-project/nerfstudio/blob/main/colab/demo.ipynb",
        "update": 1724080994.0
    },
    {
        "name": "BLIP",
        "description": "VLP framework which transfers flexibly to both vision-language understanding and generation tasks",
        "author": [
            [
                "Junnan Li",
                "https://github.com/LiJunnan1992"
            ],
            [
                "Dongxu Li",
                "https://sites.google.com/view/dongxu-li/home"
            ],
            [
                "Caiming Xiong",
                "http://cmxiong.com/"
            ],
            [
                "Steven Hoi",
                "https://sites.google.com/view/stevenhoi"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/salesforce/BLIP",
                4863
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2201.12086"
            ],
            [
                "blog post",
                "https://blog.salesforceairesearch.com/blip-bootstrapping-language-image-pretraining/"
            ],
            [
                "git",
                "https://github.com/facebookresearch/fairscale"
            ],
            [
                "git",
                "https://github.com/salesforce/ALPRO"
            ],
            [
                "git",
                "https://github.com/dmlc/decord"
            ],
            [
                "git",
                "https://github.com/salesforce/ALBEF"
            ],
            [
                "git",
                "https://github.com/rwightman/pytorch-image-models/tree/main/timm"
            ],
            [
                "yt",
                "https://youtu.be/X2k7n4FuI7c"
            ]
        ],
        "colab": "https://colab.research.google.com/github/salesforce/BLIP/blob/main/demo.ipynb",
        "update": 1646265549.0
    },
    {
        "name": "LAVIS",
        "description": "Python deep learning library for LAnguage-and-VISion intelligence research and applications",
        "author": [
            [
                "Dongxu Li",
                "https://github.com/dxli94"
            ],
            [
                "Junnan Li",
                "https://github.com/LiJunnan1992"
            ],
            [
                "Hung Le",
                "https://sites.google.com/view/henryle2018/home"
            ],
            [
                "Guangsen Wang",
                "https://github.com/guangsen-wang"
            ],
            [
                "Silvio Savarese",
                "https://scholar.google.com/citations?user=ImpbxLsAAAAJ"
            ],
            [
                "Steven Hoi",
                "https://sites.google.com/view/stevenhoi"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/salesforce/LAVIS",
                10014
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2209.09019"
            ],
            [
                "docs",
                "https://opensource.salesforce.com/LAVIS//latest/index.html"
            ],
            [
                "blog post",
                "https://blog.salesforceairesearch.com/lavis-language-vision-library/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2305.06500"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2301.12597"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2212.10846"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2210.08773"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Merlion"
            ]
        ],
        "colab": "https://colab.research.google.com/github/salesforce/LAVIS/blob/main/projects/img2llm-vqa/img2llm_vqa.ipynb",
        "update": 1679640165.0
    },
    {
        "name": "SoftVC VITS",
        "description": "Singing Voice Conversion",
        "author": [
            [
                "svc develop team",
                "https://github.com/svc-develop-team"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/svc-develop-team/so-vits-svc",
                26026
            ],
            [
                "git",
                "https://github.com/NaruseMioShirakana/MoeVoiceStudio"
            ],
            [
                "git",
                "https://github.com/openvpi/DiffSinger/tree/refactor/modules/nsf_hifigan"
            ],
            [
                "git",
                "https://github.com/auspicious3000/contentvec"
            ],
            [
                "hf",
                "https://huggingface.co/NaruseMioShirakana/MoeSS-SUBModel/tree/main"
            ],
            [
                "git",
                "https://github.com/yxlllc/DDSP-SVC"
            ],
            [
                "git",
                "https://github.com/flutydeer/audio-slicer"
            ],
            [
                "git",
                "https://github.com/openvpi/audio-slicer"
            ]
        ],
        "colab": "https://colab.research.google.com/github/svc-develop-team/so-vits-svc/blob/4.1-Stable/sovits4_for_colab.ipynb",
        "update": 1690799899.0
    },
    {
        "name": "ComfyUI",
        "description": "Powerful and modular stable diffusion GUI and backend",
        "author": [
            [
                "comfyanonymous",
                "https://github.com/comfyanonymous"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/comfyanonymous/ComfyUI",
                58973
            ],
            [
                "examples",
                "https://comfyanonymous.github.io/ComfyUI_examples/"
            ],
            [
                "pytorch",
                "https://developer.apple.com/metal/pytorch/"
            ],
            [
                "yt",
                "https://youtu.be/vUTV85D51yk"
            ],
            [
                "yt",
                "https://youtu.be/gySLXbe7WZQ"
            ],
            [
                "yt",
                "https://youtu.be/ovjeVGmy6ZM"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/StableDiffusion/comments/10lzgze/i_figured_out_a_way_to_apply_different_prompts_to/"
            ],
            [
                "git",
                "https://github.com/madebyollin/taesd"
            ]
        ],
        "colab": "https://colab.research.google.com/github/comfyanonymous/ComfyUI/blob/master/notebooks/comfyui_colab.ipynb",
        "update": 1724975328.0
    },
    {
        "name": "Flashlight",
        "description": "Fast, flexible machine learning library written entirely in C++",
        "author": [
            [
                "Jacob Kahn",
                "https://jacobkahn.me/"
            ],
            [
                "Vineel Pratap",
                "https://github.com/vineelpratap"
            ],
            [
                "Tatiana Likhomanenko",
                "https://github.com/tlikhomanenko"
            ],
            [
                "Qiantong Xu",
                "https://github.com/xuqiantong"
            ],
            [
                "Awni Hannun",
                "https://awnihannun.com/"
            ],
            [
                "Jeff Cai",
                "https://ieeexplore.ieee.org/author/37086866180"
            ],
            [
                "Paden Tomasello",
                "https://github.com/padentomasello"
            ],
            [
                "Ann Lee",
                "https://scholar.google.com/citations?user=Am6PakYAAAAJ"
            ],
            [
                "Edouard Grave",
                "https://github.com/EdouardGrave"
            ],
            [
                "Gilad Avidov",
                "https://github.com/avidov"
            ],
            [
                "Benoit Steiner",
                "http://bsteiner.info/"
            ],
            [
                "Vitaliy Liptchinsky",
                "https://scholar.google.com/citations?user=zl4dA-gAAAAJ"
            ],
            [
                "Gabriel Synnaeve",
                "https://syhw.github.io/"
            ],
            [
                "Ronan Collobert",
                "https://ronan.collobert.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/flashlight/flashlight",
                5295
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2201.12465"
            ],
            [
                "docs",
                "https://fl.readthedocs.io/en/latest/"
            ],
            [
                "docker",
                "https://hub.docker.com/r/flml/flashlight/tags?page=1&ordering=last_updated&name=cuda-latest"
            ],
            [
                "git",
                "https://github.com/arrayfire/arrayfire"
            ],
            [
                "git",
                "https://github.com/microsoft/vcpkg"
            ],
            [
                "git",
                "https://github.com/arrayfire/arrayfire-ml/"
            ],
            [
                "git",
                "https://github.com/nvidia/cub"
            ],
            [
                "git",
                "https://github.com/USCiLab/cereal"
            ],
            [
                "git",
                "https://github.com/nothings/stb"
            ],
            [
                "git",
                "https://github.com/facebookincubator/gloo"
            ],
            [
                "git",
                "https://github.com/oneapi-src/oneDNN"
            ],
            [
                "git",
                "https://github.com/google/glog"
            ],
            [
                "git",
                "https://github.com/gflags/gflags"
            ],
            [
                "git",
                "https://github.com/flashlight/text"
            ]
        ],
        "colab": "https://colab.research.google.com/github/flashlight/flashlight/blob/master/flashlight/app/asr/tutorial/notebooks/FinetuneCTC.ipynb",
        "update": 1654120720.0
    },
    {
        "name": "AnimateDiff",
        "description": "Practical framework to animate most of the existing personalized text-to-image models once and for all, saving efforts in model-specific tuning",
        "author": [
            [
                "Yuwei Guo",
                "https://github.com/guoyww"
            ],
            [
                "Ceyuan Yang",
                "https://github.com/limbo0000"
            ],
            [
                "Anyi Rao",
                "https://anyirao.com/"
            ],
            [
                "Yaohui Wang",
                "https://wyhsirius.github.io/"
            ],
            [
                "Yu Qiao",
                "https://mmlab.siat.ac.cn/yuqiao/"
            ],
            [
                "Dahua Lin",
                "http://dahua.site/"
            ],
            [
                "Bo Dai",
                "https://daibo.info/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/guoyww/animatediff/",
                10676
            ],
            [
                "project",
                "https://animatediff.github.io/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2307.04725"
            ],
            [
                "git",
                "https://github.com/continue-revolution/sd-webui-animatediff"
            ],
            [
                "git",
                "https://github.com/talesofai/AnimateDiff"
            ],
            [
                "yt",
                "https://youtu.be/rdnOhM8L8nE"
            ],
            [
                "git",
                "https://youtu.be/-wki7IrQ_sU"
            ],
            [
                "yt",
                "https://youtu.be/LcHAZaJjA5k"
            ],
            [
                "yt",
                "https://www.youtube.com/live/66JgpI3a650?feature=share"
            ]
        ],
        "colab": "https://colab.research.google.com/github/camenduru/AnimateDiff-colab/blob/main/AnimateDiff_colab.ipynb",
        "update": 1698678800.0
    },
    {
        "name": "AniPortrait",
        "description": "Framework for generating high-quality animation driven by audio and a reference portrait image",
        "author": [
            [
                "Zejun Yang",
                "https://github.com/Zejun-Yang"
            ],
            [
                "Zhisheng Wang",
                "https://scholar.google.com/citations?user=XrK2HNcAAAAJ"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/Zejun-Yang/AniPortrait",
                4692
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2403.17694"
            ],
            [
                "hf",
                "https://huggingface.co/ZJYang/AniPortrait"
            ],
            [
                "hf",
                "https://huggingface.co/runwayml/stable-diffusion-v1-5"
            ],
            [
                "hf",
                "https://huggingface.co/stabilityai/sd-vae-ft-mse"
            ],
            [
                "hf",
                "https://huggingface.co/lambdalabs/sd-image-variations-diffusers/tree/main/image_encoder"
            ],
            [
                "hf",
                "https://huggingface.co/facebook/wav2vec2-base-960h"
            ],
            [
                "git",
                "https://github.com/CelebV-HQ/CelebV-HQ"
            ],
            [
                "git",
                "https://github.com/HumanAIGC/EMO"
            ],
            [
                "git",
                "https://github.com/MooreThreads/Moore-AnimateAnyone"
            ],
            [
                "git",
                "https://github.com/magic-research/magic-animate"
            ],
            [
                "git",
                "https://github.com/guoqincode/Open-AnimateAnyone"
            ],
            [
                "yt",
                "https://youtu.be/wdRhYLQFQH8"
            ],
            [
                "yt",
                "https://youtu.be/T-B6xJRG6fQ"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/StableDiffusion/comments/1bp7rnj/aniportrait_audiodriven_synthesis_of/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/camenduru/AniPortrait-jupyter/blob/main/AniPortrait_vid2vid_jupyter.ipynb",
        "update": 1711542413.0
    },
    {
        "name": "Bark",
        "description": "Transformer-based text-to-audio model",
        "author": [
            [
                "suno",
                "https://www.suno.ai/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/suno-ai/bark",
                36339
            ],
            [
                "discord",
                "https://discord.gg/J2B2vsjKuE"
            ],
            [
                "twitter",
                "https://twitter.com/OnusFM"
            ],
            [
                "examples",
                "https://suno-ai.notion.site/Bark-Examples-5edae8b02a604b54a42244ba45ebc2e2"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2209.03143"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2301.02111"
            ],
            [
                "git",
                "https://github.com/facebookresearch/encodec"
            ],
            [
                "git",
                "https://github.com/karpathy/nanoGPT"
            ],
            [
                "hf",
                "https://huggingface.co/docs/huggingface_hub/package_reference/environment_variables#hfhome"
            ],
            [
                "yt",
                "https://youtu.be/84LzaXAo6vE"
            ],
            [
                "yt",
                "https://youtu.be/rU5Do9yHbwM"
            ],
            [
                "yt",
                "https://youtu.be/w41-MUfxIWo"
            ],
            [
                "yt",
                "https://youtu.be/_m-MxEpHUQY"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1dWWkZzvu7L9Bunq9zvD-W02RFUXoW-Pd",
        "update": 1698228306.166
    },
    {
        "name": "Fooocus",
        "description": "Image generating software",
        "author": [
            [
                "Lvmin Zhang",
                "https://lllyasviel.github.io/Style2PaintsResearch/lvmin"
            ]
        ],
        "links": [
            [
                "arxiv",
                "https://arxiv.org/abs/2210.00939"
            ],
            [
                "yt",
                "https://youtu.be/8krykSwOz3E"
            ],
            [
                "yt",
                "https://youtu.be/558W8rfnP-Q"
            ],
            [
                "yt",
                "https://youtu.be/TJkrzuPdmvE"
            ],
            [
                "yt",
                "https://youtu.be/NfNwmKM3sxc"
            ],
            [
                "git",
                "https://github.com/lllyasviel/Fooocus",
                41788
            ]
        ],
        "colab": "https://colab.research.google.com/github/lllyasviel/Fooocus/blob/main/colab.ipynb",
        "update": 1696354602.0
    },
    {
        "name": "RWKV",
        "description": "Reinventing RNNs for the Transformer Era",
        "author": [
            [
                "Bo Peng",
                "https://github.com/BlinkDL"
            ],
            [
                "Eric Alcaide",
                "https://hypnopump.github.io/"
            ],
            [
                "Quentin Anthony",
                "https://quentin-anthony.github.io/"
            ],
            [
                "Alon Albalak",
                "https://alon-albalak.github.io/"
            ],
            [
                "Samuel Arcadinho",
                "https://github.com/SSamDav"
            ],
            [
                "Matteo Grella",
                "http://www.matteogrella.com/"
            ],
            [
                "Kranthi Kiran",
                "https://kranthigv.github.io/"
            ],
            [
                "Haowen Hou",
                "https://github.com/howard-hou"
            ],
            [
                "Przemyslaw Kazienko",
                "https://kazienko.eu/en"
            ],
            [
                "Jan Kocon",
                "https://github.com/KoconJan"
            ],
            [
                "Bartlomiej Koptyra",
                "https://github.com/bkoptyra"
            ],
            [
                "Ipsit Mantri",
                "https://ipsitmantri.github.io/"
            ],
            [
                "Ferdinand Mom",
                "https://3outeille.github.io/"
            ],
            [
                "Xiangru Tang",
                "https://github.com/tangxiangru"
            ],
            [
                "Johan Wind",
                "https://johanwind.github.io/"
            ],
            [
                "Stanisław Woźniak",
                "https://www.researchgate.net/profile/Stanislaw-Wozniak-3"
            ],
            [
                "Qihang Zhao",
                "https://www.researchgate.net/profile/Qihang-Zhao-2"
            ],
            [
                "Peng Zhou",
                "https://pengzhou.sites.ucsc.edu/"
            ],
            [
                "Jian Zhu",
                "https://lingjzhu.github.io/"
            ],
            [
                "Rui-Jie Zhu",
                "https://scholar.google.com/citations?user=08ITzJsAAAAJ"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/BlinkDL/RWKV-LM",
                12735
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2305.13048"
            ],
            [
                "hf",
                "https://huggingface.co/BlinkDL"
            ],
            [
                "website",
                "https://www.rwkv.com/"
            ],
            [
                "git",
                "https://github.com/saharNooby/rwkv.cpp"
            ],
            [
                "git",
                "https://github.com/cgisky1980/ai00_rwkv_server"
            ],
            [
                "git",
                "https://github.com/harrisonvanderbyl/rwkv-cpp-cuda"
            ],
            [
                "git",
                "https://github.com/Blealtan/RWKV-LM-LoRA"
            ],
            [
                "git",
                "https://github.com/TheRamU/Fay/blob/main/README_EN.md"
            ],
            [
                "discord",
                "https://discord.gg/bDSBUMeFpc"
            ],
            [
                "twitter",
                "https://twitter.com/BlinkDL_AI"
            ],
            [
                "git",
                "https://github.com/ridgerchu/SpikeGPT"
            ],
            [
                "hf",
                "https://huggingface.co/BlinkDL/clip-guided-binary-autoencoder"
            ],
            [
                "twitter",
                "https://twitter.com/HochreiterSepp/status/1524270961314484227"
            ],
            [
                "demo",
                "https://josephrocca.github.io/rwkv-v4-web/demo/"
            ],
            [
                "git",
                "https://github.com/BlinkDL/RWKV-v2-RNN-Pile/tree/main/RWKV-v3"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2105.14103"
            ],
            [
                "git",
                "https://github.com/BlinkDL/SmallInitEmb"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/MachineLearning/comments/umq908/r_rwkvv2rnn_a_parallelizable_rnn_with/"
            ],
            [
                "git",
                "https://github.com/BlinkDL/RWKV-CUDA"
            ],
            [
                "git",
                "https://github.com/BlinkDL/minGPT-tuned"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2002.05202"
            ],
            [
                "data",
                "https://dldata-public.s3.us-east-2.amazonaws.com/simplebooks.zip"
            ],
            [
                "yt",
                "https://youtu.be/x8pW19wKfXQ"
            ],
            [
                "yt",
                "https://youtu.be/B3Qa2rRsaXo"
            ],
            [
                "yt",
                "https://youtu.be/w-xydM6C6Qc"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1F7tZoPZaWJf1fsCmZ5tjw6sYHiFOYVWM",
        "update": 1663743587.297
    },
    {
        "name": "ChatRWKV",
        "description": "Like ChatGPT but powered by RWKV (100% RNN) language model, which is the only RNN that can match transformers in quality and scaling, while being faster and saves VRAM",
        "author": [
            [
                "Bo Peng",
                "https://github.com/BlinkDL"
            ],
            [
                "Eric Alcaide",
                "https://hypnopump.github.io/"
            ],
            [
                "Quentin Anthony",
                "https://quentin-anthony.github.io/"
            ],
            [
                "Alon Albalak",
                "https://alon-albalak.github.io/"
            ],
            [
                "Samuel Arcadinho",
                "https://github.com/SSamDav"
            ],
            [
                "Matteo Grella",
                "http://www.matteogrella.com/"
            ],
            [
                "Kranthi Kiran",
                "https://kranthigv.github.io/"
            ],
            [
                "Haowen Hou",
                "https://github.com/howard-hou"
            ],
            [
                "Przemyslaw Kazienko",
                "https://kazienko.eu/en"
            ],
            [
                "Jan Kocon",
                "https://github.com/KoconJan"
            ],
            [
                "Bartlomiej Koptyra",
                "https://github.com/bkoptyra"
            ],
            [
                "Ipsit Mantri",
                "https://ipsitmantri.github.io/"
            ],
            [
                "Ferdinand Mom",
                "https://3outeille.github.io/"
            ],
            [
                "Xiangru Tang",
                "https://github.com/tangxiangru"
            ],
            [
                "Johan Wind",
                "https://johanwind.github.io/"
            ],
            [
                "Stanisław Woźniak",
                "https://www.researchgate.net/profile/Stanislaw-Wozniak-3"
            ],
            [
                "Qihang Zhao",
                "https://www.researchgate.net/profile/Qihang-Zhao-2"
            ],
            [
                "Peng Zhou",
                "https://pengzhou.sites.ucsc.edu/"
            ],
            [
                "Jian Zhu",
                "https://lingjzhu.github.io/"
            ],
            [
                "Rui-Jie Zhu",
                "https://scholar.google.com/citations?user=08ITzJsAAAAJ"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/BlinkDL/ChatRWKV",
                9434
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2305.13048"
            ],
            [
                "hf",
                "https://huggingface.co/BlinkDL"
            ],
            [
                "website",
                "https://www.rwkv.com/"
            ],
            [
                "git",
                "https://github.com/saharNooby/rwkv.cpp"
            ],
            [
                "git",
                "https://github.com/harrisonvanderbyl/rwkv-cpp-cuda"
            ],
            [
                "git",
                "https://github.com/Blealtan/RWKV-LM-LoRA"
            ],
            [
                "git",
                "https://github.com/josStorer/RWKV-Runner"
            ],
            [
                "discord",
                "https://discord.gg/bDSBUMeFpc"
            ],
            [
                "twitter",
                "https://twitter.com/BlinkDL_AI"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/MachineLearning/comments/1135aew/r_rwkv4_14b_release_and_chatrwkv_a_surprisingly/"
            ],
            [
                "yt",
                "https://youtu.be/UeAD1qWNb1U"
            ]
        ],
        "colab": "https://colab.research.google.com/github/resloved/RWKV-notebooks/blob/master/RWKV_ChatRWKV.ipynb",
        "update": 1683512016.0
    },
    {
        "name": "Grounded-SAM",
        "description": "Marrying Grounding DINO with Segment Anything & Stable Diffusion & Recognize Anything - Automatically Detect, Segment and Generate Anything",
        "author": [
            [
                "IDEA-Research",
                "https://www.idea.edu.cn/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/IDEA-Research/Grounded-Segment-Anything",
                15310
            ],
            [
                "yt",
                "https://youtu.be/oEQYStnF2l8"
            ],
            [
                "git",
                "https://github.com/MasterBin-IIAU/UNINEXT"
            ],
            [
                "yt",
                "https://youtu.be/gKTYMfwPo4M"
            ],
            [
                "git",
                "https://github.com/IDEA-Research/OSX"
            ],
            [
                "git",
                "https://github.com/dvlab-research/VoxelNeXt"
            ],
            [
                "git",
                "https://github.com/UX-Decoder/Semantic-SAM"
            ],
            [
                "git",
                "https://github.com/UX-Decoder/Segment-Everything-Everywhere-All-At-Once"
            ],
            [
                "git",
                "https://github.com/IDEA-Research/OpenSeeD"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2304.02643"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2303.05499"
            ],
            [
                "git",
                "https://github.com/Computer-Vision-in-the-Wild/CVinW_Readings"
            ],
            [
                "git",
                "https://github.com/sail-sg/EditAnything"
            ],
            [
                "git",
                "https://github.com/feizc/IEA"
            ],
            [
                "git",
                "https://github.com/Li-Qingyun/sam-mmrotate"
            ],
            [
                "git",
                "https://github.com/VainF/Awesome-Anything"
            ],
            [
                "git",
                "https://github.com/RockeyCoss/Prompt-Segment-Anything"
            ],
            [
                "yt",
                "https://youtu.be/0Fpb8TBH0nM"
            ],
            [
                "yt",
                "https://youtu.be/GuEDDBWrN24"
            ]
        ],
        "colab": "https://colab.research.google.com/github/betogaona7/Grounded-Segment-Anything/blob/main/grounded_sam_colab_demo.ipynb",
        "update": 1681275438.0
    },
    {
        "name": "Gorilla",
        "description": "Finetuned LLaMA-based model that surpasses the performance of GPT-4 on writing API calls",
        "author": [
            [
                "Shishir Patil",
                "https://shishirpatil.github.io/"
            ],
            [
                "Tianjun Zhang",
                "https://github.com/tianjunz"
            ],
            [
                "Xin Wang",
                "https://xinw.ai/"
            ],
            [
                "Joseph Gonzalez",
                "https://people.eecs.berkeley.edu/~jegonzal/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/ShishirPatil/gorilla",
                11536
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2305.15334"
            ],
            [
                "project",
                "http://gorilla.cs.berkeley.edu/"
            ],
            [
                "discord",
                "https://discord.gg/SwTyuTAxX3"
            ],
            [
                "git",
                "https://github.com/gorilla-llm/gorilla-cli"
            ],
            [
                "yt",
                "https://youtu.be/4EdyWkcddPc"
            ],
            [
                "yt",
                "https://youtu.be/RMgM3tPTpXI"
            ],
            [
                "yt",
                "https://youtu.be/CX1Kzijq2TI"
            ],
            [
                "yt",
                "https://youtu.be/8AqQBPI4CFI"
            ],
            [
                "yt",
                "https://youtu.be/iQwYoii4YiI"
            ],
            [
                "yt",
                "https://youtu.be/alDArqcxSvw"
            ],
            [
                "yt",
                "https://youtu.be/EypdTAlmoo4"
            ],
            [
                "yt",
                "https://youtu.be/LkV5DTRNxAg"
            ],
            [
                "medium",
                "https://medium.com/latinxinai/try-gorilla-a-large-language-model-connected-with-massive-apis-442f3b554ffb"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1DEBPsccVLF_aUnmD0FwPeHFrtdC0QIUP",
        "update": 1712369447.967
    },
    {
        "name": "Open Interpreter",
        "description": "An open-source, locally running implementation of OpenAI's Code Interpreter",
        "author": [
            [
                "Killian Lucas",
                "https://github.com/KillianLucas"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/KillianLucas/open-interpreter",
                57260
            ],
            [
                "website",
                "https://openinterpreter.com/"
            ],
            [
                "discord",
                "https://discord.gg/6p3fD6rBVm"
            ],
            [
                "docs",
                "https://docs.openinterpreter.com/"
            ],
            [
                "yt",
                "https://youtu.be/SqnXUHwIa3c"
            ],
            [
                "yt",
                "https://youtu.be/s-f4lCETxu0"
            ],
            [
                "yt",
                "https://youtu.be/J-H2un1Adr0"
            ],
            [
                "yt",
                "https://youtu.be/jaijpff58vw"
            ],
            [
                "yt",
                "https://youtu.be/7KFbG_3dKKs"
            ],
            [
                "yt",
                "https://youtu.be/4OhuFjPyZNQ"
            ],
            [
                "yt",
                "https://youtu.be/01tQLn_RRcE"
            ],
            [
                "yt",
                "https://youtu.be/uyfoHQVgeY0"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1WKmRXZgsErej2xUriKzxrEAXdxMSgWbb",
        "update": 1704280094.272
    },
    {
        "name": "Compel",
        "description": "Text prompt weighting and blending library for transformers-type text embedding systems",
        "author": [
            [
                "Damian Stewart",
                "http://damianstewart.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/damian0815/compel",
                534
            ],
            [
                "hf",
                "https://huggingface.co/cactusfriend/nightmare-invokeai-prompts"
            ],
            [
                "git",
                "https://github.com/invoke-ai/InvokeAI/issues/2832"
            ]
        ],
        "colab": "https://colab.research.google.com/github/damian0815/compel/blob/main/compel-demo.ipynb",
        "update": 1674725751.0
    },
    {
        "name": "Mistral Transformer",
        "description": "The most powerful language model for its size to date",
        "author": [
            [
                "Albert Jiang",
                "https://albertqjiang.github.io/"
            ],
            [
                "Alexandre Sablayrolles",
                "https://github.com/alexandresablayrolles"
            ],
            [
                "Arthur Mensch",
                "https://github.com/arthurmensch"
            ],
            [
                "Chris Bamford",
                "https://griddly.ai/"
            ],
            [
                "Devendra Chaplot",
                "https://devendrachaplot.github.io/"
            ],
            [
                "Diego Casas",
                "https://github.com/diegolascasas"
            ],
            [
                "Florian Bressand",
                "https://www.linkedin.com/in/florianbressand"
            ],
            [
                "Gianna Lengyel",
                "https://www.linkedin.com/in/gianna-maria-lengyel"
            ],
            [
                "Guillaume Lample",
                "https://github.com/glample"
            ],
            [
                "Lucile Saulnier",
                "https://scholar.google.com/citations?user=Baj_9IsAAAAJ"
            ],
            [
                "Lélio Renard Lavaud",
                "https://github.com/lerela"
            ],
            [
                "Marie-Anne Lachaux",
                "https://scholar.google.com/citations?user=dSEMIJ8AAAAJ"
            ],
            [
                "Pierre Stock",
                "https://github.com/pierrestock"
            ],
            [
                "Teven Scao",
                "https://scholar.google.com/citations?user=ik0_vxsAAAAJ"
            ],
            [
                "Thibaut Lavril",
                "https://scholar.google.com/citations?user=9nPunCEAAAAJ"
            ],
            [
                "Thomas Wang",
                "https://github.com/thomasw21"
            ],
            [
                "Timothée Lacroix",
                "https://scholar.google.com/citations?&user=tZGS6dIAAAAJ"
            ],
            [
                "William Sayed",
                "https://www.linkedin.com/in/william-el-sayed-48672312a"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/mistralai/mistral-src",
                9778
            ],
            [
                "blog post",
                "https://mistral.ai/news/announcing-mistral-7b/"
            ],
            [
                "discord",
                "https://discord.com/invite/mistralai"
            ],
            [
                "docs",
                "https://docs.mistral.ai/"
            ],
            [
                "git",
                "https://github.com/vllm-project/vllm"
            ],
            [
                "git",
                "https://github.com/lm-sys/FastChat"
            ],
            [
                "git",
                "https://github.com/ggerganov/ggml"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2310.06825"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1904.10509"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2004.05150"
            ],
            [
                "hf",
                "https://huggingface.co/mistralai"
            ],
            [
                "git",
                "https://github.com/Dao-AILab/flash-attention"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2306.05685"
            ],
            [
                "git",
                "https://github.com/skypilot-org/skypilot"
            ],
            [
                "medium",
                "https://towardsdatascience.com/mistral-7b-recipes-for-fine-tuning-and-quantization-on-your-computer-631401583f77"
            ],
            [
                "yt",
                "https://youtu.be/g7kVVBlCGo0"
            ],
            [
                "yt",
                "https://youtu.be/ASpageg8nPw"
            ],
            [
                "yt",
                "https://youtu.be/OMIuP6lQXe4"
            ],
            [
                "yt",
                "https://youtu.be/jnPZApwtE4I"
            ],
            [
                "yt",
                "https://youtu.be/3SdopNwQJ-c"
            ]
        ],
        "colab": "https://colab.research.google.com/github/camenduru/Mistral-colab/blob/main/Mistral_colab.ipynb",
        "update": 1696859516.0
    },
    {
        "name": "Mistral Inference",
        "description": "Minimal code to run Mistral models",
        "author": [
            [
                "mistral",
                "https://mistral.ai/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/mistralai/mistral-inference",
                9778
            ],
            [
                "blog post",
                "https://mistral.ai/news/announcing-mistral-7b/"
            ],
            [
                "discord",
                "https://discord.com/invite/mistralai"
            ],
            [
                "docs",
                "https://docs.mistral.ai/"
            ],
            [
                "pypi",
                "https://pypi.org/project/mistral-inference/"
            ],
            [
                "medium",
                "https://medium.com/@parikshitsaikia1619/mistral-mastery-fine-tuning-fast-inference-guide-62e163198b06"
            ],
            [
                "yt",
                "https://youtu.be/mYRqvB1_gRk"
            ]
        ],
        "colab": "https://colab.research.google.com/github/mistralai/mistral-inference/blob/main/tutorials/getting_started.ipynb",
        "update": 1721124999.0
    },
    {
        "name": "threestudio",
        "description": "Unified framework for 3D content creation from text prompts, single images, and few-shot images, by lifting 2D text-to-image generation models",
        "author": [
            [
                "Yuan-Chen Guo",
                "https://github.com/bennyguo"
            ],
            [
                "Ying-Tian Liu",
                "https://github.com/thuliu-yt16"
            ],
            [
                "Ruizhi Shao",
                "https://github.com/DSaurus"
            ],
            [
                "Christian Laforte",
                "https://github.com/claforte"
            ],
            [
                "Vikram Voleti",
                "https://github.com/voletiv"
            ],
            [
                "Guan Luo",
                "https://github.com/logan0601"
            ],
            [
                "Chia-Hao Chen",
                "https://scholar.google.com/citations?user=X0zirvMAAAAJ"
            ],
            [
                "Zi-Xin Zou",
                "https://github.com/zouzx"
            ],
            [
                "Chen Wang",
                "https://cwchenwang.github.io/"
            ],
            [
                "Yanpei Cao",
                "https://yanpei.me/"
            ],
            [
                "Song-Hai Zhang",
                "https://scholar.google.com/citations?user=AWtV-EQAAAAJ"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/threestudio-project/threestudio",
                6376
            ],
            [
                "discord",
                "https://discord.gg/ejer2MAB8N"
            ],
            [
                "git",
                "https://github.com/DSaurus/Tensor4D"
            ],
            [
                "git",
                "https://github.com/eladrich/latent-nerf"
            ],
            [
                "git",
                "https://github.com/Gorilla-Lab-SCUT/Fantasia3D"
            ],
            [
                "git",
                "https://github.com/cvlab-columbia/zero123"
            ],
            [
                "git",
                "https://github.com/guochengqian/Magic123"
            ],
            [
                "git",
                "https://github.com/ayaanzhaque/instruct-nerf2nerf"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2303.15413"
            ],
            [
                "hf",
                "https://huggingface.co/DeepFloyd/IF-I-XL-v1.0"
            ],
            [
                "hf",
                "https://huggingface.co/docs/huggingface_hub/v0.14.1/guides/download#download-an-entire-repository"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2305.16213"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2211.10440"
            ],
            [
                "git",
                "https://github.com/KAIR-BAIR/nerfacc"
            ],
            [
                "git",
                "https://github.com/Lightning-AI/lightning"
            ],
            [
                "git",
                "https://github.com/ashawkey/fantasia3d.unofficial"
            ],
            [
                "yt",
                "https://youtu.be/gT8Xvx5b6IE"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/StableDiffusion/comments/1635cb0/threestudio_a_unified_framework_for_3d_content/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/threestudio-project/threestudio/blob/main/threestudio.ipynb",
        "update": 1690544217.0
    },
    {
        "name": "OmegaConf",
        "description": "Hierarchical configuration system, with support for merging configurations from multiple sources providing a consistent API regardless of how the configuration was created",
        "author": [
            [
                "Omry Yadan",
                "https://github.com/omry"
            ]
        ],
        "links": [
            [
                "docs",
                "https://omegaconf.readthedocs.io/"
            ],
            [
                "git",
                "https://github.com/omry/omegaconf",
                1992
            ],
            [
                "slides",
                "https://docs.google.com/presentation/d/e/2PACX-1vT_UIV7hCnquIbLUm4NnkUpXvPEh33IKiUEvPRF850WKA8opOlZOszjKdZ3tPmf8u7hGNP6HpqS-NT5/pub"
            ],
            [
                "medium",
                "https://majianglin2003.medium.com/python-omegaconf-a33be1b748ab"
            ]
        ],
        "colab": "https://colab.research.google.com/github/omry/omegaconf/blob/master/docs/notebook/Tutorial.ipynb",
        "update": 1708025079.0
    },
    {
        "name": "Autodistill",
        "description": "Uses big, slower foundation models to train small, faster supervised models",
        "author": [
            [
                "autodistill",
                "https://github.com/autodistill"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/autodistill/autodistill",
                2012
            ],
            [
                "docs",
                "https://docs.autodistill.com/"
            ],
            [
                "blog post",
                "https://blog.roboflow.com/autodistill/"
            ],
            [
                "yt",
                "https://youtu.be/gKTYMfwPo4M"
            ],
            [
                "git",
                "https://github.com/autodistill/autodistill-grounded-sam"
            ],
            [
                "git",
                "https://github.com/autodistill/autodistill-yolov8"
            ],
            [
                "git",
                "https://github.com/autodistill/autodistill-yolonas"
            ],
            [
                "git",
                "https://github.com/autodistill/autodistill-yolov5"
            ],
            [
                "git",
                "https://github.com/autodistill/autodistill-detr"
            ],
            [
                "git",
                "https://github.com/autodistill/autodistill-detic"
            ],
            [
                "git",
                "https://github.com/autodistill/autodistill-grounding-dino"
            ],
            [
                "git",
                "https://github.com/autodistill/autodistill-owl-vit"
            ],
            [
                "git",
                "https://github.com/autodistill/autodistill-sam-clip"
            ],
            [
                "git",
                "https://github.com/autodistill/autodistill-llava"
            ],
            [
                "git",
                "https://github.com/autodistill/autodistill-kosmos-2"
            ],
            [
                "git",
                "https://github.com/autodistill/autodistill-owlv2"
            ],
            [
                "git",
                "https://github.com/autodistill/autodistill-roboflow-universe"
            ],
            [
                "git",
                "https://github.com/autodistill/autodistill-azure-vision"
            ],
            [
                "git",
                "https://github.com/autodistill/autodistill-rekognition"
            ],
            [
                "git",
                "https://github.com/autodistill/autodistill-gcp-vision"
            ],
            [
                "yt",
                "https://youtu.be/M_QZ_Q0zT0k"
            ],
            [
                "yt",
                "https://youtube.com/roboflow"
            ],
            [
                "git",
                "https://github.com/roboflow/inference"
            ]
        ],
        "colab": "https://colab.research.google.com/github/roboflow-ai/notebooks/blob/main/notebooks/how-to-auto-train-yolov8-model-with-autodistill.ipynb",
        "update": 1730462044.0
    },
    {
        "name": "CodeGen",
        "description": "Family of open-source model for program synthesis",
        "author": [
            [
                "Erik Nijkamp",
                "https://eriknijkamp.com/"
            ],
            [
                "Bo Pang",
                "https://scholar.google.com/citations?user=s9fNEVEAAAAJ"
            ],
            [
                "Hiroaki Hayashi",
                "https://hiroakih.me/"
            ],
            [
                "Lifu Tu",
                "https://lifu-tu.github.io/"
            ],
            [
                "Huan Wang",
                "https://huan-december.github.io/"
            ],
            [
                "Yingbo Zhou",
                "https://scholar.google.com/citations?user=H_6RQ7oAAAAJ"
            ],
            [
                "Silvio Savarese",
                "https://cvgl.stanford.edu/silvio/"
            ],
            [
                "Caiming Xiong",
                "http://cmxiong.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/salesforce/CodeGen",
                4946
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2203.13474"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2305.02309"
            ],
            [
                "hf",
                "https://huggingface.co/models?search=salesforce+codegen"
            ],
            [
                "git",
                "https://github.com/salesforce/jaxformer"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1fQI8OgzMAR0bquCrvhlAtXSw6iMFbVgI",
        "update": 1650716560.036
    },
    {
        "name": "PaddleHub",
        "description": "Pre-trained models toolkit based on PaddlePaddle: 400+ models including Image, Text, Audio, Video and Cross-Modal with Easy Inference & Serving",
        "author": [
            [
                "Zeyu Chen",
                "https://github.com/ZeyuChen"
            ],
            [
                "Zewu Wu",
                "https://github.com/nepeplwu"
            ],
            [
                "Bin Long",
                "https://github.com/sjtubinlong"
            ],
            [
                "Xuefei Zhang",
                "https://github.com/Steffy-zxf"
            ],
            [
                "Jinxuan Qiu",
                "https://github.com/kinghuin"
            ],
            [
                "Yuhan Shen",
                "https://github.com/ShenYuhan"
            ],
            [
                "Yuying Hao",
                "https://github.com/haoyuying"
            ],
            [
                "Xiaojie Chen",
                "https://github.com/KPatr1ck"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/PaddlePaddle/PaddleHub",
                12752
            ],
            [
                "website",
                "https://www.paddlepaddle.org.cn/en"
            ],
            [
                "hf",
                "https://huggingface.co/PaddlePaddle"
            ],
            [
                "git",
                "https://github.com/PaddlePaddle/PaddleOCR"
            ],
            [
                "git",
                "https://github.com/PaddlePaddle/PaddleDetection"
            ],
            [
                "git",
                "https://github.com/PaddlePaddle/PaddleGAN"
            ],
            [
                "git",
                "https://github.com/CMU-Perceptual-Computing-Lab/openpose"
            ],
            [
                "git",
                "https://github.com/PaddlePaddle/PaddleSeg"
            ],
            [
                "git",
                "https://github.com/PaddlePaddle/PaddleClas"
            ],
            [
                "git",
                "https://github.com/PaddlePaddle/ERNIE"
            ],
            [
                "git",
                "https://github.com/baidu/LAC"
            ],
            [
                "git",
                "https://github.com/baidu/DDParser"
            ],
            [
                "git",
                "https://github.com/PaddlePaddle/PaddleSpeech"
            ],
            [
                "yt",
                "https://youtu.be/9adXuF_lTSg"
            ],
            [
                "docs",
                "https://paddlehub.readthedocs.io/en"
            ],
            [
                "medium",
                "https://medium.com/analytics-vidhya/paddlehub-fdd1ec75a07b"
            ]
        ],
        "colab": "https://colab.research.google.com/github/PaddlePaddle/PaddleHub/blob/develop/demo/serving/bentoml/cloud-native-model-serving-with-bentoml.ipynb",
        "update": 1618919803.0
    },
    {
        "name": "Intel® Extension for Transformers",
        "description": "Transformer-based Toolkit to Accelerate GenAI/LLM Everywhere",
        "author": [
            [
                "intel",
                "https://www.intel.com/content/www/us/en/developer/topic-technology/open/overview.html"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/intel/intel-extension-for-transformers",
                2141
            ],
            [
                "docs",
                "https://intel.github.io/intel-extension-for-transformers/latest/docs/Welcome.html"
            ],
            [
                "discord",
                "https://discord.gg/Wxk3J3ZJkU"
            ],
            [
                "medium",
                "https://medium.com/@NeuralCompressor/creating-your-own-llms-on-your-laptop-a08cc4f7c91b"
            ],
            [
                "hf",
                "https://huggingface.co/blog/assisted-generation"
            ],
            [
                "hf",
                "https://huggingface.co/Intel/neural-chat-7b-v3-1"
            ],
            [
                "yt",
                "https://youtu.be/bWhZ1u_1rlc"
            ],
            [
                "medium",
                "https://medium.com/@NeuralCompressor/the-practice-of-supervised-finetuning-and-direct-preference-optimization-on-habana-gaudi2-a1197d8a3cd3"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2309.17453"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2311.00502"
            ],
            [
                "git",
                "https://github.com/ggerganov/ggml"
            ],
            [
                "git",
                "https://github.com/ggerganov/llama.cpp"
            ],
            [
                "yt",
                "https://www.youtube.com/watch?v=RbKRELWP9y8&t=2954s"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2211.07715"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2210.17114"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2111.05754"
            ],
            [
                "medium",
                "https://medium.com/@NeuralCompressor/llm-performance-of-intel-extension-for-transformers-f7d061556176"
            ],
            [
                "hf",
                "https://huggingface.co/blog/Andyrasika/neural-chat-intel"
            ],
            [
                "yt",
                "https://youtu.be/7_urstS-noU"
            ],
            [
                "yt",
                "https://youtu.be/bWhZ1u_1rlc"
            ],
            [
                "yt",
                "https://youtu.be/KWT6yKfu4n0"
            ],
            [
                "medium",
                "https://medium.com/@NeuralCompressor/high-performance-low-bit-layer-wise-weight-only-quantization-on-a-laptop-712580899396"
            ],
            [
                "medium",
                "https://medium.com/intel-analytics-software/reduce-large-language-model-carbon-footprint-with-intel-neural-compressor-and-intel-extension-for-dfadec3af76a"
            ],
            [
                "git",
                "https://github.com/TimDettmers/bitsandbytes"
            ],
            [
                "git",
                "https://github.com/lm-sys/FastChat"
            ],
            [
                "git",
                "https://github.com/IntelLabs/fastRAG"
            ],
            [
                "git",
                "https://github.com/IST-DASLab/gptq"
            ],
            [
                "git",
                "https://github.com/mit-han-lab/streaming-llm"
            ]
        ],
        "colab": "https://colab.research.google.com/github/intel/intel-extension-for-transformers/blob/main/docs/tutorials/pytorch/text-classification/SetFit_model_compression_AGNews.ipynb",
        "update": 1710837461.0
    },
    {
        "name": "Intel® Neural Compressor",
        "description": "Aims to provide popular model compression techniques such as quantization, pruning (sparsity), distillation, and neural architecture search on mainstream frameworks such as TensorFlow, PyTorch, ONNX Runtime, and MXNet, as well as Intel extensions such as Intel Extension for TensorFlow and Intel Extension for PyTorch",
        "author": [
            [
                "intel",
                "https://www.intel.com/content/www/us/en/developer/topic-technology/open/overview.html"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/intel/neural-compressor",
                2243
            ],
            [
                "docs",
                "https://github.com/intel/neural-compressor"
            ],
            [
                "git",
                "https://github.com/intel/intel-extension-for-tensorflow"
            ],
            [
                "git",
                "https://github.com/intel/intel-extension-for-pytorch"
            ],
            [
                "pt",
                "https://pytorch.org/tutorials/recipes/intel_neural_compressor_for_pytorch.html"
            ],
            [
                "git",
                "https://github.com/Lightning-AI/pytorch-lightning/blob/master/docs/source-pytorch/advanced/post_training_quantization.rst"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2309.14592"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2309.05516"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2211.07715"
            ],
            [
                "neurips",
                "https://neurips.cc/virtual/2022/59433"
            ],
            [
                "discord",
                "https://discord.com/invite/Wxk3J3ZJkU"
            ],
            [
                "yt",
                "https://youtu.be/SswQbIHUrvQ"
            ],
            [
                "yt",
                "https://youtu.be/5xHKe4wWLes"
            ],
            [
                "yt",
                "https://youtu.be/H7Gg-EmGpAI"
            ],
            [
                "yt",
                "https://youtu.be/ie3w_j0Ntsk"
            ],
            [
                "yt",
                "https://youtu.be/m2LokuUdeVg"
            ],
            [
                "yt",
                "https://youtu.be/38wrDHEQZuM"
            ],
            [
                "medium",
                "https://medium.com/pytorch/pytorch-inference-acceleration-with-intel-neural-compressor-842ef4210d7d"
            ],
            [
                "medium",
                "https://medium.com/intel-analytics-software/efficient-text-classification-with-intel-neural-compressor-4853296deeac"
            ]
        ],
        "colab": "https://colab.research.google.com/github/intel/neural-compressor/blob/master/examples/notebook/onnxruntime/Quick_Started_Notebook_of_INC_for_ONNXRuntime.ipynb",
        "update": 1698375626.0
    },
    {
        "name": "Distil-Whisper",
        "description": "Maintains the robustness of the Whisper model to difficult acoustic conditions, while being less prone to hallucination errors on long-form audio",
        "author": [
            [
                "Sanchit Gandhi",
                "https://github.com/sanchit-gandhi"
            ],
            [
                "Patrick von Platen",
                "https://github.com/patrickvonplaten"
            ],
            [
                "Alexander Rush",
                "https://scholar.google.com/citations?&user=LIjnUGgAAAAJ"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/huggingface/distil-whisper",
                3638
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2311.00430"
            ],
            [
                "hf",
                "https://huggingface.co/collections/distil-whisper/training-datasets-6538d05c69721489d1db1e49"
            ],
            [
                "hf",
                "https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModelForSpeechSeq2Seq"
            ],
            [
                "hf",
                "https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoProcessor"
            ],
            [
                "git",
                "https://github.com/huggingface/safetensors"
            ],
            [
                "hf",
                "https://huggingface.co/docs/transformers/main_classes/pipelines#transformers.AutomaticSpeechRecognitionPipeline"
            ],
            [
                "hf",
                "https://huggingface.co/docs/transformers/v4.34.1/en/model_doc/whisper#transformers.WhisperForConditionalGeneration.forward.example"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2211.17192"
            ],
            [
                "hf",
                "https://huggingface.co/docs/transformers/main/en/main_classes/text_generation#transformers.GenerationMixin.generate.assistant_model"
            ],
            [
                "hf",
                "https://huggingface.co/docs/transformers/main/en/perf_infer_gpu_one#flashattention-2"
            ],
            [
                "git",
                "https://github.com/Dao-AILab/flash-attention"
            ],
            [
                "hf",
                "https://huggingface.co/docs/transformers/main/en/perf_infer_gpu_one#bettertransformer"
            ],
            [
                "yt",
                "https://youtu.be/46Q6fbdUCbg"
            ],
            [
                "yt",
                "https://youtu.be/SZtHEKyvuug"
            ],
            [
                "yt",
                "https://www.youtube.com/live/kI1pA1CADxM"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/MachineLearning/comments/17vqtcb/p_distilwhisper_a_distilled_variant_of_whisper/"
            ],
            [
                "medium",
                "https://medium.com/prompt-engineering/transcribing-audio-with-python-and-distil-whisper-9b4fec3d53bf"
            ]
        ],
        "colab": "https://colab.research.google.com/github/sanchit-gandhi/notebooks/blob/main/Distil_Whisper_Benchmark.ipynb",
        "update": 1699455542.0
    },
    {
        "name": "CleanVision",
        "description": "Automatically detects potential issues in image datasets like images that are: blurry, under/over-exposed, (near) duplicates, etc",
        "author": [
            [
                "cleanlab",
                "https://cleanlab.ai/about/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/cleanlab/cleanvision",
                1036
            ],
            [
                "slack",
                "https://cleanlab.ai/slack"
            ],
            [
                "docs",
                "https://cleanvision.readthedocs.io/"
            ],
            [
                "blog post",
                "https://cleanlab.ai/blog/cleanvision/"
            ],
            [
                "git",
                "https://github.com/cleanlab/cleanvision-examples"
            ],
            [
                "twitter",
                "https://twitter.com/CleanlabAI"
            ]
        ],
        "colab": "https://colab.research.google.com/github/cleanlab/cleanvision/blob/main/docs/source/tutorials/tutorial.ipynb",
        "update": 1707844407.0
    },
    {
        "name": "Cleanlab",
        "description": "Helps you clean data and labels by automatically detecting issues in a ML dataset",
        "author": [
            [
                "Curtis Northcutt",
                "https://www.curtisnorthcutt.com/"
            ],
            [
                "Lu Jiang",
                "http://www.lujiang.info/"
            ],
            [
                "Isaac Chuang",
                "http://feynman.mit.edu/ike/homepage/index.html"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/cleanlab/cleanlab",
                9799
            ],
            [
                "docs",
                "https://docs.cleanlab.ai/"
            ],
            [
                "slack",
                "https://cleanlab.ai/slack"
            ],
            [
                "twitter",
                "https://twitter.com/CleanlabAI"
            ],
            [
                "blog post",
                "https://l7.curtisnorthcutt.com/confident-learning"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1911.00068"
            ],
            [
                "doi",
                "https://doi.org/10.1613/jair.1.12125",
                303
            ],
            [
                "yt",
                "https://youtu.be/BnOTv0f9Msk"
            ],
            [
                "yt",
                "https://youtu.be/nGye-lrsLRc"
            ],
            [
                "yt",
                "https://youtu.be/QHaT_AiUljw"
            ],
            [
                "medium",
                "https://medium.com/@sujathamudadla1213/cleanlab-python-library-34e0a37720ef"
            ]
        ],
        "colab": "https://colab.research.google.com/github/cleanlab/cleanlab/blob/master/docs/source/tutorials/image.ipynb",
        "update": 1711762179.0
    },
    {
        "name": "DiffSynth",
        "description": "Restructured architectures including Text Encoder, UNet, VAE, among others, maintaining compatibility with models from the open-source community while enhancing computational performance",
        "author": [
            [
                "Artiprocher",
                "https://github.com/Artiprocher"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/Artiprocher/DiffSynth-Studio",
                6630
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2401.16224"
            ],
            [
                "hf",
                "https://huggingface.co/Helsinki-NLP/opus-mt-en-zh"
            ],
            [
                "hf",
                "https://huggingface.co/alibaba-pai/pai-bloom-1b1-text2prompt-sd"
            ]
        ],
        "colab": "https://colab.research.google.com/github/Artiprocher/DiffSynth-Studio/blob/main/examples/Diffutoon.ipynb",
        "update": 1717671007.0
    },
    {
        "name": "VC",
        "description": "Client software for performing real-time voice conversion using various Voice Conversion AI",
        "author": [
            [
                "w-okada",
                "https://github.com/w-okada"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/w-okada/voice-changer",
                16646
            ],
            [
                "git",
                "https://github.com/yxlllc/DDSP-SVC"
            ],
            [
                "hf",
                "https://huggingface.co/wok000/vcclient000"
            ],
            [
                "yt",
                "https://youtu.be/POo_Cg0eFMU"
            ],
            [
                "yt",
                "https://youtu.be/fba9Zhsukqw"
            ],
            [
                "yt",
                "https://youtu.be/s_GirFEGvaA"
            ],
            [
                "yt",
                "https://youtu.be/Q7bbEC4aeKM"
            ],
            [
                "yt",
                "https://youtu.be/_JXbvSTGPoo"
            ],
            [
                "yt",
                "https://youtu.be/pHhjg2JwdPI"
            ],
            [
                "yt",
                "https://youtu.be/We5oYpCR3WQ"
            ],
            [
                "yt",
                "https://youtu.be/aVfoC1EHlVs"
            ],
            [
                "yt",
                "https://youtu.be/YF1lBaqeyt8"
            ]
        ],
        "colab": "https://colab.research.google.com/github/hinabl/voice-changer-colab/blob/master/Hina_Modified_Realtime_Voice_Changer_on_Colab.ipynb",
        "update": 1732073834.0
    },
    {
        "name": "Retrieval based Voice Conversion WebUI",
        "description": "An easy-to-use Voice Conversion framework based on VITS",
        "author": [
            [
                "RVC-Project",
                "https://github.com/RVC-Project"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI",
                24973
            ],
            [
                "discord",
                "https://discord.gg/HcsmBBGyVk"
            ],
            [
                "hf",
                "https://huggingface.co/lj1995/VoiceConversionWebUI"
            ],
            [
                "git",
                "https://github.com/auspicious3000/contentvec"
            ],
            [
                "git",
                "https://github.com/jik876/hifi-gan"
            ],
            [
                "git",
                "https://github.com/FFmpeg/FFmpeg"
            ],
            [
                "git",
                "https://github.com/Anjok07/ultimatevocalremovergui"
            ],
            [
                "git",
                "https://github.com/openvpi/audio-slicer"
            ],
            [
                "git",
                "https://github.com/Dream-High/RMVPE"
            ],
            [
                "yt",
                "https://youtu.be/-JcvdDErkAU"
            ],
            [
                "yt",
                "https://youtu.be/9TroP5mR3CM"
            ],
            [
                "yt",
                "https://youtu.be/Y8IxVVQBEpc"
            ],
            [
                "yt",
                "https://youtu.be/qZ12-Vm2ryc"
            ],
            [
                "yt",
                "https://youtu.be/5i_Pyw0gH-M"
            ],
            [
                "medium",
                "https://medium.com/@ja.harr91/decoding-the-sound-of-virality-a-deep-dive-into-adversarial-ai-for-voice-conversion-tasks-on-m1-d60d32cfb2d4"
            ]
        ],
        "colab": "https://colab.research.google.com/github/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/blob/main/Retrieval_based_Voice_Conversion_WebUI.ipynb",
        "update": 1704980434.0
    },
    {
        "name": "DynamiCrafter",
        "description": "Animating Open-domain Images with Video Diffusion Priors",
        "author": [
            [
                "Jinbo Xing",
                "https://doubiiu.github.io/"
            ],
            [
                "Menghan Xia",
                "https://menghanxia.github.io/"
            ],
            [
                "Yong Zhang",
                "https://yzhang2016.github.io/"
            ],
            [
                "Haoxin Chen",
                "https://scutpaul.github.io/"
            ],
            [
                "Wangbo Yu",
                "https://github.com/GooDrYu"
            ],
            [
                "Hanyuan Liu",
                "https://github.com/hyliu"
            ],
            [
                "Xintao Wang",
                "https://xinntao.github.io/"
            ],
            [
                "Tien-Tsin Wong",
                "https://ttwong12.github.io/myself.html"
            ],
            [
                "Ying Shan",
                "https://scholar.google.com/citations?user=4oXBp9UAAAAJ"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/Doubiiu/DynamiCrafter",
                2645
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2310.12190"
            ],
            [
                "project",
                "https://doubiiu.github.io/projects/DynamiCrafter/"
            ],
            [
                "yt",
                "https://youtu.be/0NfmIsNAg-g"
            ],
            [
                "yt",
                "https://youtu.be/PtW7hjCawbo"
            ],
            [
                "hf",
                "https://huggingface.co/Doubiiu/DynamiCrafter_1024"
            ],
            [
                "twitter",
                "https://x.com/noguchis/status/1754488826016432341?s=20"
            ],
            [
                "git",
                "https://github.com/chaojie/ComfyUI-DynamiCrafter"
            ],
            [
                "git",
                "https://github.com/AILab-CVC/VideoCrafter"
            ],
            [
                "git",
                "https://github.com/YingqingHe/ScaleCrafter"
            ],
            [
                "git",
                "https://github.com/AILab-CVC/TaleCrafter"
            ],
            [
                "git",
                "https://github.com/AILab-CVC/FreeNoise"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/StableDiffusion/comments/1aj7gcw/dynamicrafter_gets_updated/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/camenduru/DynamiCrafter-colab/blob/main/DynamiCrafter_colab_576_1024.ipynb",
        "update": 1707727725.0
    },
    {
        "name": "ToonCrafter",
        "description": "Can interpolate two cartoon images by leveraging the pre-trained image-to-video diffusion priors",
        "author": [
            [
                "Jinbo Xing",
                "https://doubiiu.github.io/"
            ],
            [
                "Hanyuan Liu",
                "https://github.com/hyliu"
            ],
            [
                "Menghan Xia",
                "https://menghanxia.github.io/"
            ],
            [
                "Yong Zhang",
                "https://yzhang2016.github.io/"
            ],
            [
                "Xintao Wang",
                "https://xinntao.github.io/"
            ],
            [
                "Ying Shan",
                "https://scholar.google.com/citations?user=4oXBp9UAAAAJ"
            ],
            [
                "Tien-Tsin Wong",
                "https://ttwong12.github.io/myself.html"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/ToonCrafter/ToonCrafter",
                5407
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2405.17933v1"
            ],
            [
                "project",
                "https://doubiiu.github.io/projects/ToonCrafter/"
            ],
            [
                "yt",
                "https://youtu.be/u3F35do93_8"
            ],
            [
                "yt",
                "https://youtu.be/E89R5_hQ5bQ"
            ],
            [
                "yt",
                "https://youtu.be/kK-A9jOaO1U"
            ],
            [
                "yt",
                "https://youtu.be/ricylysRayw"
            ],
            [
                "yt",
                "https://youtu.be/hc5nF6rGa68"
            ],
            [
                "yt",
                "https://youtu.be/mEn3CYU7s_A"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/StableDiffusion/comments/1d470rv/tooncrafter_generative_cartoon_interpolation/"
            ]
        ],
        "colab": "https://colab.research.google.com/gist/0smboy/baef995b8f5974f19ac114ec20ac37d5/tooncrafter.ipynb",
        "update": 1718883526.0
    },
    {
        "name": "MetaVoice",
        "description": "1.2B parameter base model trained on 100K hours of speech for TTS",
        "author": [
            [
                "MetaVoice",
                "https://themetavoice.xyz/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/metavoiceio/metavoice-src",
                3922
            ],
            [
                "demo",
                "https://ttsdemo.themetavoice.xyz/"
            ],
            [
                "hf",
                "https://huggingface.co/metavoiceio"
            ],
            [
                "yt",
                "https://youtu.be/Y_k3bHPcPTo"
            ],
            [
                "yt",
                "https://youtu.be/gVKbf31hrYs"
            ],
            [
                "twitter",
                "https://twitter.com/MetaVoiceAI"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1UmjE1mzfG4td0rCjJEaAWGQXpn_GuwwY",
        "update": 1708984800.824
    },
    {
        "name": "colab2pdf",
        "description": "Convert your Colab notebook to a PDF",
        "author": [
            [
                "Drengskapur",
                "https://github.com/drengskapur"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/drengskapur/colab2pdf",
                27
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1zqrIYC0iQ_CZkRqGXgZggrwjtt_4BmpL",
        "update": 1702268826.471
    },
    {
        "name": "VideoGPT",
        "description": "A conceptually simple architecture for scaling likelihood based generative modeling to natural videos",
        "author": [
            [
                "Wilson Yan",
                "https://wilson1yan.github.io/"
            ],
            [
                "Yunzhi Zhang",
                "https://zzyunzhi.github.io/"
            ],
            [
                "Pieter Abbeel",
                "https://people.eecs.berkeley.edu/~pabbeel/"
            ],
            [
                "Aravind Srinivas",
                "https://people.eecs.berkeley.edu/~aravind/"
            ]
        ],
        "links": [
            [
                "project",
                "https://wilson1yan.github.io/videogpt/index.html"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2104.10157"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1904.10509"
            ],
            [
                "data",
                "https://www.crcv.ucf.edu/data/UCF101.php"
            ],
            [
                "git",
                "https://github.com/wilson1yan/VideoGPT",
                987
            ],
            [
                "hf",
                "https://huggingface.co/spaces/akhaliq/VideoGPT"
            ]
        ],
        "colab": "https://colab.research.google.com/github/wilson1yan/VideoGPT/blob/master/notebooks/Using_VideoGPT.ipynb",
        "update": 1646244527.0
    },
    {
        "name": "DALL·E Mini",
        "description": "Generate images from a text prompt",
        "author": [
            [
                "Boris Dayma",
                "https://github.com/borisdayma"
            ],
            [
                "Suraj Patil",
                "https://github.com/patil-suraj"
            ],
            [
                "Pedro Cuenca",
                "https://github.com/pcuenca"
            ],
            [
                "Khalid Saifullah",
                "https://khalidsaifullaah.github.io/"
            ],
            [
                "Tanishq Abraham",
                "https://github.com/tmabraham"
            ],
            [
                "Phúc H. Lê Khắc",
                "https://lkhphuc.com/"
            ],
            [
                "Luke Melas",
                "https://lukemelas.github.io/"
            ],
            [
                "Ritobrata Ghosh",
                "https://ghosh-r.github.io/"
            ]
        ],
        "links": [
            [
                "blog post",
                "https://wandb.ai/dalle-mini/dalle-mini/reports/DALL-E-mini--Vmlldzo4NjIxODA"
            ],
            [
                "hf",
                "https://huggingface.co/spaces/flax-community/dalle-mini"
            ],
            [
                "git",
                "https://github.com/borisdayma/dalle-mini",
                14754
            ],
            [
                "git",
                "https://github.com/huggingface/transformers/tree/master/examples/research_projects/jax-projects"
            ],
            [
                "git",
                "https://github.com/openai/CLIP/blob/main/data/yfcc100m.md"
            ],
            [
                "data",
                "https://aclanthology.org/P18-1238/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2102.08981"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2012.09841"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1910.13461"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2103.00020"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2012.09841"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1807.04015"
            ]
        ],
        "colab": "https://colab.research.google.com/github/borisdayma/dalle-mini/blob/main/tools/inference/inference_pipeline.ipynb",
        "update": 1692677188.0
    },
    {
        "name": "ruDALL·E",
        "description": "Generate images from texts in Russian",
        "author": [
            [
                "Alex Shonenkov",
                "https://github.com/shonenkov"
            ]
        ],
        "links": [
            [
                "project",
                "https://rudalle.ru/"
            ],
            [
                "git",
                "https://github.com/ai-forever/ru-dalle",
                1644
            ],
            [
                "git",
                "https://github.com/bes-dev/vqvae_dwt_distiller.pytorch"
            ],
            [
                "git",
                "https://github.com/boomb0om/Real-ESRGAN-colab"
            ],
            [
                "hf",
                "https://huggingface.co/spaces/multimodalart/rudalle"
            ]
        ],
        "colab": "https://colab.research.google.com/github/ai-forever/ru-dalle/blob/master/jupyters/ruDALLE-example-generation-A100.ipynb",
        "update": 1635957286.0
    },
    {
        "name": "Music Composer",
        "description": "Synthesizing symbolic music in MIDI format using the Music Transformer model",
        "author": [
            [
                "bazanovvanya",
                "https://github.com/bazanovvanya"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/ai-forever/music-composer",
                69
            ],
            [
                "git",
                "https://github.com/gwinndr/MusicTransformer-Pytorch"
            ],
            [
                "git",
                "https://github.com/bytedance/GiantMIDI-Piano"
            ],
            [
                "git",
                "https://github.com/mdeff/fma"
            ],
            [
                "data",
                "https://magenta.tensorflow.org/datasets/maestro"
            ],
            [
                "data",
                "https://colinraffel.com//projects/lmd/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1909.05858"
            ],
            [
                "blog post",
                "https://habr.com/ru/company/sberbank/blog/583592/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/ai-forever/music-composer/blob/master/src/Music_Composer_Demo_Colab_en.ipynb",
        "update": 1639994420.0
    },
    {
        "name": "Kandinsky 2.1",
        "description": "As text and image encoder it uses CLIP model and diffusion image prior between latent spaces of CLIP modalities",
        "author": [
            [
                "Arseniy Shakhmatov",
                "https://github.com/cene555"
            ],
            [
                "Anton Razzhigaev",
                "https://github.com/razzant"
            ],
            [
                "Aleksandr Nikolich",
                "https://github.com/AlexWortega"
            ],
            [
                "Vladimir Arkhipkin",
                "https://github.com/oriBetelgeuse"
            ],
            [
                "Igor Pavlov",
                "https://github.com/boomb0om"
            ],
            [
                "Andrey Kuznetsov",
                "https://github.com/kuznetsoffandrey"
            ],
            [
                "Denis Dimitrov",
                "https://github.com/denndimitrov"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/ai-forever/Kandinsky-2",
                2772
            ],
            [
                "blog post",
                "https://habr.com/ru/companies/sberbank/articles/725282/"
            ],
            [
                "demo",
                "https://editor.fusionbrain.ai/"
            ],
            [
                "hf",
                "https://huggingface.co/sberbank-ai/Kandinsky_2.1"
            ],
            [
                "yt",
                "https://youtu.be/LZvp4SWcCao"
            ],
            [
                "yt",
                "https://youtu.be/IoPhRE37XSU"
            ],
            [
                "yt",
                "https://youtu.be/dYt9xJ7dnpU"
            ],
            [
                "yt",
                "https://youtu.be/rN2J5TL2RZ0"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1xSbu-b-EwYd6GdaFPRVgvXBX_mciZ41e",
        "update": 1691397129.987
    },
    {
        "name": "Supervision",
        "description": "Reusable computer vision tools",
        "author": [
            [
                "Roboflow",
                "https://roboflow.com/about"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/roboflow/supervision",
                24377
            ],
            [
                "website",
                "https://supervision.roboflow.com/"
            ],
            [
                "discord",
                "https://discord.gg/GbfgXGJ8Bk"
            ],
            [
                "git",
                "https://github.com/roboflow/notebooks"
            ],
            [
                "docs",
                "https://github.com/roboflow/inference"
            ],
            [
                "yt",
                "https://youtu.be/uWP6UjDeZvY"
            ],
            [
                "yt",
                "https://youtu.be/4Q3ut7vqD5o"
            ],
            [
                "yt",
                "https://youtube.com/roboflow"
            ],
            [
                "docs",
                "https://docs.roboflow.com/"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/code/leoroboflow/inferring-on-a-dataset-with-a-roboflow-model"
            ],
            [
                "hf",
                "https://huggingface.co/spaces/Roboflow/Annotators"
            ]
        ],
        "colab": "https://colab.research.google.com/github/roboflow/supervision/blob/main/demo.ipynb",
        "update": 1726731330.0
    },
    {
        "name": "Multimodal Maestro",
        "description": "Gives you more control over large multimodal models to get the outputs you want",
        "author": [
            [
                "Roboflow",
                "https://roboflow.com/about"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/roboflow/multimodal-maestro",
                1407
            ],
            [
                "website",
                "https://maestro.roboflow.com/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2310.11441"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2309.17421"
            ],
            [
                "blog post",
                "https://blog.roboflow.com/multimodal-maestro-advanced-lmm-prompting/"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/computervision/comments/186o2b2/multimodal_maestro_prompt_tools_for_use_with_lmms/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/roboflow/multimodal-maestro/blob/develop/cookbooks/multimodal_maestro_gpt_4_vision.ipynb",
        "update": 1727359204.0
    },
    {
        "name": "Bullet Physics SDK",
        "description": "Real-time collision detection and multi-physics simulation for VR, games, visual effects, robotics, machine learning etc",
        "author": [
            [
                "Erwin Coumans",
                "https://github.com/erwincoumans"
            ],
            [
                "Yunfei Bai",
                "https://github.com/YunfeiBai"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/bulletphysics/bullet3",
                12741
            ],
            [
                "website",
                "https://pybullet.org"
            ],
            [
                "docs",
                "https://docs.google.com/document/d/10sXEhzFRSnvFcl3XxNGhnD4N2SedqwdAvK3dsihxVUA/edit#heading=h.2ye70wns7io3"
            ],
            [
                "git",
                "https://github.com/Microsoft/vcpkg"
            ],
            [
                "yt",
                "https://www.youtube.com/playlist?list=PLinBNdD-7nkNCfoEKap4z3qadLVj8QB4a"
            ],
            [
                "yt",
                "https://youtu.be/9p0O941opGc"
            ],
            [
                "yt",
                "https://youtu.be/kZxPaGdoSJY"
            ],
            [
                "yt",
                "https://www.youtube.com/playlist?list=PL9LUFPiB6N3YrS0O7XM_1sBVWRnSRB643"
            ]
        ],
        "colab": "https://colab.research.google.com/github/bulletphysics/bullet3/blob/master/examples/pybullet/notebooks/HelloPyBullet.ipynb",
        "update": 1602628473.0
    },
    {
        "name": "panda-gym",
        "description": "Set of robotic environments based on PyBullet physics engine and gymnasium",
        "author": [
            [
                "Quentin Gallouédec",
                "https://gallouedec.com/"
            ],
            [
                "Nicolas Cazin",
                "https://github.com/NicolasCAZIN"
            ],
            [
                "Emmanuel Dellandréa",
                "http://perso.ec-lyon.fr/emmanuel.dellandrea/"
            ],
            [
                "Liming Chen",
                "https://sites.google.com/view/limingchen/accueil"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/qgallouedec/panda-gym",
                584
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2106.13687"
            ],
            [
                "pypi",
                "https://pypi.org/project/panda-gym/"
            ],
            [
                "docs",
                "https://panda-gym.readthedocs.io/en/latest/"
            ],
            [
                "yt",
                "https://youtu.be/BgvpoSP45hA"
            ]
        ],
        "colab": "https://colab.research.google.com/github/qgallouedec/panda-gym/blob/master/examples/PickAndPlace.ipynb",
        "update": 1672673935.0
    },
    {
        "name": "FiftyOne",
        "description": "Open-source tool for building high-quality datasets and computer vision models",
        "author": [
            [
                "Brian Moore",
                "https://github.com/brimoor"
            ],
            [
                "Jason Corso",
                "https://web.eecs.umich.edu/~jjcorso/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/voxel51/fiftyone",
                8933
            ],
            [
                "website",
                "https://voxel51.com/fiftyone/"
            ],
            [
                "docs",
                "https://docs.voxel51.com/"
            ],
            [
                "blog post",
                "https://voxel51.com/blog/"
            ],
            [
                "slack",
                "https://slack.voxel51.com/"
            ],
            [
                "medium",
                "https://medium.com/voxel51"
            ],
            [
                "twitter",
                "https://twitter.com/voxel51"
            ],
            [
                "git",
                "https://github.com/voxel51/fiftyone-examples"
            ],
            [
                "yt",
                "https://www.youtube.com/playlist?list=PLuREAXoPgT0SJLKsgFzKxffMApbXp90Gi"
            ],
            [
                "medium",
                "https://towardsdatascience.com/open-source-tools-for-fast-computer-vision-model-building-b39755aab490"
            ]
        ],
        "colab": "https://colab.research.google.com/github/voxel51/fiftyone-examples/blob/master/examples/quickstart.ipynb",
        "update": 1709044862.0
    },
    {
        "name": "Gazelle",
        "description": "Joint Speech Language Model",
        "author": [
            [
                "Tincans",
                "https://tincans.ai"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/tincans-ai/gazelle",
                356
            ],
            [
                "blog post",
                "https://tincans.ai/slm"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Spike_/(software_development)"
            ],
            [
                "discord",
                "https://discord.gg/qyC5h3FSzU"
            ],
            [
                "hf",
                "https://huggingface.co/tincans-ai/gazelle-v0.1"
            ],
            [
                "hf",
                "https://huggingface.co/tincans-ai/gazelle-v0.2"
            ],
            [
                "hf",
                "https://huggingface.co/tincans-ai/gazelle-v0.2-dpo"
            ],
            [
                "hf",
                "https://huggingface.co/facebook/wav2vec2-base-960h"
            ],
            [
                "hf",
                "https://huggingface.co/meta-llama/Llama-2-7b-chat"
            ],
            [
                "git",
                "https://www.reddit.com/r/LocalLLaMA/comments/1cr84gb/joint_speechlanguage_model_respond_directly_to/"
            ],
            [
                "demo",
                "https://demo.tincans.ai/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/tincans-ai/gazelle/blob/master/examples/infer_quantized.ipynb",
        "update": 1710943817.0
    },
    {
        "name": "IC-Light",
        "description": "Manipulate the illumination of images",
        "author": [
            [
                "Lvmin Zhang",
                "https://github.com/lllyasviel"
            ],
            [
                "Anyi Rao",
                "https://anyirao.com/"
            ],
            [
                "Maneesh Agrawala",
                "https://graphics.stanford.edu/~maneesh/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/lllyasviel/IC-Light",
                6605
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2312.06886"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2402.18848"
            ],
            [
                "yt",
                "https://youtu.be/U_ZIkFb9P8w"
            ],
            [
                "yt",
                "https://youtu.be/3EsJrdXGnpo"
            ],
            [
                "yt",
                "https://youtu.be/BuSsw8Nv1N4"
            ]
        ],
        "colab": "https://colab.research.google.com/github/camenduru/IC-Light-jupyter/blob/main/IC_Light_jupyter.ipynb",
        "update": 1715221388.0
    },
    {
        "name": "Instructor",
        "description": "Library that makes it a breeze to work with structured outputs from large language models",
        "author": [
            [
                "Jason Liu",
                "https://jxnl.co/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/jxnl/instructor",
                8428
            ],
            [
                "docs",
                "https://python.useinstructor.com/"
            ],
            [
                "discord",
                "https://discord.gg/CV8sPM5k5Y"
            ],
            [
                "twitter",
                "https://twitter.com/jxnlco"
            ],
            [
                "yt",
                "https://youtu.be/rDP44EVpHTA"
            ],
            [
                "yt",
                "https://youtu.be/dq1Sjb8IGow"
            ],
            [
                "yt",
                "https://youtu.be/higlHgYDc5E"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1iBkrEh2G5U8yh8RmI8EkWxjLq6zIIuVm",
        "update": 1710342725.811
    },
    {
        "name": "Kor",
        "description": "Half-baked prototype that \"helps\" you extract structured data from text using LLMs",
        "author": [
            [
                "Eugene Yurtsev",
                "https://eyurtsev.github.io/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/eyurtsev/kor",
                1640
            ],
            [
                "docs",
                "https://eyurtsev.github.io/kor/"
            ],
            [
                "discord",
                "https://discord.com/channels/1038097195422978059/1170024642245832774"
            ]
        ],
        "colab": "https://colab.research.google.com/github/eyurtsev/kor/blob/main/docs/source/guidelines.ipynb",
        "update": 1721444386.0
    },
    {
        "name": "MARS5",
        "description": "Speech model for insane prosody",
        "author": [
            [
                "CAMB.AI",
                "https://www.camb.ai/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/Camb-ai/MARS5-TTS",
                2544
            ],
            [
                "discord",
                "https://discord.gg/FFQNCSKSXX"
            ],
            [
                "hf",
                "https://huggingface.co/CAMB-AI/MARS5-TTS"
            ],
            [
                "yt",
                "https://youtu.be/bmJSLPYrKtE"
            ],
            [
                "demo",
                "https://6b1a3a8e53ae.ngrok.app/"
            ],
            [
                "docker",
                "https://hub.docker.com/r/cambai/mars5ttsimage"
            ],
            [
                "docs",
                "https://docs.camb.ai/"
            ],
            [
                "git",
                "https://github.com/RF5/transfusion-asr"
            ],
            [
                "git",
                "https://github.com/ehoogeboom/multinomial_diffusion"
            ],
            [
                "git",
                "https://github.com/karpathy/minbpe"
            ]
        ],
        "colab": "https://colab.research.google.com/github/Camb-ai/mars5-tts/blob/master/mars5_demo.ipynb",
        "update": 1719303952.0
    },
    {
        "name": "MagicTime",
        "description": "Metamorphic time-lapse video generation model, which learns real-world physics knowledge from time-lapse videos and implements metamorphic generation",
        "author": [
            [
                "Shenghai Yuan",
                "https://shyuanbest.github.io/"
            ],
            [
                "Jinfa Huang",
                "https://infaaa.github.io/"
            ],
            [
                "Yujun Shi",
                "https://yujun-shi.github.io/"
            ],
            [
                "Yongqi Xu",
                "https://cheliosoops.github.io/YongqiXu.io/"
            ],
            [
                "Ruijie Zhu",
                "https://ruijie-zhu.github.io/"
            ],
            [
                "Bin Lin",
                "https://github.com/LinB203"
            ],
            [
                "Xinhua Cheng",
                "https://cxh0519.github.io/"
            ],
            [
                "Li Yuan",
                "https://yuanli2333.github.io/"
            ],
            [
                "Jiebo Luo",
                "https://www.cs.rochester.edu/u/jluo/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/PKU-YuanGroup/MagicTime",
                1310
            ],
            [
                "project",
                "https://pku-yuangroup.github.io/MagicTime/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2404.05014"
            ],
            [
                "hf",
                "https://huggingface.co/spaces/BestWishYsh/MagicTime?logs=build"
            ],
            [
                "twitter",
                "https://x.com/_akhaliq/status/1777538468043792473"
            ],
            [
                "twitter",
                "https://twitter.com/vhjf36495872/status/1777525817087553827?s=61&t=r2HzCsU2AnJKbR8yKSprKw"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2406.18522"
            ],
            [
                "git",
                "https://github.com/PKU-YuanGroup/ChronoMagic-Bench"
            ],
            [
                "git",
                "https://github.com/kijai/ComfyUI-MagicTimeWrapper"
            ],
            [
                "hf",
                "https://huggingface.co/datasets/BestWishYsh/ChronoMagic"
            ],
            [
                "git",
                "https://github.com/xuduo35/MakeLongVideo"
            ],
            [
                "hf",
                "https://huggingface.co/cerspense/zeroscope_v2_576w"
            ],
            [
                "git",
                "https://github.com/Vchitect/LaVie"
            ],
            [
                "git",
                "https://github.com/Vchitect/Latte"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/StableDiffusion/comments/1c1rv7q/magictime_demo_timelapse_video_generation_models/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/camenduru/MagicTime-jupyter/blob/main/MagicTime_jupyter.ipynb",
        "update": 1713097806.0
    },
    {
        "name": "Open-Sora Plan",
        "description": "Simple and efficient design along with remarkable performance in text-to-video generation",
        "author": [
            [
                "YUAN Lab at PKU",
                "https://github.com/PKU-YuanGroup"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/PKU-YuanGroup/Open-Sora-Plan",
                11645
            ],
            [
                "discord",
                "https://discord.gg/YtsBNg7n"
            ],
            [
                "hf",
                "https://huggingface.co/spaces/LanguageBind/Open-Sora-Plan-v1.1.0"
            ],
            [
                "git",
                "https://github.com/PKU-YuanGroup/Open-Sora-Dataset"
            ],
            [
                "hf",
                "https://huggingface.co/datasets/LanguageBind/Open-Sora-Plan-v1.0.0"
            ],
            [
                "git",
                "https://github.com/Vchitect/Latte"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2306.15595"
            ],
            [
                "git",
                "https://github.com/whlzy/FiT"
            ],
            [
                "yt",
                "https://youtu.be/cRUz3c7hRs4"
            ],
            [
                "yt",
                "https://youtu.be/mYnRwR0RyvE"
            ]
        ],
        "colab": "https://colab.research.google.com/github/camenduru/Open-Sora-Plan-jupyter/blob/main/Open_Sora_Plan_jupyter.ipynb",
        "update": 1712497276.0
    },
    {
        "name": "Vocos",
        "description": "Closing the gap between time-domain and Fourier-based neural vocoders for high-quality audio synthesis",
        "author": [
            [
                "Hubert Siuzdak",
                "https://github.com/hubertsiuzdak"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/gemelo-ai/vocos",
                834
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2306.00814"
            ],
            [
                "project",
                "https://gemelo-ai.github.io/vocos/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/charactr-platform/vocos/blob/main/notebooks/Bark%2BVocos.ipynb",
        "update": 1700573919.0
    },
    {
        "name": "Llama3 from scratch",
        "description": "Llama3 from scratch, one tensor and matrix multiplication at a time",
        "author": [
            [
                "Nishant Aklecha",
                "https://www.naklecha.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/naklecha/llama3-from-scratch",
                13835
            ],
            [
                "git",
                "https://github.com/karpathy/minbpe"
            ],
            [
                "yt",
                "https://youtu.be/o29P0Kpobz0?t=530"
            ],
            [
                "twitter",
                "https://twitter.com/naklecha"
            ],
            [
                "twitter",
                "https://twitter.com/aaaaaaaaaaorg"
            ]
        ],
        "colab": "https://colab.research.google.com/github/naklecha/llama3-from-scratch/blob/main/llama3-from-scratch.ipynb",
        "update": 1716135922.0
    },
    {
        "name": "NotebookLlama",
        "description": "Open Source version of NotebookLM",
        "author": [
            [
                "Meta",
                "https://www.llama.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/meta-llama/llama-recipes/tree/main/recipes/quickstart/NotebookLlama",
                15471
            ],
            [
                "medium",
                "https://medium.com/ai-disruption/meta-launches-open-source-version-notebookllama-rivals-googles-popular-notebooklm-9a41edd99c24"
            ],
            [
                "meidum",
                "https://medium.com/ai-artistry/notebook-llama-an-open-source-guide-to-building-a-pdf-to-podcast-workflow-e8fceec888a9"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/OpenSourceeAI/comments/1gdsmax/meta_ai_silently_releases_notebookllama_an_open/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/meta-llama/llama-recipes/blob/main/recipes/quickstart/NotebookLlama/Step-1%20PDF-Pre-Processing-Logic.ipynb",
        "update": 1730219560.0
    },
    {
        "name": "Llama 3.1",
        "description": "First openly available model that rivals the top AI models when it comes to state-of-the-art capabilities in general knowledge, steerability, math, tool use, and multilingual translation",
        "author": [
            [
                "unsloth",
                "https://unsloth.ai/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/unslothai/unsloth",
                18837
            ],
            [
                "discord",
                "https://discord.gg/unsloth"
            ],
            [
                "meta",
                "https://ai.meta.com/blog/meta-llama-3-1/"
            ],
            [
                "meta",
                "https://llama.meta.com/"
            ],
            [
                "hf",
                "https://huggingface.co/meta-llama"
            ],
            [
                "yt",
                "https://youtu.be/QyRWqJehK7I"
            ],
            [
                "yt",
                "https://youtu.be/1xdneyn6zjw"
            ],
            [
                "yt",
                "https://youtu.be/p5O-_AiKD_Q"
            ],
            [
                "yt",
                "https://youtu.be/4rk9fHIOGTU"
            ],
            [
                "blog post",
                "https://unsloth.ai/blog/llama3-1"
            ],
            [
                "twitter",
                "https://twitter.com/unslothai"
            ],
            [
                "meta",
                "https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/danielhanchen/kaggle-llama-3-1-8b-unsloth-notebook"
            ],
            [
                "pypi",
                "https://pypi.org/project/unsloth/"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1Ys44kVvmeZtnICzWz0xgpRnrIOjZAuxp",
        "update": 1731826299.049
    },
    {
        "name": "Phi-3.5",
        "description": "3.8 billion parameter language model trained on 3.3 trillion tokens, whose overall performance, as measured by both academic benchmarks and internal testing, rivals that of models such as Mixtral 8x7B and GPT-3.5, despite being small enough to be deployed on a phone",
        "author": [
            [
                "unsloth",
                "https://unsloth.ai/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/unslothai/unsloth",
                18837
            ],
            [
                "hf",
                "https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3"
            ],
            [
                "discord",
                "https://discord.gg/unsloth"
            ],
            [
                "website",
                "https://azure.microsoft.com/en-us/products/phi-3"
            ],
            [
                "blog post",
                "https://azure.microsoft.com/en-us/blog/introducing-phi-3-redefining-whats-possible-with-slms/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2404.14219"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/mlscaling/comments/1cberec/phi3_technical_report_a_highly_capable_language/"
            ],
            [
                "twitter",
                "https://twitter.com/unslothai"
            ],
            [
                "yt",
                "https://youtu.be/Enp70Kkjb8k"
            ],
            [
                "medium",
                "https://medium.com/@mysocial81/phi-3-5-microsofts-efficient-multilingual-and-secure-open-source-slms-5ed7d36738aa"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/LocalLLaMA/comments/1ey5i22/phi35_is_very_safe_microsoft_really_outdid/"
            ],
            [
                "pypi",
                "https://pypi.org/project/unsloth/"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1lN6hPQveB_mHSnTOYifygFcrO8C1bxq4",
        "update": 1731826235.897
    },
    {
        "name": "Gemma 2",
        "description": "New addition to the Gemma family of lightweight, state-of-the-art open models, ranging in scale from 2 billion to 27 billion parameters",
        "author": [
            [
                "unsloth",
                "https://unsloth.ai/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/unslothai/unsloth",
                18837
            ],
            [
                "blog post",
                "https://blog.google/technology/developers/google-gemma-2/"
            ],
            [
                "discord",
                "https://discord.gg/unsloth"
            ],
            [
                "hf",
                "https://huggingface.co/google/gemma-2-2b"
            ],
            [
                "yt",
                "https://youtu.be/t3js5iy1pcE"
            ],
            [
                "yt",
                "https://youtu.be/xxCkuxQuT_g"
            ],
            [
                "yt",
                "https://youtu.be/4N38V4h9S0A"
            ],
            [
                "yt",
                "https://youtu.be/qFULISWcjQc"
            ],
            [
                "yt",
                "https://youtu.be/MARG5S1uNbc"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2408.00118"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/code/danielhanchen/kaggle-gemma-7b-unsloth-notebook/"
            ],
            [
                "pypi",
                "https://pypi.org/project/unsloth/"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1vIrqH5uYDQwsJ4-OO3DErvuv4pBgVwk4",
        "update": 1731826314.482
    },
    {
        "name": "Mistral Small",
        "description": "Enterprise-grade small model",
        "author": [
            [
                "unsloth",
                "https://unsloth.ai/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/unslothai/unsloth",
                18837
            ],
            [
                "discord",
                "https://discord.gg/unsloth"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/LocalLLaMA/comments/1fj4unz/mistralaimistralsmallinstruct2409_new_22b_from/"
            ],
            [
                "website",
                "https://mistral.ai/"
            ],
            [
                "yt",
                "https://youtu.be/damcEQdlpqY"
            ],
            [
                "pypi",
                "https://pypi.org/project/unsloth/"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1oCEHcED15DzL8xXGU1VTx5ZfOJM8WY01",
        "update": 1731826275.51
    },
    {
        "name": "ORPO",
        "description": "Get up and running with large language models",
        "author": [
            [
                "Jiwoo Hong",
                "https://jiwooya1000.github.io/"
            ],
            [
                "Noah Lee",
                "https://nlee-208.github.io/"
            ],
            [
                "James Thorne",
                "https://jamesthorne.com/"
            ]
        ],
        "links": [
            [
                "discord",
                "https://discord.gg/unsloth"
            ],
            [
                "hf",
                "https://huggingface.co/datasets/reciperesearch/dolphin-sft-v0.1-preference"
            ],
            [
                "hf",
                "https://huggingface.co/docs/trl/main/en/orpo_trainer"
            ],
            [
                "pypi",
                "https://pypi.org/project/unsloth/"
            ],
            [
                "git",
                "https://github.com/xfactlab/orpo",
                423
            ],
            [
                "git",
                "https://github.com/unslothai/unsloth"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2403.07691"
            ],
            [
                "medium",
                "https://medium.com/@AriaLeeNotAriel/numbynum-orpo-monolithic-optimization-without-reference-model-hong-et-al-2024-reviewed-262d0778e08c"
            ],
            [
                "medium",
                "https://medium.com/@zergtant/optimizing-language-model-preferences-without-a-reference-model-introducing-the-orpo-method-1144b3e7aec3"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/LLMResearch/comments/1bh8iq5/orpo_monolithic_preference_optimization_without/"
            ],
            [
                "yt",
                "https://youtu.be/52kMBrAI_IM"
            ],
            [
                "yt",
                "https://youtu.be/6kkJGkPZP88"
            ],
            [
                "yt",
                "https://youtu.be/8MEPCPdKUH8"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/11t4njE3c4Lxl-07OD8lJSMKkfyJml3Tn",
        "update": 1731826247.258
    },
    {
        "name": "LlamaIndex",
        "description": "Data framework for your LLM application",
        "author": [
            [
                "Jerry Liu",
                "https://github.com/jerryjliu"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/run-llama/llama_index",
                37127
            ],
            [
                "pypi",
                "https://pypi.org/project/llama-index/"
            ],
            [
                "discord",
                "https://discord.gg/dGcwcsnxhU"
            ],
            [
                "git",
                "https://github.com/run-llama/LlamaIndexTS"
            ],
            [
                "docs",
                "https://docs.llamaindex.ai/en/stable/"
            ],
            [
                "twitter",
                "https://twitter.com/llama_index"
            ],
            [
                "git",
                "https://github.com/run-llama/llama-lab"
            ],
            [
                "website",
                "https://www.llamaindex.ai/"
            ],
            [
                "meta",
                "https://llama.meta.com/docs/integration-guides/llamaindex/"
            ],
            [
                "yt",
                "https://www.youtube.com/@LlamaIndex"
            ],
            [
                "yt",
                "https://youtu.be/TRjq7t2Ms5I"
            ],
            [
                "yt",
                "https://youtu.be/pApPGFwbigI"
            ],
            [
                "yt",
                "https://youtu.be/zeAyuLc_f3Q"
            ],
            [
                "yt",
                "https://youtu.be/hH4WkgILUD4"
            ],
            [
                "yt",
                "https://youtu.be/v6g8eo86T8A"
            ],
            [
                "yt",
                "https://youtu.be/FQBou-YgxyE"
            ],
            [
                "yt",
                "https://youtu.be/bQw92baScME"
            ],
            [
                "yt",
                "https://youtu.be/cNMYeW2mpBs"
            ]
        ],
        "colab": "https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/cookbooks/oreilly_course_cookbooks/Module-2/Components_Of_LlamaIndex.ipynb",
        "update": 1725550996.0
    },
    {
        "name": "Ollama",
        "description": "Get up and running with large language models",
        "author": [
            [
                "Michael Yang",
                "https://github.com/mxyng"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/ollama/ollama",
                100772
            ],
            [
                "website",
                "https://ollama.com/"
            ],
            [
                "docker",
                "https://hub.docker.com/r/ollama/ollama"
            ],
            [
                "git",
                "https://github.com/ollama/ollama-python"
            ],
            [
                "git",
                "https://github.com/ollama/ollama-js"
            ],
            [
                "git",
                "https://github.com/ggerganov/llama.cpp"
            ],
            [
                "pypi",
                "https://pypi.org/project/ollama/"
            ],
            [
                "twitter",
                "https://x.com/ollama"
            ],
            [
                "yt",
                "https://youtu.be/rIRkxZSn-A8"
            ],
            [
                "yt",
                "https://youtu.be/1xdneyn6zjw"
            ],
            [
                "yt",
                "https://youtu.be/cTxENLLX1ho"
            ],
            [
                "yt",
                "https://youtu.be/ztBJqzBU5kc"
            ],
            [
                "yt",
                "https://youtu.be/Ox8hhpgrUi0"
            ],
            [
                "yt",
                "https://youtu.be/lhQ8ixnYO2Y"
            ],
            [
                "yt",
                "https://youtu.be/pxhkDaKzBaY"
            ]
        ],
        "colab": "https://colab.research.google.com/github/ollama/ollama/blob/master/examples/jupyter-notebook/ollama.ipynb",
        "update": 1707520770.0
    },
    {
        "name": "X—LLM",
        "description": "Easy LLM Finetuning using the most advanced methods",
        "author": [
            [
                "Boris Zubarev",
                "https://github.com/BobaZooba"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/BobaZooba/xllm",
                382
            ],
            [
                "discord",
                "https://discord.gg/5znbxBgwZP"
            ],
            [
                "pypi",
                "https://pypi.org/project/xllm/"
            ],
            [
                "git",
                "https://github.com/BobaZooba/xllm-demo"
            ],
            [
                "git",
                "https://github.com/BobaZooba/wgpt"
            ],
            [
                "git",
                "https://github.com/BobaZooba/shurale"
            ],
            [
                "hf",
                "https://huggingface.co/TachyHealth"
            ],
            [
                "hf",
                "https://huggingface.co/BobaZooba/Shurale7b-v1"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2305.18290"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1zsNmJFns1PKZy5VE5p5nsQL-mZF7SwHf?usp=sharing",
        "update": 1700046727.032
    },
    {
        "name": "XGBoost",
        "description": "Optimized distributed gradient boosting library designed to be highly efficient, flexible and portable",
        "author": [
            [
                "Tianqi Chen",
                "https://tqchen.com/"
            ],
            [
                "Carlos Guestrin",
                "https://guestrin.su.domains/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/dmlc/xgboost",
                26368
            ],
            [
                "docs",
                "https://xgboost.readthedocs.org/"
            ],
            [
                "pypi",
                "https://pypi.python.org/pypi/xgboost/"
            ],
            [
                "twitter",
                "https://twitter.com/XGBoostProject"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Gradient_boosting"
            ],
            [
                "doi",
                "https://doi.org/10.1145/2939672.2939785",
                23893
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/XGBoost"
            ],
            [
                "yt",
                "https://www.youtube.com/playlist?list=PLblh5JKOoLULU0irPgs1SnKO6wqVjKUsQ"
            ],
            [
                "yt",
                "https://youtu.be/vV12dGe_Fho"
            ],
            [
                "yt",
                "https://youtu.be/gPciUPwWJQQ"
            ],
            [
                "yt",
                "https://youtu.be/TyvYZ26alZs"
            ],
            [
                "yt",
                "https://youtu.be/kho6oANGu_A"
            ],
            [
                "yt",
                "https://youtu.be/0Xc9LIb_HTw"
            ],
            [
                "yt",
                "https://youtu.be/OQKQHNCVf5k"
            ]
        ],
        "colab": "https://colab.research.google.com/github/comet-ml/comet-examples/blob/master/integrations/model-training/xgboost/notebooks/how_to_use_comet_with_xgboost_tutorial.ipynb",
        "update": 1729604554.0
    },
    {
        "name": "CatBoost",
        "description": "High-performance open source library for gradient boosting on decision trees",
        "author": [
            [
                "Anna Veronika Dorogush",
                "https://github.com/annaveronika"
            ],
            [
                "Vasily Ershov",
                "https://linkedin.com/in/vasily-ershov-04768199"
            ],
            [
                "Andrey Gulin",
                "https://www.linkedin.com/in/andreygulin"
            ],
            [
                "Liudmila Prokhorenkova",
                "https://github.com/ostroumova-la"
            ],
            [
                "Gleb Gusev",
                "https://scholar.google.com/citations?user=RWX4sYcAAAAJ"
            ],
            [
                "Aleksandr Vorobev",
                "https://scholar.google.com/citations?user=WiCXGGIAAAAJ"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/catboost/catboost",
                8125
            ],
            [
                "website",
                "https://catboost.ai/"
            ],
            [
                "pypi",
                "https://pypi.org/project/catboost/"
            ],
            [
                "twitter",
                "https://twitter.com/CatBoostML"
            ],
            [
                "docs",
                "https://catboost.ai/en/docs/"
            ],
            [
                "yt",
                "https://youtu.be/8o0e-r0B5xQ"
            ],
            [
                "yt",
                "https://youtu.be/usdEWSDisS0"
            ],
            [
                "yt",
                "https://youtu.be/KXOTSkPL2X4"
            ],
            [
                "yt",
                "https://youtu.be/UYDwhuyWYSo"
            ],
            [
                "yt",
                "https://youtu.be/xl1fwCza9C8"
            ],
            [
                "yt",
                "https://youtu.be/Q_xa4RvnDcY"
            ],
            [
                "yt",
                "https://youtu.be/ySla2kczbeM"
            ],
            [
                "yt",
                "https://youtu.be/47-mAVms-b8"
            ],
            [
                "yt",
                "https://youtu.be/nrGt5VKZpzc"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1810.11363"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1706.09516"
            ],
            [
                "neurips",
                "https://papers.nips.cc/paper_files/paper/2018/hash/14491b756b3a51daac41c24863285549-Abstract.html"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/CatBoost"
            ],
            [
                "medium",
                "https://medium.com/@mohan-gupta/catboost-algorithm-2156129d740d"
            ]
        ],
        "colab": "https://colab.research.google.com/github/catboost/tutorials/blob/master/python_tutorial.ipynb",
        "update": 1731886346.0
    },
    {
        "name": "img2dataset",
        "description": "Easily turn large sets of image urls to an image dataset",
        "author": [
            [
                "Romain Beaumont",
                "https://github.com/rom1504"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/rom1504/img2dataset",
                3761
            ],
            [
                "discord",
                "https://discord.gg/eq3cAMZtCC"
            ],
            [
                "pypi",
                "https://pypi.python.org/pypi/img2dataset"
            ],
            [
                "git",
                "https://github.com/uber/petastorm"
            ],
            [
                "tf",
                "https://www.tensorflow.org/guide/data"
            ],
            [
                "git",
                "https://github.com/fsspec/filesystem_spec/blob/6233f315548b512ec379323f762b70764efeb92c/fsspec/registry.py#L87"
            ],
            [
                "hf",
                "https://huggingface.co/docs/hub/datasets-viewer"
            ],
            [
                "hf",
                "https://huggingface.co/docs/huggingface_hub/guides/hf_file_system"
            ],
            [
                "git",
                "https://github.com/fsspec/sshfs"
            ],
            [
                "git",
                "https://github.com/rom1504/cah-prepro"
            ],
            [
                "medium",
                "https://rom1504.medium.com/semantic-search-at-billions-scale-95f21695689a"
            ]
        ],
        "colab": "https://colab.research.google.com/github/rom1504/img2dataset/blob/master/notebook/img2dataset_getting_started.ipynb",
        "update": 1631877703.0
    },
    {
        "name": "AutoFaiss",
        "description": "Automatically create Faiss knn indices with the most optimal similarity search parameters",
        "author": [
            [
                "Ctiteo",
                "https://github.com/criteo"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/criteo/autofaiss",
                821
            ],
            [
                "docs",
                "https://criteo.github.io/autofaiss/"
            ],
            [
                "pypi",
                "https://pypi.python.org/pypi/autofaiss"
            ],
            [
                "git",
                "https://github.com/facebookresearch/faiss"
            ],
            [
                "medium",
                "https://medium.com/criteo-engineering/introducing-autofaiss-an-automatic-k-nearest-neighbor-indexing-library-at-scale-c90842005a11"
            ]
        ],
        "colab": "https://colab.research.google.com/github/criteo/autofaiss/blob/master/docs/notebooks/autofaiss_getting_started.ipynb",
        "update": 1705051590.0
    },
    {
        "name": "tensor_parallel",
        "description": "Run large PyTorch models on multiple GPUs in one line of code with potentially linear speedup",
        "author": [
            [
                "Andrei Panferov",
                "https://blog.panferov.org/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/BlackSamorez/tensor_parallel",
                637
            ],
            [
                "pypi",
                "https://pypi.org/project/tensor-parallel/"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/code/blacksamorez/tensor-parallel-int4-llm/"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/code/muellerzr/multi-gpu-and-accelerate"
            ],
            [
                "git",
                "https://github.com/microsoft/DeepSpeed"
            ],
            [
                "git",
                "https://github.com/facebookresearch/fairscale"
            ],
            [
                "git",
                "https://github.com/NVIDIA/Megatron-LM"
            ],
            [
                "git",
                "https://github.com/tunib-ai/parallelformers"
            ],
            [
                "hf",
                "https://huggingface.co/docs/transformers/model_doc/gpt2"
            ],
            [
                "git",
                "https://github.com/alpa-projects/alpa"
            ]
        ],
        "colab": "https://colab.research.google.com/github/BlackSamorez/tensor_parallel/blob/master/examples/training_flan-t5-xl.ipynb",
        "update": 1672352467.0
    },
    {
        "name": "Contextualized Topic Models",
        "description": "Family of topic models that use pre-trained representations of language to support topic modeling",
        "author": [
            [
                "Federico Bianchi",
                "https://federicobianchi.io/"
            ],
            [
                "Silvia Terragni",
                "https://silviatti.github.io/"
            ],
            [
                "Dirk Hovy",
                "http://dirkhovy.com/"
            ],
            [
                "Debora Nozza",
                "https://www.deboranozza.com/"
            ],
            [
                "Elisabetta Fersini",
                "https://www.unimib.it/elisabetta-fersini"
            ]
        ],
        "links": [
            [
                "doi",
                "https://doi.org/10.18653/v1/2021.eacl-main.143",
                49
            ],
            [
                "doi",
                "https://doi.org/10.18653/v1/2021.acl-short.96"
            ],
            [
                "git",
                "https://github.com/MilaNLProc/contextualized-topic-models",
                1206
            ],
            [
                "pypi",
                "https://pypi.python.org/pypi/contextualized_topic_models"
            ],
            [
                "medium",
                "https://medium.com/towards-data-science/contextualized-topic-modeling-with-python-eacl2021-eacf6dfa576"
            ],
            [
                "yt",
                "https://youtu.be/n1_G8K07KoM"
            ],
            [
                "docs",
                "https://contextualized-topic-models.readthedocs.io/en/latest/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2004.03974"
            ],
            [
                "git",
                "https://github.com/estebandito22/PyTorchAVITM"
            ],
            [
                "git",
                "https://github.com/dlukes/rbo"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/1fXJjr_rwqvpp1IdNQ4dxqN4Dp88cxO97",
        "update": 1689980743.006
    },
    {
        "name": "DataChain",
        "description": "AI-dataframe to enrich, transform and analyze data from cloud storages for ML training and LLM apps",
        "author": [
            [
                "Iterative",
                "https://iterative.ai/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/iterative/datachain",
                2041
            ],
            [
                "docs",
                "https://datachain.dvc.ai/"
            ],
            [
                "pypi",
                "https://pypi.org/project/datachain/"
            ],
            [
                "discord",
                "https://dvc.org/chat"
            ],
            [
                "twitter",
                "https://twitter.com/DVCorg"
            ],
            [
                "yt",
                "https://youtu.be/qoqhllB3gN8"
            ],
            [
                "yt",
                "https://www.youtube.com/live/JT5AwGz5QMI"
            ]
        ],
        "colab": "https://colab.research.google.com/github/iterative/datachain-examples/blob/main/multimodal/clip_fine_tuning.ipynb",
        "update": 1725845364.0
    },
    {
        "name": "SAA+",
        "description": "Framework, Segment Any Anomaly +, for zero-shot anomaly segmentation with hybrid prompt regularization to improve the adaptability of modern foundation models",
        "author": [
            [
                "Yunkang Cao",
                "https://caoyunkang.github.io/"
            ],
            [
                "Xiaohao Xu",
                "https://scholar.google.com/citations?user=3Ifn2DoAAAAJ"
            ],
            [
                "Chen Sun",
                "https://www.researchgate.net/profile/Chen-Sun-58"
            ],
            [
                "Yuqi Cheng",
                "https://scholar.google.com/citations?user=02BC-WgAAAAJ"
            ],
            [
                "Zongwei Du",
                "https://github.com/duzongwei"
            ],
            [
                "Liang Gao",
                "https://scholar.google.com/citations?user=NqIi8_8AAAAJ"
            ],
            [
                "Weiming Shen",
                "https://scholar.google.com/citations?user=FuSHsx4AAAAJ"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/caoyunkang/Segment-Any-Anomaly",
                746
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2305.10724"
            ],
            [
                "hf",
                "https://huggingface.co/spaces/Caoyunkang/Segment-Any-Anomaly"
            ],
            [
                "git",
                "https://github.com/abin24/Magnetic-tile-defect-datasets."
            ],
            [
                "git",
                "https://github.com/caoyunkang/WinClip"
            ]
        ],
        "colab": "https://colab.research.google.com/drive/12Sh0j92YYmTa0oIuSEWWpPBCpIwCSVhz",
        "update": 1726211734.185
    },
    {
        "name": "NeuSpell",
        "description": "Open-source toolkit for spelling correction in English",
        "author": [
            [
                "Sai Muralidhar Jayanthi",
                "https://github.com/murali1996"
            ],
            [
                "Danish Pruthi",
                "https://danishpruthi.com/"
            ],
            [
                "Graham Neubig",
                "https://phontron.com/index.php"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/neuspell/neuspell",
                675
            ],
            [
                "project",
                "https://neuspell.github.io/"
            ],
            [
                "hf",
                "https://huggingface.co/transformers/bertology.html"
            ],
            [
                "doi",
                "https://doi.org/10.18653/v1/2020.emnlp-demos.21",
                27
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2010.11085"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1312.3005"
            ],
            [
                "medium",
                "https://medium.com/@kunalgkjoshi/implementing-spell-correction-a-journey-with-xfspell-and-neuspell-4bc33e3bcde7"
            ]
        ],
        "colab": "https://colab.research.google.com/github/neuspell/neuspell/blob/master/scripts/english_baselines/2_jamspell.ipynb",
        "update": 1617477043.0
    },
    {
        "name": "TriMap",
        "description": "Dimensionality reduction technique based on triplet constraints, which preserves the global structure of the data better than the other commonly used methods such as t-SNE, LargeVis, and UMAP",
        "author": [
            [
                "Ehsan Amid",
                "https://sites.google.com/view/eamid/"
            ],
            [
                "Manfred Warmuth",
                "https://mwarmuth.bitbucket.io/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/eamid/trimap",
                308
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/1910.00204"
            ],
            [
                "git",
                "https://github.com/google-research/google-research/tree/master/trimap"
            ],
            [
                "git",
                "https://github.com/spotify/annoy"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Principal_component_analysis#/media/File:GaussianScatterPCA.svg"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/MNIST_database"
            ],
            [
                "git",
                "https://github.com/zalandoresearch/fashion-mnist"
            ],
            [
                "data",
                "https://www.cs.columbia.edu/CAVE/software/softlib/coil-100.php"
            ]
        ],
        "colab": "https://colab.research.google.com/github/eamid/examples/blob/master/TriMap.ipynb#scrollTo=nSyGA-ymB-jN",
        "update": 1647498950.0
    },
    {
        "name": "XLA",
        "description": "Accelerated Linear Algebra is an open-source machine learning compiler for GPUs, CPUs, and ML accelerators",
        "author": [
            [
                "OpenXLA",
                "https://openxla.org"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/openxla/xla",
                2752
            ],
            [
                "pt",
                "https://pytorch.org/xla"
            ],
            [
                "tf",
                "https://www.tensorflow.org/xla"
            ],
            [
                "medium",
                "https://medium.com/@muhammedashraf2661/demystifying-xla-unlocking-the-power-of-accelerated-linear-algebra-9b62f8180dbd"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/Accelerated_Linear_Algebra"
            ],
            [
                "medium",
                "https://runaker.medium.com/one-code-to-rule-them-all-simplifying-ai-development-with-hardware-agnostic-abstraction-layers-a61448bb6d22"
            ],
            [
                "yt",
                "https://www.youtube.com/playlist?list=PLlFotmaRrOzs23kqlSF-r8v1dJHz5GxZs"
            ],
            [
                "yt",
                "https://www.youtube.com/playlist?list=PLlFotmaRrOzu8TQsTahDo_Cn7QdntFlUL"
            ],
            [
                "yt",
                "https://www.youtube.com/playlist?list=PLlFotmaRrOzt8xOwckcXL7vObZmr8PK1y"
            ],
            [
                "yt",
                "https://youtu.be/QNSxFXJ-xMM"
            ]
        ],
        "colab": "https://colab.research.google.com/github/openxla/xla/blob/main/docs/tf2xla/tutorials/jit_compile.ipynb",
        "update": 1706895318.0
    },
    {
        "name": "TransformerLens",
        "description": "Library for doing mechanistic interpretability of GPT-2 Style language models",
        "author": [
            [
                "Neel Nanda",
                "https://www.neelnanda.io/about"
            ],
            [
                "Joseph Bloom",
                "https://github.com/jbloomAus"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/TransformerLensOrg/TransformerLens",
                1629
            ],
            [
                "pypi",
                "https://pypi.org/project/transformer-lens/"
            ],
            [
                "docs",
                "https://transformerlensorg.github.io/TransformerLens/"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2302.03025"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2303.08112"
            ],
            [
                "git",
                "https://github.com/jbloomAus/DecisionTransformerInterpretability"
            ],
            [
                "yt",
                "https://www.youtube.com/channel/UCBMJ0D-omcRay8dh4QT0doQ"
            ],
            [
                "slack",
                "https://join.slack.com/t/opensourcemechanistic/shared_invite/zt-1qosyh8g3-9bF3gamhLNJiqCL_QqLFrA"
            ],
            [
                "medium",
                "https://medium.com/@fgkffbvkhg/transformerlens-understanding-the-model-e339be551299"
            ],
            [
                "yt",
                "https://youtu.be/oL67e-uEgWI"
            ]
        ],
        "colab": "https://colab.research.google.com/github/TransformerLensOrg/TransformerLens/blob/main/demos/Main_Demo.ipynb",
        "update": 1721756319.0
    },
    {
        "name": "LightAutoML",
        "description": "Allows you create machine learning models using just a few lines of code, or build your own custom pipeline using ready blocks",
        "author": [
            [
                "Alexander Ryzhkov",
                "https://github.com/alexmryzhkov"
            ],
            [
                "Anton Vakhrushev",
                "https://www.kaggle.com/btbpanda"
            ],
            [
                "Dmitry Simakov",
                "https://github.com/DESimakov"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/sb-ai-lab/LightAutoML",
                1232
            ],
            [
                "pypi",
                "https://pypi.org/project/lightautoml"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/alexryzhkov/n3-tps-april-21-lightautoml-starter"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/alexryzhkov/lightautoml-titanic-love"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/alexryzhkov/lightautoml-extreme-short-titanic-solution"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/alexryzhkov/lightautoml-houseprices-love"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/simakov/lama-whitebox-preset-example"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/simakov/lama-custom-automl-pipeline-example"
            ],
            [
                "kaggle",
                "https://www.kaggle.com/code/mikhailkuz/lightautoml-nn-happiness"
            ],
            [
                "yt",
                "https://www.youtube.com/live/4pbO673B9Oo"
            ],
            [
                "yt",
                "https://youtu.be/ci8uqgWFJGg"
            ],
            [
                "yt",
                "https://youtu.be/TYu1UG-E9e8"
            ],
            [
                "arxiv",
                "https://arxiv.org/abs/2109.01528"
            ],
            [
                "medium",
                "https://alexmryzhkov.medium.com/lightautoml-preset-usage-tutorial-2cce7da6f936"
            ],
            [
                "git",
                "https://github.com/Rishat-skoltech/LightAutoML_GPU"
            ],
            [
                "git",
                "https://github.com/sb-ai-lab/SLAMA"
            ],
            [
                "website",
                "https://developers.sber.ru/portal/products/lightautoml"
            ],
            [
                "docs",
                "https://lightautoml.readthedocs.io/en/latest/"
            ],
            [
                "yt",
                "https://www.youtube.com/playlist?list=PLJU_M19giWaEXcQtWWhpOKJf_luMc12B2"
            ],
            [
                "yt",
                "https://youtu.be/hr8GbPOHaEE"
            ]
        ],
        "colab": "https://colab.research.google.com/github/AILab-MLTools/LightAutoML/blob/master/examples/tutorials/Tutorial_1_basics.ipynb",
        "update": 1730367195.0
    },
    {
        "name": "SAE Lens",
        "description": "Training Sparse Autoencoders on Language Models",
        "author": [
            [
                "Joseph Bloom",
                "https://github.com/jbloomAus"
            ],
            [
                "Curt Tigges",
                "https://curttigges.com/"
            ],
            [
                "David Chanin",
                "https://chanind.github.io/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/jbloomAus/SAELens",
                507
            ],
            [
                "pypi",
                "https://pypi.org/project/sae-lens/"
            ],
            [
                "docs",
                "https://jbloomaus.github.io/SAELens/"
            ],
            [
                "slack",
                "https://join.slack.com/t/opensourcemechanistic/shared_invite/zt-2k0id7mv8-CsIgPLmmHd03RPJmLUcapw"
            ]
        ],
        "colab": "https://colab.research.google.com/github/jbloomAus/SAELens/blob/main/tutorials/tutorial_2_0.ipynb",
        "update": 1733245050.0
    },
    {
        "name": "LangGraph",
        "description": "Library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows",
        "author": [
            [
                "LangChain",
                "https://www.langchain.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/langchain-ai/langgraph",
                7008
            ],
            [
                "docs",
                "https://langchain-ai.github.io/langgraph/"
            ],
            [
                "git",
                "https://github.com/langchain-ai/langgraphjs"
            ],
            [
                "website",
                "https://www.langchain.com/langgraph"
            ],
            [
                "blog post",
                "https://www.langchain.com/langgraph"
            ],
            [
                "medium",
                "https://towardsdatascience.com/from-basics-to-advanced-exploring-langgraph-e8c1cf4db787?gi=eb24d42206bf"
            ],
            [
                "pypi",
                "https://pypi.org/project/langgraph/"
            ],
            [
                "yt",
                "https://www.youtube.com/playlist?list=PLfaIDFEXuae16n2TWUkKq5PgJ0w6Pkwtg"
            ],
            [
                "yt",
                "https://youtu.be/1bUy-1hGZpI"
            ],
            [
                "yt",
                "https://youtu.be/PqS1kib7RTw"
            ],
            [
                "yt",
                "https://youtu.be/PNr3f7QyQU4"
            ],
            [
                "yt",
                "https://youtu.be/qaWOwbFw3cs"
            ],
            [
                "medium",
                "https://medium.com/cyberark-engineering/building-production-ready-ai-agents-with-langgraph-a-real-life-use-case-7bda34c7f4e4"
            ]
        ],
        "colab": "https://colab.research.google.com/github/langchain-ai/langgraph/blob/main/docs/docs/tutorials/introduction.ipynb",
        "update": 1732775463.0
    },
    {
        "name": "LangChain",
        "description": "Framework for developing applications powered by large language models",
        "author": [
            [
                "LangChain",
                "https://www.langchain.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/langchain-ai/langchain",
                95736
            ],
            [
                "docs",
                "https://python.langchain.com/docs/introduction/"
            ],
            [
                "twitter",
                "https://twitter.com/langchainai"
            ],
            [
                "git",
                "https://github.com/langchain-ai/langchainjs"
            ],
            [
                "git",
                "https://github.com/langchain-ai/langchain-extract"
            ],
            [
                "git",
                "https://github.com/langchain-ai/chat-langchain"
            ],
            [
                "git",
                "https://github.com/langchain-ai/weblangchain"
            ],
            [
                "wiki",
                "https://en.wikipedia.org/wiki/LangChain"
            ],
            [
                "yt",
                "https://www.youtube.com/playlist?list=PLqZXAkvF1bPNQER9mLmDbntNfSpzdDIU5"
            ],
            [
                "yt",
                "https://youtu.be/1bUy-1hGZpI"
            ],
            [
                "yt",
                "https://youtu.be/9AXP7tCI9PI"
            ],
            [
                "yt",
                "https://youtu.be/aywZrzNaKjs"
            ],
            [
                "yt",
                "https://youtu.be/dXxQ0LR-3Hg"
            ],
            [
                "yt",
                "https://youtu.be/sVcwVQRHIc8"
            ],
            [
                "yt",
                "https://youtu.be/MlK6SIjcjE8"
            ],
            [
                "yt",
                "https://youtu.be/TLf90ipMzfE"
            ],
            [
                "yt",
                "https://www.youtube.com/playlist?list=PLZoTAELRMXVORE4VF7WQ_fAl0L1Gljtar"
            ],
            [
                "pypi",
                "https://pypi.org/project/langchain/"
            ],
            [
                "medium",
                "https://medium.com/@neelmakvana168/what-is-lang-chain-in-llm-e55e021da2b3"
            ],
            [
                "medium",
                "https://medium.com/@bijit211987/llm-powered-applications-building-with-langchain-cad4032d733c"
            ],
            [
                "medium",
                "https://medium.com/munchy-bytes/exploring-langchain-ff13fff63340"
            ]
        ],
        "colab": "https://colab.research.google.com/github/langchain-ai/langchain/blob/master/docs/docs/tutorials/qa_chat_history.ipynb",
        "update": 1732635792.0
    },
    {
        "name": "Crawl4AI",
        "description": "LLM Friendly Web Crawler & Scrapper",
        "author": [
            [
                "UncleCode",
                "https://github.com/unclecode"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/unclecode/crawl4ai",
                17976
            ],
            [
                "docs",
                "https://crawl4ai.com/mkdocs/"
            ],
            [
                "twitter",
                "https://twitter.com/unclecode"
            ],
            [
                "yt",
                "https://youtu.be/Ex3EpKxlMO0"
            ],
            [
                "yt",
                "https://youtu.be/KAvuVUh0XU8"
            ],
            [
                "yt",
                "https://youtu.be/lpOb1bQO7aM"
            ],
            [
                "yt",
                "https://youtu.be/81KIBvg0bsQ"
            ],
            [
                "medium",
                "https://medium.com/@pankaj_pandey/crawl4ai-your-ultimate-asynchronous-web-crawling-companion-%EF%B8%8F-66a21cf57c0a"
            ],
            [
                "pypi",
                "https://pypi.org/project/Crawl4AI/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/unclecode/crawl4ai/blob/main/docs/examples/quickstart.ipynb",
        "update": 1730291975.0
    },
    {
        "name": "Anthropic courses",
        "description": "Anthropic's educational courses",
        "author": [
            [
                "Anthropic",
                "https://www.anthropic.com/"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/anthropics/courses",
                8252
            ],
            [
                "docs",
                "https://docs.anthropic.com/en/docs/resources/courses"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/ClaudeAI/comments/1f7czsx/anthropics_official_educational_courses_on_prompt/"
            ]
        ],
        "colab": "https://colab.research.google.com/github/anthropics/courses/blob/master/anthropic_api_fundamentals/01_getting_started.ipynb",
        "update": 1724351244.0
    },
    {
        "name": "Swarm",
        "description": "Educational framework exploring ergonomic, lightweight multi-agent orchestration",
        "author": [
            [
                "Ilan Bigio",
                "https://ilanbigio.com/"
            ],
            [
                "James Hills",
                "https://github.com/jhills20"
            ],
            [
                "Shyamal Anadkat",
                "https://shyamal.me/"
            ],
            [
                "Charu Jaiswal",
                "https://github.com/charuj"
            ],
            [
                "Colin Jarvis",
                "https://github.com/colin-openai"
            ],
            [
                "Katia Guzman",
                "https://github.com/katia-openai"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/openai/swarm",
                16556
            ],
            [
                "medium",
                "https://medium.com/@michael_79773/exploring-openais-swarm-an-experimental-framework-for-multi-agent-systems-5ba09964ca18"
            ],
            [
                "reddit",
                "https://www.reddit.com/r/LocalLLaMA/comments/1g56itb/openai_swarm_the_agentic_framework_should_you_care/"
            ],
            [
                "medium",
                "https://ai.plainenglish.io/openai-releases-swarm-what-is-it-b61ecb88d67e"
            ],
            [
                "yt",
                "https://youtu.be/Cw0ME8OZ0xI"
            ],
            [
                "yt",
                "https://youtu.be/q7_5eCmu0MY"
            ],
            [
                "yt",
                "https://youtu.be/LBih635lzps"
            ],
            [
                "yt",
                "https://youtu.be/npAljHBeKPc"
            ]
        ],
        "colab": "https://colab.research.google.com/github/NirDiamant/GenAI_Agents/blob/main/all_agents_tutorials/blog_writer_swarm.ipynb",
        "update": 1728970190.0
    },
    {
        "name": "moondream",
        "description": "Tiny vision language model that kicks ass and runs anywhere",
        "author": [
            [
                "Vik Korrapati",
                "https://github.com/vikhyat"
            ]
        ],
        "links": [
            [
                "git",
                "https://github.com/vikhyat/moondream",
                5914
            ],
            [
                "website",
                "https://moondream.ai/"
            ],
            [
                "discord",
                "https://discord.com/invite/tRUdpjDQfH"
            ],
            [
                "hf",
                "https://huggingface.co/vikhyatk/moondream2"
            ],
            [
                "medium",
                "https://medium.com/@indradumnabanerjee/getting-started-with-vision-language-model-moondream-783c264a02b9"
            ],
            [
                "hf",
                "https://huggingface.co/datasets/google/docci"
            ],
            [
                "hf",
                "https://huggingface.co/vikhyatk/moondream1"
            ],
            [
                "git",
                "https://github.com/kijai/ComfyUI-moondream"
            ]
        ],
        "colab": "https://colab.research.google.com/github/vikhyat/moondream/blob/main/notebooks/Finetuning.ipynb",
        "update": 1732974601.0
    }
]